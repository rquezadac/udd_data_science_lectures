{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f5e089b",
   "metadata": {},
   "source": [
    "# CLASE 1.5: Una introducción (generosa) al cálculo de probabilidades\n",
    "---\n",
    "\n",
    "## Introducción.\n",
    "La probabilidad, en términos bien generales, se corresponde con el estudio de la incertidumbre. Puede ser pensada como la fracción de tiempo en el cual un evento determinado ocurre, o como el grado de creencia bajo el cual un evento puede ocurrir. Queremos usar la probabilidad como medida de la posibilidad en que un suceso ocurre en un experimento determinado. Esta idea es esencial en los modelos de machine learning, puesto que con frecuencia queremos entender cuánto nivel de incertidumbre hay en nuestra data o en la predicción realizada por un modelo determinado. La cuantificación de la incertidumbre requiere de objetos matemáticos especializados conocidos como **variables aleatorias**, las cuales corresponden a funciones que mapean los resultados de experimentos aleatorios sobre los conjuntos de propiedades que nos interesan. Hay funciones asociadas a las variables aleatorias que permiten medir la probabilidad de que un resultado particular (o un conjunto de resultados) ocurra(n). Tales funciones se conocen como **distribuciones de probabilidad**.\n",
    "\n",
    "Las distribuciones de probabilidad son utilizadas como cimientos para la construcción de otros conceptos, tales como modelos probabilísticos, modelos gráficos y selección de modelos. En esta sección, presentaremos los conceptos necesarios para poder definir una probabilidad y cómo estos se relacionan para la construcción de una variable aleatoria, a fin de poder entender constructos más generales, tales como densidades y distribuciones.\n",
    "\n",
    "## Teoría clásica de probabilidad.\n",
    "\n",
    "### El concepto de probabilidad.\n",
    "Todos estamos familiarizados con la importancia de los experimentos en ciencias e ingeniería. La experimentación es útil porque, si suponemos que llevamos a cabo ciertos experimentos bajo condiciones esencialmente idénticas (algo especialmente cierto en pruebas industriales de algún componente, por ejemplo, un sistema de medición de perfil de cascada de mineral en un molino SAG), llegaremos (o deberíamos llegar) a los mismos resultados. En estas circunstancias, estamos en condiciones de controlar el valor de las variables que afectan el resultado del experimento.\n",
    "\n",
    "Sin embargo, en algunos experimentos, no somos capaces de controlar el valor de determinadas variables, de manera que un resultado cambiará de un experimento a otro, a pesar de que la mayoría de las condiciones sean las mismas. Estos experimentos se describen como aleatorios, porque existe una determinada (y muchas veces razonable) cantidad de incertidumbre inherente a ellos. Por ejemplo, si lanzamos un dado (no cargado y simétrico), el resultado del experimento será uno de los números del conjunto $\\Omega =\\left\\{ 1,2,3,4,5,6\\right\\}$. Un ejemplo un poco más industrial es la medición de la vida útil de fusibles producidos por una compañía manufacturadora de estos artefactos eléctricos. Entonces, el resultado del experimento es el tiempo $t$ en horas que se encuentra en algún intervalo, digamos $0\\leq t\\leq 6500$, suponiendo que la vida útil del fusible tiene un límite técnico de 6500 horas de uso.\n",
    "\n",
    "Un conjunto $\\Omega$ que consta de todos los resultados posibles de un experimento aleatorio es llamado espacio muestral, y cada resultado se denomina punto muestral. Con frecuencia habrá más de un espacio muestral que puede describir los resultados de un experimento, pero generalmente habrá uno que provee la mayor cantidad de información.\n",
    "\n",
    "**Ejemplo 5.1:** Consideremos el experimento de lanzar dos veces una moneda. Sea 0 el resultado que describe la obtención de un sello, y 1 el resultado que describe la obtención de una cara. El espacio muestral asociado a este experimento se ilustra en la Fig. (5.1), donde, por ejemplo, el par (0, 1) representa que, en el primer lanzamiento, obtenemos un sello, y en el segundo, una cara. ◼︎\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_5_1.png\" width=\"450\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (5.1): Una representación gráfica del espacio muestral relativo al experimento de lanzar una moneda (no trucada) </p>\n",
    "\n",
    "Si un espacio muestral tiene un numero finito de puntos muestrales, como en el ejemplo (5.1), se llamará **espacio muestral finito**. Si tiene un total de $n$ puntos, con $n\\in \\mathbb{N}$, siendo $n$ un valor no determinado, será llamado **espacio muestral infinito numerable** o **contable**. Si tiene un número indeterminado de puntos, no necesariamente equidistantes en relación a una referencia (por ejemplo, tantos puntos como los existentes en el intervalo $[a,b]$), será llamado **espacio muestral infinito no numerable**.\n",
    "\n",
    "Con frecuencia, si un espacio muestral $\\Omega$ es finito o infinito numerable, se habla de un **espacio muestral discreto**. Por otro lado, si $\\Omega$ es infinito no numerable, suele ser denominado como **espacio muestral continuo**.\n",
    "\n",
    "Un **evento** es un subconjunto $A$ del espacio muestral $\\Omega$. Es decir, un conjunto de resultados posibles. Si el resultado de un experimento es un elemento de $A$, decimos que **el evento $A$ ocurrió**. Un evento que consta de un punto sencillo de $\\Omega$ se denomina, con frecuencia, un **evento simple o elemental**.\n",
    "\n",
    "**Ejemplo 5.2:** Si lanzamos una moneda dos veces, el evento relativo a que sólo salga una cara es un subconjunto del espacio muestral y que consta únicamente de los puntos $(0, 1)$ y $(1, 0)$, tal y como se ilustra en la Fig. (5.2). ◼︎\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_5_2.png\" width=\"450\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (5.2): Una representación gráfica del espacio muestral relativo al experimento descrito en el ejemplo (5.2)</p>\n",
    "\n",
    "Como eventos particulares tenemos al mismo espacio muestral $\\Omega$, el cual se conoce como **evento seguro** o **cierto**, dado que un elemento de $\\Omega$ debe ocurrir sí o sí. Por otro lado, el conjunto vacío $\\emptyset$ se denomina **evento imposible**, debido a que no es factible que éste ocurra. Usando operaciones lógicas (que son también válidas para el álgebra de conjuntos), podemos definir otros eventos de $\\Omega$. Por ejemplo, si $A$ y $B$ son eventos, entonces podemos definir:\n",
    "\n",
    "- **(C1):** $A\\cap B$ corresponde a la **conjunción** de los eventos $A$ y $B$. Denota al evento compuesto por la ocurrencia simultánea de $A$ y $B$. En lógica matemática, la conjunción se suele escribir como $A\\wedge B$ y se corresponde con la operación lógica “Y” (`and` o `&` en Python).\n",
    "- **(C2):** $A\\cup B$ corresponde a la **disyunción** de los eventos $A$ y $B$. Denota el evento compuesto por la ocurrencia de $A$, o bien, de $B$. En lógica matemática, la disyunción se suele escribir como $A\\vee B$ y se corresponde con la operación lógica “O” (`or` o `|` en Python).\n",
    "- **(C3):** $\\bar{A}$ s el **evento complementario** a $A$. Denota el evento que describe la no ocurrencia de $A$. En lógica matemática, el complemento se corresponde con la operación lógica de negación denotada como “NO” (`not` o `~` en Python). También suele denotarse como $\\sim A$.\n",
    "- **(C4):** $A-B=A\\cap \\bar{B}$ describe la **diferencia simétrica** de los eventos $A$ y $B$. Describe al evento que consiste en la ocurrencia de $A$ y la no ocurrencia de $B$. En particular, observamos que $\\bar{A}=\\Omega -A$, donde $\\Omega$ es el espacio muestral.\n",
    "\n",
    "Si los conjuntos que describen a $A$ y $B$ son **disjuntos** (es decir, $A\\cap B=\\emptyset$), decimos que los eventos $A$ y $B$ son **mutuamente excluyentes**. En la práctica, esto significa que no pueden ocurrir simultáneamente. Una colección $A_{1},...,A_{n}$ de eventos es mutuamente excluyente si cada par $(A_{i},A_{j})$ de la colección (para $i\\neq j$) es mutuamente excluyente.\n",
    "\n",
    "En cualquier experimento aleatorio, hay siempre incertidumbre sobre si ocurrirá un evento en particular. Como una medida de la probabilidad con que esperamos que ocurra cierto evento, es conveniente asignar un número entre 0 y 1. Si estamos seguros de que tal evento ocurrirá, decimos que la **probabilidad** de dicho evento es 1 (o, equivalentemente, del 100%). Si estamos seguros de que tal evento no ocurrirá, la probabilidad de dicho evento es 0 (o del 0%).\n",
    "\n",
    "La probabilidad así definida permite además definir la **probabilidad del complemento** de un evento. De esta manera, si un evento tiene una probabilidad de $\\frac{1}{4}$ (o del 25%), entonces la diferencia $1-\\frac{1}{4}=\\frac{3}{4}$ (o 75%) será la probabilidad del complemento de dicho evento (es decir, la probabilidad de que no ocurra). Existen varias formas, en la teoría clásica, de definir una probabilidad. En primera instancia, tenemos un **enfoque clásico**, que establece que si un evento puede ocurrir de $k$ formas diferentes de un total de $n$, todas igualmente posibles (es decir, **equiprobables**), entonces la probabilidad del evento es igual a $\\frac{k}{n}$. Si $A$ es tal evento, entonces escribimos $P(A)=\\frac{k}{n}$.\n",
    "\n",
    "Existe también un **enfoque frecuentista** que permite definir la probabilidad en un contexto más empírico. De esta manera, si después de $n$ repeticiones de un experimento, donde $n$ es un número muy grande, se observa que un evento ocurre $k$ veces, entonces la probabilidad de dicho evento es igual a $\\frac{k}{n}$. Al respecto, una probabilidad definida de esta manera suele denominarse **probabilidad empírica** del evento.\n",
    "\n",
    "Ambos enfoques presentan serios inconvenientes. El clásico debido a que la frase “igualmente probable” es una situación que se describe vagamente; y el frecuentista, porque un “número grande” es igualmente vago. Debido a estas dificultades, la definición de probabilidad se hace en base a ciertos enunciados conocidos formalmente como **axiomas de probabilidad**.\n",
    "\n",
    "**<font color='blue'>Definición 5.1 – Probabilidad:</font>** Supongamos que tenemos un espacio muestral $\\Omega$. Si $\\Omega$ es discreto, todos los subconjuntos corresponden a eventos y viceversa, pero si $\\Omega$ no es discreto, sólo los subconjuntos *medibles* corresponden a eventos. Para cada evento $A$ en la clase $C$ de eventos (siendo $C$ un subconjunto como el descrito previamente), asociamos un número $P(A)\\in \\mathbb{R}$. Entonces $P$ se denomina **función de probabilidad** y $P(A)$ la probabilidad asociada al evento $A$, si se cumplen los siguientes axiomas:\n",
    "\n",
    "- **(A1):** Para cada evento $A$ en la clase $C$, se tiene que $P(A)\\geq 0$.\n",
    "- **(A2):** Para el evento seguro $\\Omega$ en la clase $C$, se tiene que $P(\\Omega)=1$.\n",
    "- **(A3):** Para cualquier número de eventos mutuamente excluyentes, digamos $A_{1},...,A_{n}$, en la clase $C$, se tiene que $P\\left( \\bigcup^{n}_{k=1} A_{k}\\right)  =\\sum^{n}_{k=1} P\\left( A_{k}\\right)$.\n",
    "\n",
    "A partir de los axiomas de probabilidad, es posible agrupar una serie de resultados importantes e inmediatos relativos a la definición de probabilidad. Todos estos resultados los agrupamos en términos del siguiente teorema.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.1:</font>** *Sea $\\Omega$ un espacio muestral y $\\left\\{ A_{k}\\right\\}^{n}_{k=1}$ una colección de eventos de $\\Omega$. Entonces tenemos que:*\n",
    "\n",
    "- **(T1):** *Si $A_{i}\\subset A_{j}$, entonces $P(A_{i})\\leq P(A_{j})$ y $P(A_{j}-A_{i})=P(A_{j})-P(A_{i})$.*\n",
    "- **(T2):** *Para todo evento $A_{k}\\subset \\Omega$, se tiene que $0\\leq P(A_{k})\\leq 1$. Es decir, la probabilidad de un evento tiene un valor entre 0 y 1.*\n",
    "- **(T3):** $P(\\emptyset)=0$. *Es decir, el evento imposible tiene probabilidad nula.*\n",
    "- **(T4):** *Si $\\bar{A}$ es el complemento de $A$, entonces se tiene que $P(\\bar{A})=1-P(A)$.*\n",
    "- **(T5):** *Si $A=\\bigcup^{n}_{k=1} A_{k}$, donde $A_{1},...,A_{n}$ son eventos mutuamente excluyentes, entonces $P\\left( A\\right)  =\\sum^{n}_{k=1} P\\left( A_{k}\\right)$. En particular, si $A=\\Omega$, entonces $P(\\Omega)=1$.*\n",
    "- **(T6):** *Si $A$ y $B$ son dos eventos cualesquiera, entonces $P(A\\cup B)=P(A)+P(B)-P(A\\cap B)$. De forma más general, para la colección $\\left\\{ A_{k}\\right\\}^{n}_{k=1}$, si los eventos de dicha colección son todos arbitrarios, se tiene que*\n",
    "\n",
    "$$P\\left( \\bigcup^{n}_{k=1} A_{k}\\right)  =\\sum^{n}_{k=1} P\\left( A_{k}\\right)  -\\sum_{i,j:1\\leq i\\leq j\\leq n} P\\left( A_{i}\\cap A_{j}\\right)  +\\sum_{i,j,k:1\\leq i\\leq j\\leq k\\leq n} P\\left( A_{i}\\cap A_{j}\\cap A_{k}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.1)$</p>\n",
    "\n",
    "- **(T7):** *Para cualesquiera eventos $A$ y $B$, se tiene que $P(A)=P(A\\cap B)+P(A\\cap \\bar{B})$*.\n",
    "- **(T8):** *Si un evento $A$ debe dar como resultado la ocurrencia de uno de los eventos mutuamente excluyentes $A_{1},...,A_{n}$, entonces tenemos que*\n",
    "\n",
    "$$P\\left( A_{k}\\right)  =\\sum^{n}_{k=1} P\\left( A\\cap A_{k}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.2)$</p>\n",
    "◆"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ab258a9",
   "metadata": {},
   "source": [
    "### Asignación de probabilidades.\n",
    "Si un espacio muestral $\\Omega$ consta de un número finito de resultados $a_{1},...,a_{n}$, entonces, conforme **(T5)**, tenemos que $P(A_{1})+\\cdots +P(A_{n})=1$, donde $A_{1},...,A_{n}$ es una colección de eventos elementales tales que $A_{i}=\\left\\{ a_{i}\\right\\}$. Entonces podemos escoger arbitrariamente cualquier número no negativo para las probabilidades de esos eventos sencillos siempre y cuando se satisfaga la ecuación (5.2). En particular, si suponemos que hay probabilidades iguales para todos esos eventos sencillos, entonces se tendrá que\n",
    "\n",
    "$$P\\left( A_{k}\\right)  =\\frac{1}{k} \\  ;\\  k=1,...,n$$\n",
    "<p style=\"text-align: right;\">$(5.3)$</p>\n",
    "\n",
    "Si $A$ es un conjunto conformado por $h$ eventos sencillos, entonces se tendrá que\n",
    "\n",
    "$$P\\left( A\\right)  =\\frac{h}{n}$$\n",
    "<p style=\"text-align: right;\">$(5.4)$</p>\n",
    "\n",
    "que equivale a la fórmula clásica de probabilidad vista al inicio de esta sección.\n",
    "\n",
    "**Ejemplo 5.3:** Supongamos que se lanza un dado no cargado y simétrico una sola vez. Calcularemos la probabilidad de obtener un 2 o un 5 en dicho lanzamiento. En efecto, el espacio muestral de este experimento corresponde al conjunto finito $\\Omega =\\left\\{ 1,2,3,4,5,6\\right\\}$. Si asignamos probabilidades iguales a cada uno de los puntos muestrales (lo que desde luego es válido, puesto que hemos supuesto que el dado no está cargado y es completamente simétrico), entonces\n",
    "\n",
    "$$P\\left( 1\\right)  =P\\left( 2\\right)  =\\cdots =P\\left( 6\\right)  =\\frac{1}{6}$$\n",
    "<p style=\"text-align: right;\">$(5.5)$</p>\n",
    "\n",
    "Por lo tanto, la probabilidad buscada es $P(2\\cup 5)=P(2)+P(5)=1/3$. ◼"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eecfa33",
   "metadata": {},
   "source": [
    "### Probabilidad condicional.\n",
    "Sean $A$ y $B$ dos eventos ilustrados en el diagrama de Venn de la Fig. (5.3), tales que $P(A)>0$. Denotemos por $P(B|A)$ la probabilidad de ocurrencia del evento $B$, condicionada a la ocurrencia previa del evento $A$. Puesto que sabemos que ocurrió $A$, es claro que dicho evento se convierte en el espacio muestral del evento $A|B$. Tiene sentido, por tanto, la siguiente definición.\n",
    "\n",
    "**<font color='blue'>Definición 5.2 – Probabilidad condicional:</font>** Sean $A$ y $B$ dos eventos tales que $P(A)>0$. Definimos la **probabilidad condicional** de ocurrencia de $B$, dado que previamente ocurrió $A$, denotada como $P(B|A)$, como\n",
    "\n",
    "$$P\\left( B|A\\right)  :=\\frac{P\\left( A\\cap B\\right)  }{P\\left( A\\right)}$$\n",
    "<p style=\"text-align: right;\">$(5.6)$</p>\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_5_3.png\" width=\"350\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (5.3): Diagrama de Venn que muestra los subconjuntos $A$ y $B$ de un espacio muestral $\\Omega$, remarcando su intersección</p>\n",
    "\n",
    "**Ejemplo 5.4:** Supongamos nuevamente que lanzamos un dado no cargado y simétrico. Vamos a determinar la probabilidad de que el resultado sea un número menor que 4, dado que previamente el mismo dado, tras lanzarlo, entregó un número impar.\n",
    "\n",
    "En efecto, sea $A$ el evento condicional relativo a que, al lanzar el dado, el resultado sea un número impar. Luego $P(A)=\\frac{1}{2}$. Por lo tanto, aplicando la fórmula de probabilidad condicional (5.6), obtenemos\n",
    "\n",
    "$$P\\left( B|A\\right)  =\\frac{P\\left( A\\cap B\\right)  }{P\\left( B\\right)  } =\\frac{1/3}{1/2} =\\frac{2}{3}$$\n",
    "<p style=\"text-align: right;\">$(5.7)$</p>\n",
    "\n",
    "Por lo tanto, la información empírica relativa a saber que nuestro dado previamente resultó en un número impar eleva las probabilidades de obtener un número menor que 4 a 2/3 (originalmente, sin ese conocimiento previo, dicha probabilidad era de 1/2). ︎◼︎\n",
    "\n",
    "La definición de probabilidad condicional permite enunciar los siguientes teoremas.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.2:</font>** *Sean $A_{1},A_{2}$ y $A_{3}$ tres eventos arbitrarios. Entonces tenemos que*\n",
    "\n",
    "$$P\\left( A_{1}\\cap A_{2}\\cap A_{3}\\right)  =P\\left( A_{1}\\right)  P\\left( A_{2}|A_{1}\\right)  P\\left( A_{3}|A_{1}\\cap A_{2}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.8)$</p>\n",
    "◆\n",
    "\n",
    "**<font color='crimson'>Teorema 5.3 – Regla de la suma:</font>** *Si un evento $A$ debe originar uno de los eventos mutuamente excluyentes $A_{1},...,A_{n}$, entonces tenemos que*\n",
    "\n",
    "$$P\\left( A\\right)  =\\sum^{n}_{k=1} P\\left( A_{k}\\right)  P\\left( A|A_{k}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.9)$</p>\n",
    "◆\n",
    "\n",
    "**<font color='blue'>Definición 5.3 – Eventos independientes:</font>** Sean $A$ y $B$ dos eventos con probabilidades de ocurrencia $P(A)$ y $P(B)$, respectivamente. Diremos que $A$ y $B$ son **eventos independientes** si se cumple que $P(B|A)=P(B)$. Esto equivale a decir que $P(A\\cap B)=P(A)P(B)$. Más aun, la colección de eventos $A_{1},...,A_{n}$ será llamada **colección de eventos independientes** si cada una de las parejas $(A_{i},A_{j})$ es independiente (para $i\\neq j$). En este caso, se tiene que\n",
    "\n",
    "$$P\\left( \\bigcap^{n}_{k=1} A_{k}\\right)  =\\prod^{n}_{k=1} P\\left( A_{k}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.10)$</p>\n",
    "\n",
    "Los resultados anteriores nos permiten formular el siguiente teorema, el cual es un resultado importante de la teoría de probabilidad.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.4 – Regla del producto:</font>** *Sea $A_{1},...,A_{n}$ una colección de eventos mutuamente excluyentes cuya unión es el espacio muestral $\\Omega$ (es decir, al menos uno de los eventos de la colección tiene probabilidad no nula). Entonces, si $A$ es un evento arbitrario, se tiene que*\n",
    "\n",
    "$$P\\left( A_{k}|A\\right)  =\\frac{P\\left( A_{k}\\right)  P\\left( A|A_{k}\\right)  }{\\sum\\nolimits^{n}_{j=1} P\\left( A_{j}\\right)  P\\left( A|A_{j}\\right)  } \\  ;\\  1\\leq k\\leq n$$\n",
    "<p style=\"text-align: right;\">$(5.11)$</p>\n",
    "◆\n",
    "\n",
    "En términos más generales y menos matemáticos, el teorema de Bayes es de enorme relevancia puesto que vincula la probabilidad de $A$ dado $B$ con la probabilidad de $B$ dado $A$. Es decir, por ejemplo, que sabiendo la probabilidad de tener un dolor de cabeza dado que se tiene gripe, se podría saber (si se tiene algún dato más), la probabilidad de tener gripe si se tiene un dolor de cabeza. Este sencillo ejemplo permite ilustrar la alta relevancia del teorema (5.4) en cuestión para la ciencia en todas sus ramas, puesto que tiene vinculación íntima con la comprensión de la probabilidad de aspectos causales dados los efectos observados. Es decir, mientras tengamos **evidencia empírica** de la ocurrencia de un fenómeno, siempre podemos tener un cierto nivel de certidumbre en relación a la ocurrencia de otros fenómenos que, experimentalmente, sabemos que están relacionados con el primero.\n",
    "\n",
    "El teorema (5.4) es válido en todas las aplicaciones de la teoría de la probabilidad. Sin embargo, hay una controversia sobre el tipo de probabilidades que emplea. En esencia, los seguidores de la estadística tradicional solo admiten probabilidades basadas en **experimentos repetibles** y que tengan una **confirmación empírica** mientras que los llamados **estadísticos Bayesianos** permiten **probabilidades subjetivas**. El teorema (5.4) puede servir entonces para indicar cómo debemos modificar nuestras probabilidades subjetivas cuando recibimos información adicional de un experimento. La **estadística Bayesiana** está demostrando su utilidad en ciertas estimaciones basadas en el conocimiento subjetivo a priori y el hecho de permitir revisar esas estimaciones en función de la evidencia empírica es lo que está abriendo nuevas formas de hacer conocimiento. Una aplicación de esto son los **clasificadores Bayesianos** que son frecuentemente usados en implementaciones de filtros de correo basura o spam, que se adaptan con el uso. Otra aplicación se encuentra en la fusión de datos, combinando información expresada en términos de densidad de probabilidad proveniente de distintos sensores. Es decir, la estadística Bayesiana resulta esencial en la base de muchos procesos de inteligencia artificial que son comunes en los algoritmos de machine learning.\n",
    "\n",
    "**Ejemplo 5.5:** Consideremos una caja (que llamaremos $\\Omega_{1}$) que contiene 3 bolitas rojas y 2 bolitas azules. Otra caja (la caja $\\Omega_{2}$) contiene 2 bolitas rojas y 8 bolitas azules. Se define el siguiente experimento: Se lanza una moneda no trucada (es decir, cuyos resultados son equiprobables) y, si sale cara, se saca una bolita de la caja $\\Omega_{1}$ y, si se obtiene sello, se saca una bolita de la caja $\\Omega_{2}$. Vamos a resolver dos interrogantes:\n",
    "\n",
    "- **(I1):** Determinaremos la probabilidad de obtener una bolita roja.\n",
    "- **(I2):** Suponiendo que quien lanza la moneda no revela si obtiene cara o sello (de manera que no sabemos tampoco de qué caja se saca la bolita respectiva), y afirma que obtuvo una bolita roja, determinaremos la probabilidad de que haya escogido la caja $\\Omega_{1}$.\n",
    "\n",
    "En efecto, sea $R$ el evento definido por la obtención de una bolita roja, mientras que $\\Omega_{1}$ y $\\Omega_{2}$ describen los eventos que se escojan las cajas correspondientes. Dado que podemos obtener una bolita roja en ambas cajas, podemos aplicar la fórmula de probabilidad condicional de manera directa, obteniendo\n",
    "\n",
    "$$P\\left( R\\right)  =P\\left( \\Omega_{1} \\right)  P\\left( R|\\Omega_{1} \\right)  +P\\left( \\Omega_{2} \\right)  P\\left( R|\\Omega_{2} \\right)  =\\frac{1}{2} \\left( \\frac{3}{3+2} \\right)  +\\frac{1}{2} \\left( \\frac{2}{2+8} \\right)  =\\frac{2}{5}$$\n",
    "<p style=\"text-align: right;\">$(5.12)$</p>\n",
    "\n",
    "Para la pregunta **(I2)**, basta con aplicar el teorema de Bayes, lo que nos da\n",
    "\n",
    "$$P\\left( \\Omega_{1} |R\\right)  =\\frac{P\\left( \\Omega_{1} \\right)  P\\left( R|\\Omega_{1} \\right)  }{P\\left( \\Omega_{1} \\right)  P\\left( R|\\Omega_{1} \\right)  +P\\left( \\Omega_{2} \\right)  P\\left( R|\\Omega_{2} \\right)  } =\\frac{\\frac{1}{2} \\left( \\frac{3}{3+2} \\right)  }{\\frac{1}{2} \\left( \\frac{3}{3+2} \\right)  +\\frac{1}{2} \\left( \\frac{2}{2+8} \\right)  } =\\frac{3}{4}$$\n",
    "<p style=\"text-align: right;\">$(5.13)$</p>\n",
    "◼︎"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea73e806",
   "metadata": {},
   "source": [
    "## Teoría moderna de probabilidad.\n",
    "\n",
    "### Funciones de conjunto con aditividad finita.\n",
    "El área de una región en el plano $XY$, la longitud de una curva, o la masa de un sistema de partículas son números que miden la magnitud o contenido de un conjunto. Todas esas medidas tienen ciertas propiedades en común. Establecidas de forma abstracta, conducen a un concepto general llamado **función de conjunto con aditividad finita**. Más adelante redefiniremos la probabilidad como otro ejemplo de función de este tipo. Para preparar el camino, primero discutiremos algunas propiedades comunes para este tipo de funciones.\n",
    "\n",
    "Una función $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ cuyo dominio es una colección $\\mathcal{A}$ de conjuntos y cuyos valores son números reales, se llama **función de conjunto**. Si $A$ es un conjunto de la colección $\\mathcal{A}$, el valor de la función $f$ en $A$ se representa como $f(A)$. Tiene sentido por tanto la siguiente definición.\n",
    "\n",
    "**<font color='blue'>Definición 5.4 – Función de conjunto con aditividad finita:</font>** Una función de conjunto $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ se dice que es de **aditividad finita** si se cumple que\n",
    "\n",
    "$$f(A\\cup B)=f(A)+f(B)$$\n",
    "<p style=\"text-align: right;\">$(5.14)$</p>\n",
    "\n",
    "Siempre que $A$ y $B$ sean conjuntos disjuntos de $\\mathcal{A}$, tales que $A\\cup B\\in \\mathcal{A}$.\n",
    "\n",
    "El área, la longitud y la masa son ejemplos de este tipo de funciones. A continuación, discutiremos algunas consecuencias de la ecuación (5.14). En las aplicaciones corrientes, los conjuntos de $\\mathcal{A}$ son subconjuntos de un conjunto dado $\\Omega$, llamado **conjunto universal**. Es común tener que efectuar las operaciones de unión, intersección y complementación sobre los conjuntos de $\\mathcal{A}$. Para garantizar que $\\mathcal{A}$ es cerrado con respecto a estas operaciones impondremos una condición: $\\mathcal{A}$ debe ser un **álgebra Booleana**, la cual se define a continuación.\n",
    "\n",
    "**<font color='blue'>Definición 5.5 – Álgebra Booleana de conjuntos:</font>** Una clase no vacía $\\mathcal{A}$ de subconjuntos de un conjunto universal $\\Omega$ es llamada **álgebra Booleana** si, para todo par $A$ y $B$ de conjuntos de $\\mathcal{A}$, se tiene que\n",
    "\n",
    "$$A\\cup B\\in \\mathcal{A} \\wedge \\bar{A} \\in \\mathcal{A}$$\n",
    "<p style=\"text-align: right;\">$(5.15)$</p>\n",
    "\n",
    "Donde, como antes, $\\bar{A}$ denota al complemento de $A$ con respecto a $\\Omega$. Un álgebra Booleana también es cerrada para las intersecciones y diferencias simétricas, ya que $A\\cap B=\\overline{\\left( \\bar{A} \\cup \\bar{B} \\right)}$ y $A-B=A\\cap \\bar{B}$. Esto implica que el conjunto vacío $\\emptyset$ también pertenece a $\\mathcal{A}$, ya que $\\emptyset=A-A$ para algún $A$ de $\\mathcal{A}$. También el conjunto universal $\\Omega$ pertenece a $\\mathcal{A}$, puesto que $\\Omega=\\bar{\\emptyset}$.\n",
    "\n",
    "A partir de los subconjuntos de un conjunto universal dado $\\Omega$ es posible construir un gran número de álgebras Booleanas. La menor de esas álgebras es la clase $\\mathcal{A}_{0} =\\left\\{ \\emptyset ,\\Omega \\right\\}$ que consta únicamente de los conjuntos *triviales* $\\emptyset$ y $\\Omega$. En el otro extremo está la clase $\\mathcal{A}_{1}$, que consta de *todos* los subconjuntos de $\\Omega$. Toda álgebra Boleana construida con subconjuntos de $\\Omega$ satisface las **relaciones de inclusión** $\\mathcal{A}_{0} \\subseteq \\mathcal{A} \\subseteq \\mathcal{A}_{1}$.\n",
    "\n",
    "La propiedad de aditividad finita de las funciones de conjunto en la ecuación (5.14) exige que $A$ y $B$ sean conjuntos disjuntos. De esta exigencia se desprende el siguiente teorema.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.5:</font>** *Si $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ es una función de conjunto con aditividad finita sobre un álgebra Booleana $\\mathcal{A}$ de conjuntos, entonces, para todo par de conjuntos $A$ y $B$ de $\\mathcal{A}$, tenemos que*\n",
    "\n",
    "$$f\\left( A\\cap B\\right)  =f\\left( A\\right)  +f\\left( B-A\\right)  \\wedge f\\left( A\\cup B\\right)  =f\\left( A\\right)  +f\\left( B\\right)  -f\\left( A\\cap B\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.16)$</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abce68e2",
   "metadata": {},
   "source": [
    "### Medidas con aditividad finita.\n",
    "Las funciones de conjunto que representan áreas, longitudes y masas poseen propiedades comunes. Por ejemplo, todas estas funciones son no negativas; es decir, $f(A)\\geq 0$ para cada conjunto $A$ de la clase $\\mathcal{A}$ que se considera. Esto motiva la siguiente definición.\n",
    "\n",
    "**<font color='blue'>Definición 5.6 – Medida con aditividad finita:</font>** Una función de conjunto no negativa $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ que es con aditividad finita es llamada **medida con aditividad finita** o, simplemente, una medida.\n",
    "\n",
    "Aplicando el teorema (5.5) a la definición (5.6), obtenemos inmediatamente las siguientes propiedades, descritas en el teorema (5.6).\n",
    "\n",
    "**<font color='crimson'>Teorema 5.6:</font>** *Sea $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ una medida con aditividad finita definida sobre un álgebra Booleana $\\mathcal{A}$. Para cualquier par de conjuntos $A$ y $B$ de $\\mathcal{A}$, se cumplen las siguientes propiedades:*\n",
    "\n",
    "- **(P1):** $f\\left( A\\cup B\\right)  \\leq f\\left( A\\right)  +f\\left( B\\right)$.\n",
    "- **(P2):** $f\\left( B-A\\right)  =f\\left( B\\right)  -f\\left( A\\right)  \\Longleftrightarrow A\\subseteq B$.\n",
    "- **(P3):** $f\\left( A\\right)  \\leq f\\left( B\\right)  \\Longleftrightarrow A\\subseteq B$.\n",
    "- **(P4):** $f\\left( \\emptyset \\right)  =0$.\n",
    "◆"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
