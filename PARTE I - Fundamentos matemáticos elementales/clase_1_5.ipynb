{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b09f5ce4",
   "metadata": {},
   "source": [
    "# CLASE 1.5: Una introducción (generosa) al cálculo de probabilidades\n",
    "---\n",
    "\n",
    "## Introducción.\n",
    "La probabilidad, en términos bien generales, se corresponde con el estudio de la incertidumbre. Puede ser pensada como la fracción de tiempo en el cual un evento determinado ocurre, o como el grado de creencia bajo el cual un evento puede ocurrir. Queremos usar la probabilidad como medida de la posibilidad en que un suceso ocurre en un experimento determinado. Esta idea es esencial en los modelos de machine learning, puesto que con frecuencia queremos entender cuánto nivel de incertidumbre hay en nuestra data o en la predicción realizada por un modelo determinado. La cuantificación de la incertidumbre requiere de objetos matemáticos especializados conocidos como **variables aleatorias**, las cuales corresponden a funciones que mapean los resultados de experimentos aleatorios sobre los conjuntos de propiedades que nos interesan. Hay funciones asociadas a las variables aleatorias que permiten medir la probabilidad de que un resultado particular (o un conjunto de resultados) ocurra(n). Tales funciones se conocen como **distribuciones de probabilidad**.\n",
    "\n",
    "Las distribuciones de probabilidad son utilizadas como cimientos para la construcción de otros conceptos, tales como modelos probabilísticos, modelos gráficos y selección de modelos. En esta sección, presentaremos los conceptos necesarios para poder definir una probabilidad y cómo estos se relacionan para la construcción de una variable aleatoria, a fin de poder entender constructos más generales, tales como densidades y distribuciones.\n",
    "\n",
    "## Teoría clásica de probabilidad.\n",
    "\n",
    "### El concepto de probabilidad.\n",
    "Todos estamos familiarizados con la importancia de los experimentos en ciencias e ingeniería. La experimentación es útil porque, si suponemos que llevamos a cabo ciertos experimentos bajo condiciones esencialmente idénticas (algo especialmente cierto en pruebas industriales de algún componente, por ejemplo, un sistema de medición de perfil de cascada de mineral en un molino SAG), llegaremos (o deberíamos llegar) a los mismos resultados. En estas circunstancias, estamos en condiciones de controlar el valor de las variables que afectan el resultado del experimento.\n",
    "\n",
    "Sin embargo, en algunos experimentos, no somos capaces de controlar el valor de determinadas variables, de manera que un resultado cambiará de un experimento a otro, a pesar de que la mayoría de las condiciones sean las mismas. Estos experimentos se describen como aleatorios, porque existe una determinada (y muchas veces razonable) cantidad de incertidumbre inherente a ellos. Por ejemplo, si lanzamos un dado (no cargado y simétrico), el resultado del experimento será uno de los números del conjunto $\\Omega =\\left\\{ 1,2,3,4,5,6\\right\\}$. Un ejemplo un poco más industrial es la medición de la vida útil de fusibles producidos por una compañía manufacturadora de estos artefactos eléctricos. Entonces, el resultado del experimento es el tiempo $t$ en horas que se encuentra en algún intervalo, digamos $0\\leq t\\leq 6500$, suponiendo que la vida útil del fusible tiene un límite técnico de 6500 horas de uso.\n",
    "\n",
    "Un conjunto $\\Omega$ que consta de todos los resultados posibles de un experimento aleatorio es llamado espacio muestral, y cada resultado se denomina punto muestral. Con frecuencia habrá más de un espacio muestral que puede describir los resultados de un experimento, pero generalmente habrá uno que provee la mayor cantidad de información.\n",
    "\n",
    "**Ejemplo 5.1:** Consideremos el experimento de lanzar dos veces una moneda. Sea 0 el resultado que describe la obtención de un sello, y 1 el resultado que describe la obtención de una cara. El espacio muestral asociado a este experimento se ilustra en la Fig. (5.1), donde, por ejemplo, el par (0, 1) representa que, en el primer lanzamiento, obtenemos un sello, y en el segundo, una cara. ◼︎\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_5_1.png\" width=\"450\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (5.1): Una representación gráfica del espacio muestral relativo al experimento de lanzar una moneda (no trucada) </p>\n",
    "\n",
    "Si un espacio muestral tiene un numero finito de puntos muestrales, como en el ejemplo (5.1), se llamará **espacio muestral finito**. Si tiene un total de $n$ puntos, con $n\\in \\mathbb{N}$, siendo $n$ un valor no determinado, será llamado **espacio muestral infinito numerable** o **contable**. Si tiene un número indeterminado de puntos, no necesariamente equidistantes en relación a una referencia (por ejemplo, tantos puntos como los existentes en el intervalo $[a,b]$), será llamado **espacio muestral infinito no numerable**.\n",
    "\n",
    "Con frecuencia, si un espacio muestral $\\Omega$ es finito o infinito numerable, se habla de un **espacio muestral discreto**. Por otro lado, si $\\Omega$ es infinito no numerable, suele ser denominado como **espacio muestral continuo**.\n",
    "\n",
    "Un **evento** es un subconjunto $A$ del espacio muestral $\\Omega$. Es decir, un conjunto de resultados posibles. Si el resultado de un experimento es un elemento de $A$, decimos que **el evento $A$ ocurrió**. Un evento que consta de un punto sencillo de $\\Omega$ se denomina, con frecuencia, un **evento simple o elemental**.\n",
    "\n",
    "**Ejemplo 5.2:** Si lanzamos una moneda dos veces, el evento relativo a que sólo salga una cara es un subconjunto del espacio muestral y que consta únicamente de los puntos $(0, 1)$ y $(1, 0)$, tal y como se ilustra en la Fig. (5.2). ◼︎\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_5_2.png\" width=\"450\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (5.2): Una representación gráfica del espacio muestral relativo al experimento descrito en el ejemplo (5.2)</p>\n",
    "\n",
    "Como eventos particulares tenemos al mismo espacio muestral $\\Omega$, el cual se conoce como **evento seguro** o **cierto**, dado que un elemento de $\\Omega$ debe ocurrir sí o sí. Por otro lado, el conjunto vacío $\\emptyset$ se denomina **evento imposible**, debido a que no es factible que éste ocurra. Usando operaciones lógicas (que son también válidas para el álgebra de conjuntos), podemos definir otros eventos de $\\Omega$. Por ejemplo, si $A$ y $B$ son eventos, entonces podemos definir:\n",
    "\n",
    "- **(C1):** $A\\cap B$ corresponde a la **conjunción** de los eventos $A$ y $B$. Denota al evento compuesto por la ocurrencia simultánea de $A$ y $B$. En lógica matemática, la conjunción se suele escribir como $A\\wedge B$ y se corresponde con la operación lógica “Y” (`and` o `&` en Python).\n",
    "- **(C2):** $A\\cup B$ corresponde a la **disyunción** de los eventos $A$ y $B$. Denota el evento compuesto por la ocurrencia de $A$, o bien, de $B$. En lógica matemática, la disyunción se suele escribir como $A\\vee B$ y se corresponde con la operación lógica “O” (`or` o `|` en Python).\n",
    "- **(C3):** $\\bar{A}$ s el **evento complementario** a $A$. Denota el evento que describe la no ocurrencia de $A$. En lógica matemática, el complemento se corresponde con la operación lógica de negación denotada como “NO” (`not` o `~` en Python). También suele denotarse como $\\sim A$.\n",
    "- **(C4):** $A-B=A\\cap \\bar{B}$ describe la **diferencia simétrica** de los eventos $A$ y $B$. Describe al evento que consiste en la ocurrencia de $A$ y la no ocurrencia de $B$. En particular, observamos que $\\bar{A}=\\Omega -A$, donde $\\Omega$ es el espacio muestral.\n",
    "\n",
    "Si los conjuntos que describen a $A$ y $B$ son **disjuntos** (es decir, $A\\cap B=\\emptyset$), decimos que los eventos $A$ y $B$ son **mutuamente excluyentes**. En la práctica, esto significa que no pueden ocurrir simultáneamente. Una colección $A_{1},...,A_{n}$ de eventos es mutuamente excluyente si cada par $(A_{i},A_{j})$ de la colección (para $i\\neq j$) es mutuamente excluyente.\n",
    "\n",
    "En cualquier experimento aleatorio, hay siempre incertidumbre sobre si ocurrirá un evento en particular. Como una medida de la probabilidad con que esperamos que ocurra cierto evento, es conveniente asignar un número entre 0 y 1. Si estamos seguros de que tal evento ocurrirá, decimos que la **probabilidad** de dicho evento es 1 (o, equivalentemente, del 100%). Si estamos seguros de que tal evento no ocurrirá, la probabilidad de dicho evento es 0 (o del 0%).\n",
    "\n",
    "La probabilidad así definida permite además definir la **probabilidad del complemento** de un evento. De esta manera, si un evento tiene una probabilidad de $\\frac{1}{4}$ (o del 25%), entonces la diferencia $1-\\frac{1}{4}=\\frac{3}{4}$ (o 75%) será la probabilidad del complemento de dicho evento (es decir, la probabilidad de que no ocurra). Existen varias formas, en la teoría clásica, de definir una probabilidad. En primera instancia, tenemos un **enfoque clásico**, que establece que si un evento puede ocurrir de $k$ formas diferentes de un total de $n$, todas igualmente posibles (es decir, **equiprobables**), entonces la probabilidad del evento es igual a $\\frac{k}{n}$. Si $A$ es tal evento, entonces escribimos $P(A)=\\frac{k}{n}$.\n",
    "\n",
    "Existe también un **enfoque frecuentista** que permite definir la probabilidad en un contexto más empírico. De esta manera, si después de $n$ repeticiones de un experimento, donde $n$ es un número muy grande, se observa que un evento ocurre $k$ veces, entonces la probabilidad de dicho evento es igual a $\\frac{k}{n}$. Al respecto, una probabilidad definida de esta manera suele denominarse **probabilidad empírica** del evento.\n",
    "\n",
    "Ambos enfoques presentan serios inconvenientes. El clásico debido a que la frase “igualmente probable” es una situación que se describe vagamente; y el frecuentista, porque un “número grande” es igualmente vago. Debido a estas dificultades, la definición de probabilidad se hace en base a ciertos enunciados conocidos formalmente como **axiomas de probabilidad**.\n",
    "\n",
    "**<font color='blue'>Definición 5.1 – Probabilidad:</font>** Supongamos que tenemos un espacio muestral $\\Omega$. Si $\\Omega$ es discreto, todos los subconjuntos corresponden a eventos y viceversa, pero si $\\Omega$ no es discreto, sólo los subconjuntos *medibles* corresponden a eventos. Para cada evento $A$ en la clase $C$ de eventos (siendo $C$ un subconjunto como el descrito previamente), asociamos un número $P(A)\\in \\mathbb{R}$. Entonces $P$ se denomina **función de probabilidad** y $P(A)$ la probabilidad asociada al evento $A$, si se cumplen los siguientes axiomas:\n",
    "\n",
    "- **(A1):** Para cada evento $A$ en la clase $C$, se tiene que $P(A)\\geq 0$.\n",
    "- **(A2):** Para el evento seguro $\\Omega$ en la clase $C$, se tiene que $P(\\Omega)=1$.\n",
    "- **(A3):** Para cualquier número de eventos mutuamente excluyentes, digamos $A_{1},...,A_{n}$, en la clase $C$, se tiene que $P\\left( \\bigcup^{n}_{k=1} A_{k}\\right)  =\\sum^{n}_{k=1} P\\left( A_{k}\\right)$.\n",
    "\n",
    "A partir de los axiomas de probabilidad, es posible agrupar una serie de resultados importantes e inmediatos relativos a la definición de probabilidad. Todos estos resultados los agrupamos en términos del siguiente teorema.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.1:</font>** *Sea $\\Omega$ un espacio muestral y $\\left\\{ A_{k}\\right\\}^{n}_{k=1}$ una colección de eventos de $\\Omega$. Entonces tenemos que:*\n",
    "\n",
    "- **(T1):** *Si $A_{i}\\subset A_{j}$, entonces $P(A_{i})\\leq P(A_{j})$ y $P(A_{j}-A_{i})=P(A_{j})-P(A_{i})$.*\n",
    "- **(T2):** *Para todo evento $A_{k}\\subset \\Omega$, se tiene que $0\\leq P(A_{k})\\leq 1$. Es decir, la probabilidad de un evento tiene un valor entre 0 y 1.*\n",
    "- **(T3):** $P(\\emptyset)=0$. *Es decir, el evento imposible tiene probabilidad nula.*\n",
    "- **(T4):** *Si $\\bar{A}$ es el complemento de $A$, entonces se tiene que $P(\\bar{A})=1-P(A)$.*\n",
    "- **(T5):** *Si $A=\\bigcup^{n}_{k=1} A_{k}$, donde $A_{1},...,A_{n}$ son eventos mutuamente excluyentes, entonces $P\\left( A\\right)  =\\sum^{n}_{k=1} P\\left( A_{k}\\right)$. En particular, si $A=\\Omega$, entonces $P(\\Omega)=1$.*\n",
    "- **(T6):** *Si $A$ y $B$ son dos eventos cualesquiera, entonces $P(A\\cup B)=P(A)+P(B)-P(A\\cap B)$. De forma más general, para la colección $\\left\\{ A_{k}\\right\\}^{n}_{k=1}$, si los eventos de dicha colección son todos arbitrarios, se tiene que*\n",
    "\n",
    "$$P\\left( \\bigcup^{n}_{k=1} A_{k}\\right)  =\\sum^{n}_{k=1} P\\left( A_{k}\\right)  -\\sum_{i,j:1\\leq i\\leq j\\leq n} P\\left( A_{i}\\cap A_{j}\\right)  +\\sum_{i,j,k:1\\leq i\\leq j\\leq k\\leq n} P\\left( A_{i}\\cap A_{j}\\cap A_{k}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.1)$</p>\n",
    "\n",
    "- **(T7):** *Para cualesquiera eventos $A$ y $B$, se tiene que $P(A)=P(A\\cap B)+P(A\\cap \\bar{B})$*.\n",
    "- **(T8):** *Si un evento $A$ debe dar como resultado la ocurrencia de uno de los eventos mutuamente excluyentes $A_{1},...,A_{n}$, entonces tenemos que*\n",
    "\n",
    "$$P\\left( A_{k}\\right)  =\\sum^{n}_{k=1} P\\left( A\\cap A_{k}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.2)$</p>\n",
    "◆"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25bc696",
   "metadata": {},
   "source": [
    "### Asignación de probabilidades.\n",
    "Si un espacio muestral $\\Omega$ consta de un número finito de resultados $a_{1},...,a_{n}$, entonces, conforme **(T5)**, tenemos que $P(A_{1})+\\cdots +P(A_{n})=1$, donde $A_{1},...,A_{n}$ es una colección de eventos elementales tales que $A_{i}=\\left\\{ a_{i}\\right\\}$. Entonces podemos escoger arbitrariamente cualquier número no negativo para las probabilidades de esos eventos sencillos siempre y cuando se satisfaga la ecuación (5.2). En particular, si suponemos que hay probabilidades iguales para todos esos eventos sencillos, entonces se tendrá que\n",
    "\n",
    "$$P\\left( A_{k}\\right)  =\\frac{1}{k} \\  ;\\  k=1,...,n$$\n",
    "<p style=\"text-align: right;\">$(5.3)$</p>\n",
    "\n",
    "Si $A$ es un conjunto conformado por $h$ eventos sencillos, entonces se tendrá que\n",
    "\n",
    "$$P\\left( A\\right)  =\\frac{h}{n}$$\n",
    "<p style=\"text-align: right;\">$(5.4)$</p>\n",
    "\n",
    "que equivale a la fórmula clásica de probabilidad vista al inicio de esta sección.\n",
    "\n",
    "**Ejemplo 5.3:** Supongamos que se lanza un dado no cargado y simétrico una sola vez. Calcularemos la probabilidad de obtener un 2 o un 5 en dicho lanzamiento. En efecto, el espacio muestral de este experimento corresponde al conjunto finito $\\Omega =\\left\\{ 1,2,3,4,5,6\\right\\}$. Si asignamos probabilidades iguales a cada uno de los puntos muestrales (lo que desde luego es válido, puesto que hemos supuesto que el dado no está cargado y es completamente simétrico), entonces\n",
    "\n",
    "$$P\\left( 1\\right)  =P\\left( 2\\right)  =\\cdots =P\\left( 6\\right)  =\\frac{1}{6}$$\n",
    "<p style=\"text-align: right;\">$(5.5)$</p>\n",
    "\n",
    "Por lo tanto, la probabilidad buscada es $P(2\\cup 5)=P(2)+P(5)=1/3$. ◼"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7632a9e",
   "metadata": {},
   "source": [
    "### Probabilidad condicional.\n",
    "Sean $A$ y $B$ dos eventos ilustrados en el diagrama de Venn de la Fig. (5.3), tales que $P(A)>0$. Denotemos por $P(B|A)$ la probabilidad de ocurrencia del evento $B$, condicionada a la ocurrencia previa del evento $A$. Puesto que sabemos que ocurrió $A$, es claro que dicho evento se convierte en el espacio muestral del evento $A|B$. Tiene sentido, por tanto, la siguiente definición.\n",
    "\n",
    "**<font color='blue'>Definición 5.2 – Probabilidad condicional:</font>** Sean $A$ y $B$ dos eventos tales que $P(A)>0$. Definimos la **probabilidad condicional** de ocurrencia de $B$, dado que previamente ocurrió $A$, denotada como $P(B|A)$, como\n",
    "\n",
    "$$P\\left( B|A\\right)  :=\\frac{P\\left( A\\cap B\\right)  }{P\\left( A\\right)}$$\n",
    "<p style=\"text-align: right;\">$(5.6)$</p>\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_5_3.png\" width=\"350\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (5.3): Diagrama de Venn que muestra los subconjuntos $A$ y $B$ de un espacio muestral $\\Omega$, remarcando su intersección</p>\n",
    "\n",
    "**Ejemplo 5.4:** Supongamos nuevamente que lanzamos un dado no cargado y simétrico. Vamos a determinar la probabilidad de que el resultado sea un número menor que 4, dado que previamente el mismo dado, tras lanzarlo, entregó un número impar.\n",
    "\n",
    "En efecto, sea $A$ el evento condicional relativo a que, al lanzar el dado, el resultado sea un número impar. Luego $P(A)=\\frac{1}{2}$. Por lo tanto, aplicando la fórmula de probabilidad condicional (5.6), obtenemos\n",
    "\n",
    "$$P\\left( B|A\\right)  =\\frac{P\\left( A\\cap B\\right)  }{P\\left( B\\right)  } =\\frac{1/3}{1/2} =\\frac{2}{3}$$\n",
    "<p style=\"text-align: right;\">$(5.7)$</p>\n",
    "\n",
    "Por lo tanto, la información empírica relativa a saber que nuestro dado previamente resultó en un número impar eleva las probabilidades de obtener un número menor que 4 a 2/3 (originalmente, sin ese conocimiento previo, dicha probabilidad era de 1/2). ︎◼︎\n",
    "\n",
    "La definición de probabilidad condicional permite enunciar los siguientes teoremas.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.2:</font>** *Sean $A_{1},A_{2}$ y $A_{3}$ tres eventos arbitrarios. Entonces tenemos que*\n",
    "\n",
    "$$P\\left( A_{1}\\cap A_{2}\\cap A_{3}\\right)  =P\\left( A_{1}\\right)  P\\left( A_{2}|A_{1}\\right)  P\\left( A_{3}|A_{1}\\cap A_{2}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.8)$</p>\n",
    "◆\n",
    "\n",
    "**<font color='crimson'>Teorema 5.3 – Regla de la suma:</font>** *Si un evento $A$ debe originar uno de los eventos mutuamente excluyentes $A_{1},...,A_{n}$, entonces tenemos que*\n",
    "\n",
    "$$P\\left( A\\right)  =\\sum^{n}_{k=1} P\\left( A_{k}\\right)  P\\left( A|A_{k}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.9)$</p>\n",
    "◆\n",
    "\n",
    "**<font color='blue'>Definición 5.3 – Eventos independientes:</font>** Sean $A$ y $B$ dos eventos con probabilidades de ocurrencia $P(A)$ y $P(B)$, respectivamente. Diremos que $A$ y $B$ son **eventos independientes** si se cumple que $P(B|A)=P(B)$. Esto equivale a decir que $P(A\\cap B)=P(A)P(B)$. Más aun, la colección de eventos $A_{1},...,A_{n}$ será llamada **colección de eventos independientes** si cada una de las parejas $(A_{i},A_{j})$ es independiente (para $i\\neq j$). En este caso, se tiene que\n",
    "\n",
    "$$P\\left( \\bigcap^{n}_{k=1} A_{k}\\right)  =\\prod^{n}_{k=1} P\\left( A_{k}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.10)$</p>\n",
    "\n",
    "Los resultados anteriores nos permiten formular el siguiente teorema, el cual es un resultado importante de la teoría de probabilidad.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.4 – Regla del producto:</font>** *Sea $A_{1},...,A_{n}$ una colección de eventos mutuamente excluyentes cuya unión es el espacio muestral $\\Omega$ (es decir, al menos uno de los eventos de la colección tiene probabilidad no nula). Entonces, si $A$ es un evento arbitrario, se tiene que*\n",
    "\n",
    "$$P\\left( A_{k}|A\\right)  =\\frac{P\\left( A_{k}\\right)  P\\left( A|A_{k}\\right)  }{\\sum\\nolimits^{n}_{j=1} P\\left( A_{j}\\right)  P\\left( A|A_{j}\\right)  } \\  ;\\  1\\leq k\\leq n$$\n",
    "<p style=\"text-align: right;\">$(5.11)$</p>\n",
    "◆\n",
    "\n",
    "En términos más generales y menos matemáticos, el teorema de Bayes es de enorme relevancia puesto que vincula la probabilidad de $A$ dado $B$ con la probabilidad de $B$ dado $A$. Es decir, por ejemplo, que sabiendo la probabilidad de tener un dolor de cabeza dado que se tiene gripe, se podría saber (si se tiene algún dato más), la probabilidad de tener gripe si se tiene un dolor de cabeza. Este sencillo ejemplo permite ilustrar la alta relevancia del teorema (5.4) en cuestión para la ciencia en todas sus ramas, puesto que tiene vinculación íntima con la comprensión de la probabilidad de aspectos causales dados los efectos observados. Es decir, mientras tengamos **evidencia empírica** de la ocurrencia de un fenómeno, siempre podemos tener un cierto nivel de certidumbre en relación a la ocurrencia de otros fenómenos que, experimentalmente, sabemos que están relacionados con el primero.\n",
    "\n",
    "El teorema (5.4) es válido en todas las aplicaciones de la teoría de la probabilidad. Sin embargo, hay una controversia sobre el tipo de probabilidades que emplea. En esencia, los seguidores de la estadística tradicional solo admiten probabilidades basadas en **experimentos repetibles** y que tengan una **confirmación empírica** mientras que los llamados **estadísticos Bayesianos** permiten **probabilidades subjetivas**. El teorema (5.4) puede servir entonces para indicar cómo debemos modificar nuestras probabilidades subjetivas cuando recibimos información adicional de un experimento. La **estadística Bayesiana** está demostrando su utilidad en ciertas estimaciones basadas en el conocimiento subjetivo a priori y el hecho de permitir revisar esas estimaciones en función de la evidencia empírica es lo que está abriendo nuevas formas de hacer conocimiento. Una aplicación de esto son los **clasificadores Bayesianos** que son frecuentemente usados en implementaciones de filtros de correo basura o spam, que se adaptan con el uso. Otra aplicación se encuentra en la fusión de datos, combinando información expresada en términos de densidad de probabilidad proveniente de distintos sensores. Es decir, la estadística Bayesiana resulta esencial en la base de muchos procesos de inteligencia artificial que son comunes en los algoritmos de machine learning.\n",
    "\n",
    "**Ejemplo 5.5:** Consideremos una caja (que llamaremos $\\Omega_{1}$) que contiene 3 bolitas rojas y 2 bolitas azules. Otra caja (la caja $\\Omega_{2}$) contiene 2 bolitas rojas y 8 bolitas azules. Se define el siguiente experimento: Se lanza una moneda no trucada (es decir, cuyos resultados son equiprobables) y, si sale cara, se saca una bolita de la caja $\\Omega_{1}$ y, si se obtiene sello, se saca una bolita de la caja $\\Omega_{2}$. Vamos a resolver dos interrogantes:\n",
    "\n",
    "- **(I1):** Determinaremos la probabilidad de obtener una bolita roja.\n",
    "- **(I2):** Suponiendo que quien lanza la moneda no revela si obtiene cara o sello (de manera que no sabemos tampoco de qué caja se saca la bolita respectiva), y afirma que obtuvo una bolita roja, determinaremos la probabilidad de que haya escogido la caja $\\Omega_{1}$.\n",
    "\n",
    "En efecto, sea $R$ el evento definido por la obtención de una bolita roja, mientras que $\\Omega_{1}$ y $\\Omega_{2}$ describen los eventos que se escojan las cajas correspondientes. Dado que podemos obtener una bolita roja en ambas cajas, podemos aplicar la fórmula de probabilidad condicional de manera directa, obteniendo\n",
    "\n",
    "$$P\\left( R\\right)  =P\\left( \\Omega_{1} \\right)  P\\left( R|\\Omega_{1} \\right)  +P\\left( \\Omega_{2} \\right)  P\\left( R|\\Omega_{2} \\right)  =\\frac{1}{2} \\left( \\frac{3}{3+2} \\right)  +\\frac{1}{2} \\left( \\frac{2}{2+8} \\right)  =\\frac{2}{5}$$\n",
    "<p style=\"text-align: right;\">$(5.12)$</p>\n",
    "\n",
    "Para la pregunta **(I2)**, basta con aplicar el teorema de Bayes, lo que nos da\n",
    "\n",
    "$$P\\left( \\Omega_{1} |R\\right)  =\\frac{P\\left( \\Omega_{1} \\right)  P\\left( R|\\Omega_{1} \\right)  }{P\\left( \\Omega_{1} \\right)  P\\left( R|\\Omega_{1} \\right)  +P\\left( \\Omega_{2} \\right)  P\\left( R|\\Omega_{2} \\right)  } =\\frac{\\frac{1}{2} \\left( \\frac{3}{3+2} \\right)  }{\\frac{1}{2} \\left( \\frac{3}{3+2} \\right)  +\\frac{1}{2} \\left( \\frac{2}{2+8} \\right)  } =\\frac{3}{4}$$\n",
    "<p style=\"text-align: right;\">$(5.13)$</p>\n",
    "◼︎"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d66f394e",
   "metadata": {},
   "source": [
    "## Teoría moderna de probabilidad.\n",
    "\n",
    "### Funciones de conjunto con aditividad finita.\n",
    "El área de una región en el plano $XY$, la longitud de una curva, o la masa de un sistema de partículas son números que miden la magnitud o contenido de un conjunto. Todas esas medidas tienen ciertas propiedades en común. Establecidas de forma abstracta, conducen a un concepto general llamado **función de conjunto con aditividad finita**. Más adelante redefiniremos la probabilidad como otro ejemplo de función de este tipo. Para preparar el camino, primero discutiremos algunas propiedades comunes para este tipo de funciones.\n",
    "\n",
    "Una función $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ cuyo dominio es una colección $\\mathcal{A}$ de conjuntos y cuyos valores son números reales, se llama **función de conjunto**. Si $A$ es un conjunto de la colección $\\mathcal{A}$, el valor de la función $f$ en $A$ se representa como $f(A)$. Tiene sentido por tanto la siguiente definición.\n",
    "\n",
    "**<font color='blue'>Definición 5.4 – Función de conjunto con aditividad finita:</font>** Una función de conjunto $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ se dice que es de **aditividad finita** si se cumple que\n",
    "\n",
    "$$f(A\\cup B)=f(A)+f(B)$$\n",
    "<p style=\"text-align: right;\">$(5.14)$</p>\n",
    "\n",
    "Siempre que $A$ y $B$ sean conjuntos disjuntos de $\\mathcal{A}$, tales que $A\\cup B\\in \\mathcal{A}$.\n",
    "\n",
    "El área, la longitud y la masa son ejemplos de este tipo de funciones. A continuación, discutiremos algunas consecuencias de la ecuación (5.14). En las aplicaciones corrientes, los conjuntos de $\\mathcal{A}$ son subconjuntos de un conjunto dado $\\Omega$, llamado **conjunto universal**. Es común tener que efectuar las operaciones de unión, intersección y complementación sobre los conjuntos de $\\mathcal{A}$. Para garantizar que $\\mathcal{A}$ es cerrado con respecto a estas operaciones impondremos una condición: $\\mathcal{A}$ debe ser un **álgebra Booleana**, la cual se define a continuación.\n",
    "\n",
    "**<font color='blue'>Definición 5.5 – Álgebra Booleana de conjuntos:</font>** Una clase no vacía $\\mathcal{A}$ de subconjuntos de un conjunto universal $\\Omega$ es llamada **álgebra Booleana** si, para todo par $A$ y $B$ de conjuntos de $\\mathcal{A}$, se tiene que\n",
    "\n",
    "$$A\\cup B\\in \\mathcal{A} \\wedge \\bar{A} \\in \\mathcal{A}$$\n",
    "<p style=\"text-align: right;\">$(5.15)$</p>\n",
    "\n",
    "Donde, como antes, $\\bar{A}$ denota al complemento de $A$ con respecto a $\\Omega$. Un álgebra Booleana también es cerrada para las intersecciones y diferencias simétricas, ya que $A\\cap B=\\overline{\\left( \\bar{A} \\cup \\bar{B} \\right)}$ y $A-B=A\\cap \\bar{B}$. Esto implica que el conjunto vacío $\\emptyset$ también pertenece a $\\mathcal{A}$, ya que $\\emptyset=A-A$ para algún $A$ de $\\mathcal{A}$. También el conjunto universal $\\Omega$ pertenece a $\\mathcal{A}$, puesto que $\\Omega=\\bar{\\emptyset}$.\n",
    "\n",
    "A partir de los subconjuntos de un conjunto universal dado $\\Omega$ es posible construir un gran número de álgebras Booleanas. La menor de esas álgebras es la clase $\\mathcal{A}_{0} =\\left\\{ \\emptyset ,\\Omega \\right\\}$ que consta únicamente de los conjuntos *triviales* $\\emptyset$ y $\\Omega$. En el otro extremo está la clase $\\mathcal{A}_{1}$, que consta de *todos* los subconjuntos de $\\Omega$. Toda álgebra Boleana construida con subconjuntos de $\\Omega$ satisface las **relaciones de inclusión** $\\mathcal{A}_{0} \\subseteq \\mathcal{A} \\subseteq \\mathcal{A}_{1}$.\n",
    "\n",
    "La propiedad de aditividad finita de las funciones de conjunto en la ecuación (5.14) exige que $A$ y $B$ sean conjuntos disjuntos. De esta exigencia se desprende el siguiente teorema.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.5:</font>** *Si $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ es una función de conjunto con aditividad finita sobre un álgebra Booleana $\\mathcal{A}$ de conjuntos, entonces, para todo par de conjuntos $A$ y $B$ de $\\mathcal{A}$, tenemos que*\n",
    "\n",
    "$$f\\left( A\\cap B\\right)  =f\\left( A\\right)  +f\\left( B-A\\right)  \\wedge f\\left( A\\cup B\\right)  =f\\left( A\\right)  +f\\left( B\\right)  -f\\left( A\\cap B\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.16)$</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2aee4b39",
   "metadata": {},
   "source": [
    "### Medidas con aditividad finita.\n",
    "Las funciones de conjunto que representan áreas, longitudes y masas poseen propiedades comunes. Por ejemplo, todas estas funciones son no negativas; es decir, $f(A)\\geq 0$ para cada conjunto $A$ de la clase $\\mathcal{A}$ que se considera. Esto motiva la siguiente definición.\n",
    "\n",
    "**<font color='blue'>Definición 5.6 – Medida con aditividad finita:</font>** Una función de conjunto no negativa $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ que es con aditividad finita es llamada **medida con aditividad finita** o, simplemente, una medida.\n",
    "\n",
    "Aplicando el teorema (5.5) a la definición (5.6), obtenemos inmediatamente las siguientes propiedades, descritas en el teorema (5.6).\n",
    "\n",
    "**<font color='crimson'>Teorema 5.6:</font>** *Sea $f:\\mathcal{A}\\longrightarrow \\mathbb{R}$ una medida con aditividad finita definida sobre un álgebra Booleana $\\mathcal{A}$. Para cualquier par de conjuntos $A$ y $B$ de $\\mathcal{A}$, se cumplen las siguientes propiedades:*\n",
    "\n",
    "- **(P1):** $f\\left( A\\cup B\\right)  \\leq f\\left( A\\right)  +f\\left( B\\right)$.\n",
    "- **(P2):** $f\\left( B-A\\right)  =f\\left( B\\right)  -f\\left( A\\right)  \\Longleftrightarrow A\\subseteq B$.\n",
    "- **(P3):** $f\\left( A\\right)  \\leq f\\left( B\\right)  \\Longleftrightarrow A\\subseteq B$.\n",
    "- **(P4):** $f\\left( \\emptyset \\right)  =0$.\n",
    "◆\n",
    "\n",
    "**Ejemplo 5.6 – Número de elementos en un conjunto finito:** Sea $\\Omega =\\left\\{ a_{1},...,a_{n}\\right\\}$ un conjunto que consta de $n$ elementos distintos y sea $\\mathcal{A}$ la clase de todos los subconjuntos de $\\Omega$. Para cada $A$ de $\\mathcal{A}$, representemos por $\\nu (A)$ el número de elementos distintos de $A$. Es sencillo verificar que esta función es de aditividad finita en $\\mathcal{A}$. En efecto, si $A$ tiene $k$ elementos y $B$ tiene $m$ elementos, entonces $\\nu (A)=k$ y $\\nu (B)=m$. Si $A$ y $B$ son disjuntos es evidente que $A\\cup B$ es un subconjunto de $\\Omega$ con $(k+m)$ elementos, así que $\\nu (A\\cup B)=k+m=\\nu (A) +\\nu (B)$. La función $\\nu$ es no negativa, por lo que, además, se trata de una medida. ◼︎"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d91fe68",
   "metadata": {},
   "source": [
    "### Definición de probabilidad.\n",
    "En el lenguaje de las funciones de conjunto, la probabilidad es un tipo especial de medida (denotada por $P$) definida sobre una particular álgebra Booleana $\\mathcal{B}$ de subconjuntos. Los elementos de $\\mathcal{B}$ son subconjuntos de un conjunto universal $\\Omega$. Como bien sabemos, este conjunto $\\Omega$ es llamado **espacio muestral**. Primero comentaremos la definición de probabilidad para espacios muestrales finitos y luego lo haremos para aquellos que son infinitos.\n",
    "\n",
    "**<font color='blue'>Definición 5.7 – Probabilidad para espacios muestrales finitos:</font>** Sea $\\mathcal{B}$ un álgebra Booleana cuyos elementos son subconjuntos de un conjunto finito dado $\\Omega$. Una función de conjunto $P:\\mathcal{B}\\longrightarrow \\mathbb{R}$ se llama **medida de probabilidad** si satisface las siguientes condiciones:\n",
    "\n",
    "- **(C1):** $P$ es de aditividad finita.\n",
    "- **(C2):** $P$ es no negativa.\n",
    "- **(C3):** $P(\\Omega)=1$.\n",
    "\n",
    "Dicho de otro modo, para los espacios muestrales finitos, la probabilidad es simplemente una medida que asigna el valor 1 al espacio completo.\n",
    "\n",
    "Es importante darnos de que, para una descripción completa de la medida de probabilidad, deben precisarse tres ideas: El espacio muestral $\\Omega$, el álgebra Booleana $\\mathcal{B}$ construida con ciertos subconjuntos de $\\Omega$, y la función de conjunto $P$. La tripleta $(\\Omega, \\mathcal{B}, P)$ se denomina, con frecuencia, **espacio de probabilidad**. En la mayoría de las aplicaciones elementales, el álgebra Booleana $\\mathcal{B}$ es la colección de todos los subconjuntos de $\\Omega$.\n",
    "\n",
    "**Ejemplo 5.7:** El juego de *\"cara o sello\"* es un ejemplo típico de aplicación de la teoría de la probabilidad. Como espacio muestral $\\Omega$ tomamos el conjunto de todos los resultados posibles en el juego. Cada resultado es \"cara\" o \"sello\", que representamos con los símbolos $h$ y $t$, respectivamente. Dicho espacio muestral es pues $\\Omega =\\left\\{ h,t\\right\\}$. Como álgebra Booleana consideraremos la colección de todos los subconjuntos de $\\Omega$, que son cuatro: $\\emptyset, \\Omega, H$ y $T$, donde $H=\\left\\{ h\\right\\}$ y $T=\\left\\{ t\\right\\}$. Ahora asignaremos probabilidades a cada uno de estos subconjuntos. Para $\\emptyset$ y $\\Omega$ estos valores no son eligibles, ya que por **(C3)**, $P(\\Omega)=1$ y $P(\\emptyset)=0$. En cambio, tenemos libertad en la asignación a los otros dos subconjuntos, $H$ y $T$. Ya que $H$ y $T$ son conjuntos disjuntos cuya reunión es $\\Omega$, la propiedad aditiva exige que\n",
    "\n",
    "$$P\\left( H\\right)  +P\\left( T\\right)  =P\\left( \\Omega \\right)  =1$$\n",
    "<p style=\"text-align: right;\">$(5.17)$</p>\n",
    "\n",
    "Como valores de $P(H)$ y $P(T)$ podemos tomar cualquier valor no negativo con tal de que su suma sea igual a 1. Si tenemos en cuenta que la moneda no está trucada, de modo que no existe razón a priori para preferir cara o sello, parece natural asignar los valores\n",
    "\n",
    "$$P\\left( H\\right)  =P\\left( T\\right)  =\\frac{1}{2}$$\n",
    "<p style=\"text-align: right;\">$(5.18)$</p>\n",
    "\n",
    "Si, en cambio, la moneda no es geométricamente perfecta, podemos asignar valores diferentes a estas dos probabilidades. Por ejemplo, $P(H)=1/3$ y $P(T)=2/3$ son tan aceptables como $P\\left( H\\right)  =P\\left( T\\right)=1/2$. En efecto, para todo $p\\in \\mathbb{R}$ tal que $0\\leq p\\leq 1$, podemos definir $P(H)=p$ y $P(T)=1-p$, y la función resultante $P$ satisfará todas las condiciones que se exigen a una medida de probabilidad.\n",
    "\n",
    "Para una moneda determinada, no existe un método matemático para precisar cuál es la probabilidad $p$ “real”. Si escogemos $p=1/2$, podemos deducir consecuencias lógicas de la hipótesis de que la moneda no está trucada y, por extensión, no presenta sesgos de ningún tipo. La teoría desarrollada para el estudio de las probabilidades en monedas correctas puede utilizarse como test comprobatorio de su carencia de sesgo, efectuando un gran número de experimentos con ella y comparando los resultados experimentales con las predicciones teóricas. El poner de acuerdo la teoría y la evidencia empírica pertenece a la rama de la teoría de la probabilidad llamada **inferencia estadística**, y no la expondremos en estos apuntes. ◼︎\n",
    "\n",
    "El ejemplo anterior es una típica aplicación del llamado **cálculo de probabilidades**. Las cuestiones probabilísticas se presentan a menudo en situaciones llamadas experimentos. No intentaremos definir un experimento (ya hicimos un acercamiento, más bien vago, a esta cuestión al inicio de esta sección); en cambio, mencionaremos tan sólo algunos ejemplos corrientes: Lanzar una o varias monedas, lanzar un par de dados, repartir una mano de cartas, sacar una bola de una urna, recuento de las mujeres que estudian en la Facultad de Ingeniería de la Universidad de Santiago de Chile, selección de un número en una guía telefónica, registro de la radiación en un contador Geiger, etc.\n",
    "\n",
    "Para discutir las cuestiones de probabilidad que surgen en tales experimentos, nuestro primer trabajo es la construcción de un espacio muestral Ω que pueda utilizarse para mostrar todos los resultados posibles del experimento, como hicimos en el juego de lanzar una moneda. Cada elemento de $\\Omega$ representará un resultado del experimento y cada resultado corresponderá a uno y sólo un elemento de $\\Omega$. A continuación, elegimos un álgebra de Boole $\\mathcal{B}$ de subconjuntos de $\\Omega$ (casi siempre, todos los subconjuntos de $\\Omega$) y entonces se define una medida de probabilidad $P$ sobre $\\mathcal{B}$. La elección de $\\Omega$, $\\mathcal{B}$ y $P$ dependerá de la información que se posea acerca de los detalles del experimento y del problema que nos vamos a plantear. El objeto del cálculo de probabilidades no es discutir si el espacio de probabilidad $(\\Omega,\\mathcal{B},P)$ ha sido elegido correctamente. Esto pertenece a la ciencia o juego del que el experimento ha surgido, y tan solo la experiencia puede darnos idea de si la elección fue bien hecha o no. El cálculo de probabilidad es el estudio de las consecuencias lógicas que pueden deducirse una vez dado un espacio de probabilidad. La elección de un buen espacio de probabilidad no es teoría de probabilidad –ni siquiera es matemáticas–; es en cambio el arte de aplicar la teoría probabilística al mundo real.\n",
    "\n",
    "Si $\\Omega =\\left\\{ a_{1},...,a_{n}\\right\\}$ y si $\\mathcal{B}$ consta de todos los subconjuntos de $\\Omega$, la función de probabilidad $P$ está completamente determinada si conocemos sus valores para los conjuntos de un solo elemento,\n",
    "\n",
    "$$P\\left( \\left\\{ a_{1}\\right\\}  \\right)  ,P\\left( \\left\\{ a_{2}\\right\\}  \\right)  ,...,P\\left( \\left\\{ a_{n}\\right\\}  \\right)$$\n",
    "<p style=\"text-align: right;\">$(5.19)$</p>\n",
    "\n",
    "En efecto, todo subconjunto de $A$ de $\\Omega$ es una reunión disjunta de los conjuntos anteriores, y $P(A)$ está determinada por la propiedad aditiva. Por ejemplo, cuando\n",
    "\n",
    "$$A=\\bigcup^{n}_{k=1} \\left\\{ a_{k}\\right\\}$$\n",
    "<p style=\"text-align: right;\">$(5.20)$</p>\n",
    "\n",
    "la propiedad aditiva exige que\n",
    "\n",
    "$$P\\left( A\\right)  =\\sum^{n}_{k=1} P\\left( \\left\\{ a_{k}\\right\\}  \\right)$$\n",
    "<p style=\"text-align: right;\">$(5.21)$</p>\n",
    "\n",
    "Debido a que el método probabilístico se usa en cuestiones prácticas, es conveniente imaginarse que cada espacio de probabilidad $(\\Omega,\\mathcal{B},P)$ está asociado a un experimento real o ideal. El conjunto universal $\\Omega$ puede entonces concebirse como la colección de todos los resultados imaginables del experimento, como en el ejemplo (5.7). Cada elemento de $\\Omega$ se llama **resultado** o **muestra** y los subconjuntos de $\\Omega$ que se presentan en el álgebra de Boole $\\mathcal{B}$ se denominan **sucesos**. Los motivos de esta terminología se pondrán en evidencia al tratar algunos ejemplos.\n",
    "\n",
    "Dos sucesos $A$ y $B$ son **igualmente probables** (o **equiprobables**) si $P(A)=P(B)$. El suceso $A$ es **más probable** que $B$ si $P(A)>P(B)$ y **por lo menos tan probable** como $B$ si $P(A)\\geq P(B)$. La Tabla (5.1) nos muestra una lista de locuciones del lenguaje habitual en las discusiones de la teoría de probabilidad. Las letras $A$ y $B$ representan sucesos, y $x$ es el resultado de un experimento asociado al espacio muestral $\\Omega$. Cada fila de la columna de la izquierda es una afirmación relativa a los sucesos $A$ y $B$, y en la misma fila en la columna de la derecha se expresa la misma afirmación en el lenguaje de la teoría de conjuntos.\n",
    "\n",
    "<p style=\"text-align: center;\">Tabla (5.1): Proposiciones usadas en la teoría de probabilidad y su significado en la teoría de conjuntos</p>\n",
    "\n",
    "| Proposiciones                                     | Significado en la teoría de conjuntos    |\n",
    "| :------------------------------------------------ | :--------------------------------------- |\n",
    "| Por lo menos uno de los sucesos $A$ o $B$ ocurre. | $x\\in A\\cup B$                           |\n",
    "| Ambos sucesos, $A$ y $B$, ocurren.                | $x\\in A\\cap B$                           |\n",
    "| Ni $A$ ni $B$ ocurren.                            | $x\\in \\bar{A}\\cap \\bar{B}$               |\n",
    "| $A$ ocurre, pero $B$ no.                          | $x\\in A\\cap \\bar{B}$                     |\n",
    "| Exactamente ocurre uno de los sucesos, $A$ o $B$. | $x\\in (A\\cap \\bar{B})\\cup (\\bar \\cap B)$ |\n",
    "| No más de uno de los sucesos, $A$ o $B$, ocurre.  | $x\\in (\\overline{A\\cap B})$              |\n",
    "| Si $A$ ocurre, también $B$ ($A$ implica $B$).     | $A\\subseteq B$                           |\n",
    "| $A$ y $B$ son mutuamente excluyentes.             | $A\\cap B =\\emptyset$                     |\n",
    "| Suceso $A$ o suceso $B$.                          | $A\\cup B$                                |\n",
    "| Suceso $A$ y suceso $B$.                          | $A\\cap B$                                |\n",
    "\n",
    "**Ejemplo 5.8:** Consideremos el experimento consistente en tomar dos naipes de cada una de las dos barajas que constituyen un juego de cartas inglés. Vamos a determinar la probabilidad de que por lo menos uno de estos naipes sea el as de corazones.\n",
    "\n",
    "Sean $a$ y $b$ cada naipe a sacar, uno de cada baraja. Representaremos un resultado mediante el par ordenado $(a,b)$ el número de resultados posibles; esto es, el número total de pares distintos $(a,b)$ del espacio muestral de $\\Omega$ se deduce mediante una sencilla aplicación del principio multiplicativo. Así, dado que cada baraja tiene 52 naipes en total, se tendrá que el número de elementos de $\\Omega$ es $52\\times 52=52^{2}$. Asignamos a cada uno de estos pares la probabilidad $1/52^{2}$. El suceso en el que estamos interesados es el conjunto $A$ de pares $(a,b)$ en los que $a$ o $b$ pueden ser el as de corazones. En $A$ hay $52+51$ elementos (ya que no hemos establecido que el primer naipe se devuelve a la baraja una vez sacado). Por lo tanto, en esta hipótesis, deducimos que\n",
    "\n",
    "$$P\\left( A\\right)  =\\frac{52+51}{52^{2}} =\\frac{1}{26} -\\frac{1}{52^{2}}$$\n",
    "<p style=\"text-align: right;\">$(5.22)$</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebf4582f",
   "metadata": {},
   "source": [
    "## Experimentos o pruebas compuestas.\n",
    "Una disputa entre jugadores en 1654 llevó a dos famosos matemáticos franceses, Blaise Pascal y Pierre de Fermat, a la creación del cálculo de probabilidades. Antoine Gombaud, caballero de Méré, noble francés interesado en cuestiones de juegos y apuestas, llamó la atención a Pascal respecto a una aparente contradicción en un popular juego de dados. El juego consistía en lanzar 24 veces un par de dados; y el problema en decidir si era lo mismo apostar la misma cantidad a favor o en contra de la aparición por lo menos de un «doble seis» en las 24 tiradas. Una regla del juego aparentemente bien establecida condujo a de Méré a creer que apostar por un doble seis en 24 tiradas era ventajoso, pero sus propios cálculos indicaban justamente lo contrario. Este problema, consecuentemente, fue conocido como el *problema de Méré*.\n",
    "\n",
    "Para resolver este problema, consideremos el experimento de lanzar un par de dados una sola vez. El resultado de este juego puede representarse mediante pares ordenados $(a,b)$ en los que $a$ y $b$ recorren los valores 1, 2, 3, 4, 5, y 6. El espacio muestral $\\Omega$ consta de 36 de esos pares. Si asumimos que los dados no están cargados (son geométricamente perfectos, lo que implica que cada cara tiene igual probabilidad de salir), asignamos a cada par la probabilidad 1/36.\n",
    "\n",
    "Supongamos que lanzamos los dados 𝑛 veces. La sucesión de las $n$ pruebas es una prueba compuesta que queremos describir matemáticamente. Por ello, necesitamos un nuevo espacio muestral y una correspondiente medida de probabilidad. Consideremos los resultados del nuevo juego como vectores en $\\mathbb{R}^{n}$ del tipo $(x_{1},...,x_{n})$, donde cada elemento $x_{i}$ es uno de los resultados del espacio muestral original $\\Omega$. Es decir, el espacio muestral para la prueba compuesta es el producto cartesiano $\\Omega\\times \\cdots \\times \\Omega=\\Omega^{n}$. De esta manera, $\\Omega^{n}$ tiene un total de $36^{n}$ elementos, y asignamos la probabilidad $1/36^{n}$ a cada uno de ellos. Nos interesa el suceso “por lo menos un doble 6 en $n$ tiradas”. Designemos tal suceso por $A$. En este caso, es más sencillo calcular la probabilidad del suceso complementario $\\bar{A}$, que significa “ningún doble 6 en $n$ tiradas”. Cada elemento de $\\bar{A}$ es un vector en $\\mathbb{R}^{n}$ cuyas componentes pueden ser cualquier elemento de $\\Omega$ excepto $(6, 6)$. Por consiguiente, existen 35 valores para cada componente y por lo tanto $35^{n}$ vectores en total en $\\bar{A}$. Puesto que cada elemento de $\\bar{A}$ tiene probabilidad $(1/36)^{n}$, la suma de todas las probabilidades puntuales en $\\bar{A}$ es igual a $(35/36)^{n}$. Esto nos da\n",
    "\n",
    "$$P\\left( A\\right)  =1-P\\left( \\bar{A} \\right)  =1-\\left( \\frac{35}{36} \\right)^{n}$$\n",
    "<p style=\"text-align: right;\">$(5.23)$</p>\n",
    "\n",
    "Para contestar a la pregunta de Méré, tenemos que decidir si $P(A)$ es mayor o menor que 1/2 cuando $n=24$. La desigualdad $P(A)\\geq 1/2$ es equivalente a decir que $1-\\left( \\frac{35}{36} \\right)^{n}  \\geq \\frac{1}{2}$ o $\\left( \\frac{35}{36} \\right)^{n}  \\leq \\frac{1}{2}$. Tomando logaritmos, encontramos que\n",
    "\n",
    "$$n\\log \\left( 35\\right)  -n\\log \\left( 36\\right)  \\leq -\\log \\left( 2\\right)  \\  \\vee \\  n\\geq \\frac{\\log \\left( 2\\right)  }{\\log \\left( 36\\right)  -\\log \\left( 35\\right)  } =24.6$$\n",
    "<p style=\"text-align: right;\">$(5.24)$</p>\n",
    "\n",
    "Por consiguiente, $P(A)<1/2$ cuando $n=24$ y $P>1/2$ cuando $n\\geq 25$. No es ventajosa una apuesta de una cantidad al suceso de que por lo menos se presente un doble 6 en 24 tiradas, frente a la apuesta de la misma cantidad al suceso contrario.\n",
    "\n",
    "Esta discusión sugiere un método general para tratar los experimentos sucesivos. Si una prueba se repite dos o más veces, el resultado puede considerarse como una prueba compuesta. Más general, una prueba compuesta puede ser el resultado de ejecutar dos o más pruebas distintas sucesivamente. Cada una de las pruebas individuales puede estar relacionada con cada una de las otras o pueden ser estocásticamente independientes, en el sentido de que la probabilidad del resultado de cada una de ellas no depende de los resultados de las otras.\n",
    "\n",
    "Por simplicidad, discutiremos cómo se pueden combinar dos pruebas independientes en una prueba compuesta. La generalización a más de dos experiencias será evidente.\n",
    "\n",
    "Para asociar el espacio de probabilidad natural a una prueba o experiencia compuesta, debemos definir el nuevo espacio muestral $\\Omega$, el álgebra Booleana $\\mathcal{B}$ de subconjuntos de $\\Omega$ y la medida de probabilidad $P$ sobre $\\mathcal{B}$. Sean $(\\Omega_{1},\\mathcal{B}_{1},P_{1})$ y $(\\Omega_{2},\\mathcal{B},P_{2})$  dos espacios de probabilidad asociados a dos experiencias 𝐸_1 y 𝐸_2. Con 𝐸 representamos la experiencia o prueba compuesta para las que el espacio muestral $\\Omega$ es el producto cartesiano $\\Omega_{1}\\times \\Omega_{2}$. Un resultado de $E$ es el par $(x,y)$ de $\\Omega$, donde la primera componente $x$ es un resultado de $E_{1}$ y el segundo 𝑦 es un resultado de $E_{2}$. Si $\\Omega_{1}$ tiene $n$ elementos y $\\Omega_{2}$ tiene $m$ elementos, el producto $\\Omega_{1}\\times \\Omega_{2}$ tendrá $nm$ elementos.\n",
    "\n",
    "Como nueva álgebra Booleana $\\mathcal{B}$ tomamos la colección de todos los subconjuntos de $\\Omega$. A continuación definimos la probabilidad $P$. Ya que $\\Omega$ es finito, podemos definir $P(x,y)$ para cada punto $(x,y)$ de $\\Omega$ y utilizar la aditividad al definir $P$ para los subconjuntos de $\\Omega$. Las probabilidades $P(x,y)$ pueden asignarse de varias maneras. Sin embargo, si dos pruebas $E_{1}$ y $E_{2}$ son estocásticamente independientes, definimos $P$ mediante la ecuación\n",
    "\n",
    "$$P\\left( x,y\\right)  =P_{1}\\left( x\\right)  P_{2}\\left( y\\right)  ;\\forall \\left( x,y\\right)  \\in \\Omega$$\n",
    "<p style=\"text-align: right;\">$(5.25)$</p>\n",
    "\n",
    "Esta afirmación se justifica como sigue: Consideremos dos sucesos particulares $A$ y $B$ del nuevo espacio $\\Omega$, definidos como\n",
    "\n",
    "$$\\begin{array}{l}A=\\left\\{ \\left( x_{1},y_{i}\\right)  \\right\\}^{m}_{i=1}  =\\left\\{ \\left( x_{1},y_{1}\\right)  ,...,\\left( x_{1},y_{m}\\right)  \\right\\}  \\\\ B=\\left\\{ \\left( x_{i},y_{1}\\right)  \\right\\}^{n}_{i=1}  =\\left\\{ \\left( x_{1},y_{1}\\right)  ,...,\\left( x_{n},y_{1}\\right)  \\right\\}  \\end{array}$$\n",
    "<p style=\"text-align: right;\">$(5.26)$</p>\n",
    "\n",
    "Esto es, $A$ es el conjunto de todos los pares de $\\Omega_{1}\\times \\Omega_{2}$ cuyo primer elemento es $x_{1}$, y $B$ es el conjunto de todos los pares de $\\Omega_{1}\\times \\Omega_{2}$ cuyo segundo elemento es $y_{1}$. La intersección de los dos conjuntos $A$ y $B$ es el conjunto de un solo elemento $\\left\\{ \\left( x_{1},y_{1}\\right)  \\right\\}$. Si presentimos que el primer resultado $x_{1}$ no debe influir en el resultado $y_{1}$, parece razonable exigir que los sucesos $A$ y $B$ sean independientes. Esto significa que habrá que definir la nueva función de probabilidad $P$ de manera que\n",
    "\n",
    "$$P\\left( A\\cap B\\right)  =P\\left( A\\right)  P\\left( B\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.27)$</p>\n",
    "\n",
    "Si decidimos la forma de asignar las probabilidades $P(A)$ y $P(B)$, la ecuación (5.27) nos dirá como asignar la probabilidad $P(A\\cap B)$. Esto es, la probabilidad $P(x_{1},y_{1})$. Se presenta el suceso $A$ si y sólo si el resultado de la primera prueba es $x_{1}$. Puesto que $P_{1}(x_{1})$ es su probabilidad, parece natural asignar el valor $P_{1}(x_{1})$ también a $P(A)$. Análogamente, asignamos a $P(B)$ el valor $P_{2}(y_{1})$. La ecuación (5.28) nos da entonces\n",
    "\n",
    "$$P\\left( x_{1},y_{1}\\right)  =P_{1}\\left( x_{1}\\right)  P_{2}\\left( y_{1}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.28)$</p>\n",
    "\n",
    "Todo esto es, naturalmente, tan solo una justificación para la asignación de probabilidades de la ecuación (5.25). El único camino para decidir si la ecuación (5.25) es o no una asignación de probabilidades puntuales aceptable es ver si se cumplen las propiedades fundamentales de las medidas de probabilidad. Cada número $P(x,y)$ es no negativo, y la suma de todas las probabilidades puntuales es igual a 1, pues que tenemos\n",
    "\n",
    "$$\\sum_{\\left( x,y\\right)  \\in S} P\\left( x,y\\right)  =\\sum_{x\\in S_{1}} P_{1}\\left( x\\right)  \\sum_{y\\in S_{2}} P_{2}\\left( y\\right)  =1\\cdot 1=1$$\n",
    "<p style=\"text-align: right;\">$(5.29)$</p>\n",
    "\n",
    "Cuando decimos que una prueba compuesta $E$ está determinada por dos pruebas $E_{1}$ y $E_{2}$ estocásticamente independientes, queremos decir que el espacio de probabilidad $(\\Omega,\\mathcal{B},P)$ está definido como acabamos de explicar, tal “independencia” queda reflejada en el hecho de que $P(x,y)$ es igual al producto $P_{1}(x)P_{2}(y)$. Puede demostrarse que la asignación de probabilidades (5.25) implica la igualdad\n",
    "\n",
    "$$P\\left( U\\times V\\right)  =P_{1}\\left( U\\right)  P_{2}\\left( V\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.30)$</p>\n",
    "\n",
    "para todo par de subconjuntos $U$ de $\\mathcal{B}_{1}$ y $V$ de $\\mathcal{B}_{2}$. De esta forma, deduciremos algunas consecuencias importantes.\n",
    "\n",
    "Sea $A$ un suceso (de la prueba compuesta $E$) de la forma\n",
    "\n",
    "$$A=C_{1}\\times \\Omega_{2}$$\n",
    "<p style=\"text-align: right;\">$(5.31)$</p>\n",
    "\n",
    "donde $C_{1}\\in \\mathbb{B}_{1}$. Cada resultado de $A$ es un par ordenado $(x,y)$, siendo $x$ un resultado de $C_{1}$ (en la primera prueba $E_{1}$), mientras que $y$ puede ser cualquier resultado de $\\Omega_{2}$ (en la segunda prueba $E_{2}$). Si aplicamos la ecuación (5.30), encontramos que\n",
    "\n",
    "$$P\\left( A\\right)  =P\\left( C_{1}\\times \\Omega_{2} \\right)  =P_{1}\\left( C_{1}\\right)  P_{2}\\left( \\Omega_{2} \\right)  =P_{1}\\left( C_{1}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.32)$</p>\n",
    "\n",
    "ya que $P_{2}(\\Omega_{2})=1$. De este modo, la definición de $P$ aisgna la misma probabilidad $A$ que la asignada por $P_{1}$ a $C_{1}$. Por esa razón, se dice que un tal suceso $A$ **está determinado mediante la primera prueba** $E_{1}$. Análogamente, si $B$ es un suceso de $E$ de la forma\n",
    "\n",
    "$$B=\\Omega_{1}\\times C_{2}$$\n",
    "<p style=\"text-align: right;\">$(5.33)$</p>\n",
    "\n",
    "teniendo $C_{2}\\in \\mathcal{B}_{2}$, llegamos a\n",
    "\n",
    "$$P\\left( B\\right)  =P\\left( \\Omega_{1} \\times C_{2}\\right)  =P_{1}\\left( \\Omega_{1} \\right)  P_{2}\\left( C_{2}\\right)  =P_{2}\\left( C_{2}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.34)$</p>\n",
    "\n",
    "y se dice que $B$ **está determinado por la segunda prueba** $E_{2}$. Demostraremos ahora, utilizando la ecuación (5.30), que tales sucesos $A$ y $B$ son independientes. Esto es, tenemos\n",
    "\n",
    "$$P(A\\cap B)=P(A)P(B)$$\n",
    "<p style=\"text-align: right;\">$(5.35)$</p>\n",
    "\n",
    "En efecto,\n",
    "\n",
    "$$\\begin{array}{lll}A\\cap B&=&\\left\\{ \\left( x,y\\right)  \\in \\mathbb{R}^{2} :\\left( x,y\\right)  \\in C_{1}\\times \\Omega_{2} \\wedge \\left( x,y\\right)  \\in \\Omega_{1} \\times C_{2}\\right\\}  \\\\ &=&\\left\\{ \\left( x,y\\right)  \\in \\mathbb{R}^{2} :x\\in C_{1}\\wedge y\\in C_{2}\\right\\}  \\\\ &=&C_{1}\\times C_{2}\\end{array}$$\n",
    "<p style=\"text-align: right;\">$(5.36)$</p>\n",
    "\n",
    "Luego tenemos\n",
    "\n",
    "$$P(A\\cap B)=P(C_{1}\\times C_{2})=P_{1}(C_{1})P_{2}(C_{2})$$\n",
    "<p style=\"text-align: right;\">$(5.37)$</p>\n",
    "\n",
    "Puesto que $P_{1}(C_{1})=P(A)$ y $P_{2}(C_{2})=P(B)$, obtenemos la ecuación (5.35). Observemos que la la ecuación (5.37) también demuestra que podemos calcular la probabilidad $P(A\\cap B)$ como producto de las probabilidades en cada uno de los espacios muestrales $\\Omega_{1}$ y $\\Omega_{2}$. Por lo tanto, no son precisos los cálculos con probabilidades en las pruebas compuestas.\n",
    "\n",
    "La generalización a experimentos con $n$ pruebas $E_{1},...,E_{n}$ se deduce de la misma forma. Los puntos en el nuevo espacio muestral son vectores en $\\mathbb{R}^{n}$ del tipo $\\mathbf{x}=(x_{1},...,x_{2})$ y las probabilidades se definen como producto de las probabilidades particulares. Es decir,\n",
    "\n",
    "$$P\\left( \\mathbf{x} \\right)  =P\\left( x_{1},...,x_{n}\\right)  =\\prod^{n}_{k=1} P_{k}\\left( x_{k}\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.38)$</p>\n",
    "\n",
    "Cuando se adopta esta definición de $P$, decimos que $E$ **está determinado por $n$ pruebas independientes** $E_{1},...,E_{n}$. En el caso particular en el que todas las pruebas están asociadas al mismo espacio de probabilidad, la prueba compuesta 𝐸 es un ejemplo de pruebas independientes repetidas bajo idénticas condiciones. Un ejemplo de esto corresponde a las pruebas de Bernoulli, que caracterizaremos a continuación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cca170fc",
   "metadata": {},
   "source": [
    "### Pruebas de Bernoulli.\n",
    "Un ejemplo importante de prueba compuesta lo estudió Jakob Bernoulli y lo conocemos por el nombre de **sucesión de pruebas de Bernoulli**. Se trata de una sucesión de pruebas repetidas ejecutadas en las mismas condiciones, siendo cada resultado estocásticamente independiente de las demás. Cada prueba tiene exactamente dos resultados posibles, corrientemente llamados **“éxito”** y **“fallo”**; la probabilidad del éxito se representa por $p$ y la del fallo con $q$. Naturalmente, $q=1-p$. El teorema principal relacionado con las sucesiones de Bernoulli es el siguiente.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.7 – Fórmula de Bernoulli:</font>** *Sea $\\Omega=\\left\\{ 0,1\\right\\}$ el espacio muestral de un experimento particular que será repetido un número particular de veces, donde designamos al éxito de la prueba con el valor $x=1$ y al fallo con un valor $x=0$. La probabilidad de $k$ éxitos en $n$ pruebas de Bernoulli, que designamos como $P(x=1)$, se define como*\n",
    "\n",
    "$$P\\left( x=1\\right)  =\\binom{n}{k} p^{k}q^{n-k}\\  ;\\  \\binom{n}{k} =\\frac{n!}{\\left( n-k\\right)  !k!}$$\n",
    "<p style=\"text-align: right;\">$(5.39)$</p>\n",
    "◆\n",
    "\n",
    "**Ejemplo 5.9:** Se lanza 50 veces una moneda. Vamos a calcular la probabilidad de que salgan, exactamente, 50 caras. En efecto, interpretemos este juego como una sucesión de 50 pruebas de Bernoulli, en las que \"éxito\" significa cara, y \"fallo\" significa sello. Si suponemos que la moneda no presenta sesgos de ningún tipo (y, por lo tanto, cada resultado es equiprobable), asignamos las probabilidades $p=q=1/2$ y la fórmula (5.39) nos da\n",
    "\n",
    "$$P\\left( x=1\\right)  =\\binom{50}{k} \\left( \\frac{1}{2} \\right)^{50}$$\n",
    "<p style=\"text-align: right;\">$(5.40)$</p>\n",
    "\n",
    "En particular, para $k=25$, obtenemos\n",
    "\n",
    "$$P\\left( x=1\\right)  =\\binom{50}{25} \\left( \\frac{1}{2} \\right)^{50}  =\\frac{50!}{25!\\cdot 25!} \\left( \\frac{1}{2} \\right)^{50}  \\approx 0.112$$\n",
    "<p style=\"text-align: right;\">$(5.41)$</p>\n",
    "◼"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adeb83f5",
   "metadata": {},
   "source": [
    "### Número más probable de éxitos en $n$ pruebas de Bernoulli.\n",
    "Un par de dados no cargados es lanzado 28 veces ¿Cuál es el número más probable de sietes? Para resolver este problema, designemos por $f(k)$ la probabilidad de obtener exactamente $k$ sietes en 28 tiradas. La probabilidad de conseguir un siete en una tirada es 1/6. La fórmula de Bernoulli (teorema (5.7)) nos dice que\n",
    "\n",
    "$$f\\left( k\\right)  =\\binom{28}{k} \\left( \\frac{1}{6} \\right)^{k}  \\left( \\frac{5}{6} \\right)^{28-k}$$\n",
    "<p style=\"text-align: right;\">$(5.42)$</p>\n",
    "\n",
    "Queremos determinar qué valor (o valores) de $k$ entre los valores $k=0,1,2,...,28$ hacen máximo a $f(k)$. El siguiente teorema resuelve este problema para cualquier sucesión de pruebas de Bernoulli.\n",
    "\n",
    "**<font color='crimson'>Teorema 5.8:</font>** *Dados un entero $n\\geq 1$ y un número real $p$ tal que $0<p<1$, consideremos el conjunto de números*\n",
    "\n",
    "$$f\\left( k\\right)  =\\binom{n}{k} p^{k}\\left( 1-p\\right)^{n-k}  \\  ;\\  k\\in \\mathbb{N} +\\left\\{ 0\\right\\}$$\n",
    "<p style=\"text-align: right;\">$(5.43)$</p>\n",
    "\n",
    "- **(T1)**: *Si $(n+1)p\\notin \\mathbb{Z}$, el máximo de $f(k)$ se presenta exactamente para un valor de $k$:*\n",
    "\n",
    "$$k=\\left[ \\left( n+1\\right)  p\\right]$$\n",
    "<p style=\"text-align: right;\">$(5.44)$</p>\n",
    "\n",
    "*donde $\\left[ \\  \\cdot \\  \\right]$ es la función parte entera.*\n",
    "\n",
    "- **(T2)**: *Si $(n+1)p\\in \\mathbb{Z}$, el máximo de $f(k)$ se presenta exactamente para dos valores de $k$:*\n",
    "\n",
    "$$k_{1}=\\left( n+1\\right)  p\\wedge k_{2}=\\left( n+1\\right)  p-1$$\n",
    "<p style=\"text-align: right;\">$(5.45)$</p>\n",
    "◆\n",
    "\n",
    "**Ejemplo 5.10:** Vamos a determinar el número más probable de sietes cuando un par de dados se lanza 28 veces. En efecto, aplicamos el teorema (5.8) con $n=28$, $p=1/6$ y $(n+1)p=29/6$. Como $29/6$ no es un número entero, el valor máximo de $f(k)$ se presenta para $k=[29/6]=4$. ◼"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f550b48d",
   "metadata": {},
   "source": [
    "## Conjuntos numerables y no numerables.\n",
    "Hasta aquí sólo hemos considerado el concepto de probabilidad para espacios muestrales finitos. Queremos ahora extender la teoría a **espacios muestrales infinitos**. Para ello es necesario distinguir dos tipos de conjuntos infinitos, los **numerables** y los **no numerables**. En esta sección se estudian ambos.\n",
    "\n",
    "Para contar los elementos de un conjunto finito se pone en correspondencia el conjunto, elemento a elemento, con el conjunto de los números naturales $\\mathbb{N}$. La comparación de los \"tamaños\" de dos conjuntos mediante la correspondencia entre ellos elemento a elemento sustituye el recuento de los elementos cuando se trata de conjuntos infinitos. A este proceso se le puede dar una clara formulación matemática empleando el concepto de función.\n",
    "\n",
    "**<font color='blue'>Definición 5.8 – Correspondencia uno a uno de conjuntos:</font>** Se dice que dos conjuntos $A$ y $B$ están en **correspondencia uno a uno** si existe una función $f$ con la siguientes propiedades:\n",
    "\n",
    "- **(P1):** $f$ es tal que $f:A\\longrightarrow B$.\n",
    "- **(P2):** Si $x$ e $y$ son elementos distintos de $A$, entonces $f(x)$ y $f(y)$ son elementos distintos de $B$. Esto es, para todo par de elementos $x,y\\in A$, se tiene que\n",
    "\n",
    "$$x\\neq y\\Longrightarrow f(x)\\neq f(y)$$\n",
    "<p style=\"text-align: right;\">$(5.46)$</p>\n",
    "\n",
    "Una función $f$ que cumple con **(P2)** se dice inyectiva sobre $A$. Dos conjuntos $A$ y $B$ en correspondencia uno a uno se llaman también equivalentes, e indicamos esto poniendo $A\\sim B$. Resulta claro pues que todo conjunto $A$ es equivalente a sí mismo, ya que $x=f(x)$ para todo $x$ en $A$.\n",
    "\n",
    "Un conjunto puede ser equivalente a un subconjunto de sí mismo. Por ejemplo, el conjunto $P=\\left\\{ 1,2,3,...\\right\\}$ compuesto por todos los números naturales es equivalente a su subconjunto $Q=\\left\\{ 2,4,6,...\\right\\}$ compuesto por todos los números pares positivos. En este caso, la función inyectiva que los hace equivalentes es $f(x)=2x$ para todo $x\\in P$.\n",
    "\n",
    "Si $A\\sim B$, es fácil demostrar que $B\\sim A$. Si $f$ es inyectiva en $A$ y si $\\mathrm{Rec}(f)=B$, entonces, para cada $b\\in B$ existe exactamente un $a$ en $A$ tal que $f(a)=b$. De ahí que podemos definir una función inversa $g$ en $B$ del modo siguiente: Si $b\\in B$, $g(b)=a$, donde $a$ es el único elemento de $A$ tal que $f(s)=b$. La función $g$ así definida es inyectiva en $B$ y su recorrido es $A$; luego $B\\sim A$. Esta propiedad de equivalencia se llama **simetría**:\n",
    "\n",
    "$$A\\sim B\\Longrightarrow B\\sim A$$\n",
    "<p style=\"text-align: right;\">$(5.47)$</p>\n",
    "\n",
    "También resulta sencillo demostrar que la equivalencia tiene la siguiente propiedad, llamada **transitividad**:\n",
    "\n",
    "$$A\\sim B\\wedge B\\sim C\\Longrightarrow A\\sim C$$\n",
    "<p style=\"text-align: right;\">$(5.48)$</p>\n",
    "\n",
    "Un conjunto $\\Omega$ se denomina **finito** y se dice que contiene $n$ elementos si $\\Omega \\sim \\left\\{ 1,2,...,n\\right\\}$. El conjunto vacío también se considera finito. A los conjuntos que no son finitos se les llama **infinitos**. Un conjunto $\\Omega$ se llama **infinito numerable (o contable)** si es equivalente al conjunto de todos los números naturales, esto es, si $\\Omega \\sim \\mathbb{N}$. En este caso, existe una función $f$ que establece una correspondencia uno a uno entre el conjunto $\\mathbb{N}$ y los elementos de $\\Omega$; luego el conjunto $\\Omega$ puede expresarse como $\\Omega =\\left\\{ f\\left( 1\\right)  ,f\\left( 2\\right)  ,...\\right\\}  $.\n",
    "\n",
    "A menudo utilizamos subíndices y representamos $f(k)$ con $a_{k}$ (o con una notación parecida) y escribimos $\\Omega=\\left\\{ a_{1},a_{2},...\\right\\}$. La idea importante es que la correspondencia $\\Omega \\sim \\mathbb{N}$ nos permite utilizar los números naturales como “marcas” de los elementos de $\\Omega$. Un conjunto se dice que es **numerable en sentido amplio** si es finito o infinito numerable. Un conjunto que no es numerable se llama **no numerable**. Muchas operaciones con conjuntos efectuadas sobre conjuntos numerables producen conjuntos numerables. Por ejemplo, tenemos las propiedades siguientes:\n",
    "\n",
    "- **(P1):** Todo subconjunto de un conjunto numerable es numerable.\n",
    "- **(P2):** La intersección de toda colección de conjuntos numerables es numerable.\n",
    "- **(P3):** La reunión de una colección numerable de conjuntos numerables es numerable.\n",
    "- **(P4):** El producto cartesiano de un número finito de conjuntos numerables es numerable.\n",
    "\n",
    "**Ejemplo 5.11:** El conjunto $\\mathbb{Z}$ es numerable. En efecto, si $n\\in \\mathbb{Z}$, sea $f(n)=2n$ si $n$ es positivo, y $f(n)=2|n|+1$ si $n$ es negativo o cero. El dominio de $f$ es $\\mathbb{Z}$ y su recorrido es el conjunto $\\mathbb{N}+\\left\\{ 0\\right\\}$. Puesto que $f$ es inyectiva en $\\mathbb{Z}$, deducimos que $\\mathbb{Z}$ es numerable. ◼\n",
    "\n",
    "**Ejemplo 5.12:** El conjunto $\\mathbb{Q}$ de los números racionales es numerable. En efecto, para cada entero $n\\geq 1$ fijo, sea $\\Omega_{n}$ el conjunto de números racionales de la forma $x/n$, donde $x\\in \\mathbb{Z}$. Cada $\\Omega_{n}$ es equivalente a $\\mathbb{Z}$ (tómese $f(t)=nt$ si $t\\in \\Omega_{n}$) y, por consiguiente, cada $\\Omega_{n}$ es numerable. Puesto que $\\mathbb{Q}$ es la reunión de todos los $\\Omega_{n}$, en virtud de **(P3)**, $\\mathbb{Q}$ resulta ser numerable. ◼\n",
    "\n",
    "**Ejemplo 5.13:** El conjunto de todos los números reales $x$ que satisfacen $0<x<1$ es no numerable. En efecto, supongamos que el conjunto es numerable. De ser así, podemos disponer de sus elementos así: $\\left\\{ x_{1},x_{2},...\\right\\}$. Construiremos ahora un número real $y$ que cumpla con $0<y<1$ y que no estará en esta lista. Para ello, escribimos cada elemento en forma decimal. Es decir, $x_{n}=0.a_(n,1)a_(n,2)a_(n,3)...$, donde cada $a_(n,i)$ es uno de los enteros del conjunto $\\left\\{ 0,1,2,...,9\\right\\}$. Sea $y$ el número real cuyo desarrollo decimal es $0.y_{1}y_{2}y_{3}...$. Aquí,\n",
    "\n",
    "$$y_{n}=\\begin{cases}1&;\\  \\mathrm{si} \\  a_{\\left( n,n\\right)  }\\neq 1\\\\ 2&;\\  \\mathrm{si} \\  a_{\\left( n,n\\right)  }=1\\end{cases}$$\n",
    "<p style=\"text-align: right;\">$(5.49)$</p>\n",
    "\n",
    "De este modo, ningún elemento del conjunto $\\left\\{ x_{1},x_{2},...\\right\\}$ puede ser igual a $y$, puesto que $y$ difiere de $x_{1}$ en la primera cifra decimal, de $x_{2}$ en la segunda, y en general, difiere de $x_{k}$ en la $k$-ésima cifra decimal. Por lo tanto, $y$ satisface $0<y<1$, lo cual es una contradicción, lo que prueba que el conjunto $(0,1)\\subset \\mathbb{R}$ es no numerable. ◼"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09b5eda2",
   "metadata": {},
   "source": [
    "### Definición de probabilidad para espacios muestrales infinitos numerables.\n",
    "Ahora procederemos a extender la definición de probabilidad a espacios muestrales infinitos numerables. Sean $\\Omega$ un conjunto infinito numerable y $\\mathcal{B}$ un álgebra Booleana de subconjuntos de $\\Omega$. Definimos una medida de probabilidad $P$ en $\\mathcal{B}$ como se hizo en el caso finito, excepto que exigiremos la aditividad numerable además de la finita. Esto es, para toda colección infinita numerable $\\left\\{ A_{1},A_{2},\\ldots \\right\\}$ de elementos de $\\mathcal{B}$, exigimos que\n",
    "\n",
    "$$P\\left( \\bigcup^{+\\infty }_{k=1} A_{k}\\right)  =\\sum^{+\\infty }_{k=1} P\\left( A_{k}\\right)  \\Longleftrightarrow A_{i}\\cap A_{j}=\\emptyset \\  ;\\  \\forall i\\neq j$$\n",
    "<p style=\"text-align: right;\">$(5.50)$</p>\n",
    "\n",
    "Las funciones de conjunto con aditividad finita que satisfacen la ecuación (5.50) se llaman **funciones de aditividad numerable** (o *completamente aditivas*). Naturalmente, esta propiedad también exige suponer que la reunión numerable $\\bigcup^{+\\infty }_{k=1} A_{k}$ pertenece a $\\mathcal{B}$ cuando cada $A_{k}$ pertenezca también a $\\mathcal{B}$. No todas las álgebras de Boole presentan esta propiedad. Las que sí la tienen son llamadas **$\\sigma$-álgebras**. Un ejemplo es el álgebra Booleana de todos los subconjuntos del espacio muestral $\\Omega$. Precisemos, pues, esta definición.\n",
    "\n",
    "**<font color='blue'>Definición 5.9 – $\\sigma$-álgebra:</font>** Una familia de subconjuntos de $\\Omega$, representada por $\\mathcal{B}$, es una **$\\sigma$-álgebra** sobre $\\Omega$ cuando se cumplen las siguientes propiedades:\n",
    "\n",
    "- **(P1)**: El conjunto vacío está en $\\mathcal{B}$.\n",
    "- **(P2)**: Si $A\\in \\mathcal{B}$, entonces $\\bar{A} \\in \\mathcal{B}$.\n",
    "- **(P3)**: Si $A_{1},A_{2},...$ es una sucesión de elementos de $\\mathcal{B}$, entonces la unión (numerable) $\\bigcup^{+\\infty }_{k=1} A_{k}$ también está en $\\mathcal{B}$.\n",
    "\n",
    "Ahora ya estamos listos para construir la definición de probabilidad para espacios muestrales infinitos numerables.\n",
    "\n",
    "**<font color='blue'>Definición 5.10 – Probabilidad para espacios muestrales infinitos numerables:</font>** Sea $\\mathcal{B}$ una $\\sigma$-álgebra cuyos elementos son subconjuntos de un conjunto infinito $\\Omega$ numerable dado. Una función de conjunto $P$ se llama **medida de probabilidad** en $\\mathcal{B}$ si es no negativa, de aditividad numerable, y satisface $P(\\Omega)=1$.\n",
    "\n",
    "Cuando $\\mathcal{B}$ es la $\\sigma$-álgebra de todos los subconjuntos de $\\Omega$, una función de probabilidad queda completamente determinada mediante sus valores para los subconjuntos de un solo elemento (tales valores se llaman **probabilidades puntuales**). Todo subconjunto $A$ de $\\Omega$ es finito o infinito numerable, y la probabilidad de $A$ se calcula **sumando las probabilidades puntuales** para todos los elementos de $A$:\n",
    "\n",
    "$$P\\left( A\\right)  =\\sum_{x\\in A} P\\left( x\\right)$$\n",
    "<p style=\"text-align: right;\">$(5.51)$</p>\n",
    "\n",
    "La suma del lado derecho de la ecuación (5.51) tiene un número finito de sumandos, o bien, se trata de una serie absolutamente convergente.\n",
    "\n",
    "**Ejemplo 5.14:** Se lanza una moneda repetidamente hasta que el primer resultado vuelve a aparecer por segunda vez; entonces termina el juego. Como espacio muestral, tomamos la colección de todos los posibles juegos que pueden hacerse. Este conjunto puede expresarse como la reunión de los conjuntos infinitos numerables $A$ y $B$, definidos como\n",
    "\n",
    "$$A=\\left\\{ TT,THT,THHT,THHHT,...\\right\\}  \\wedge B=\\left\\{ HH,HTH,HTTH,HTTTH,...\\right\\}$$\n",
    "<p style=\"text-align: right;\">$(5.52)$</p>\n",
    "\n",
    "Donde $H$ representa una cara y $T$ representa un sello. Designemos los elementos del conjunto $A$ (en el orden en que se citan en la lista anterior) con $a_{0},a_{1},...$ y los de $B$ con $b_{0},b_{1},...$. Podemos asignar arbitrariamente probabilidades puntuales no negativas $P(a_{n})$ y $P(b_{n})$ tales que\n",
    "\n",
    "$$\\sum^{+\\infty }_{n=0} P\\left( a_{n}\\right)  +\\sum^{+\\infty }_{n=0} P\\left( b_{n}\\right)  =1$$\n",
    "<p style=\"text-align: right;\">$(5.53)$</p>\n",
    "\n",
    "Por ejemplo, supongamos que la moneda tiene una probabilidad $p$ de mostrar cara. Es decir, $P(H)=p$ y $P(T)=1-p$, con $0<p<1$. Entonces resulta natural la asignación de las probabilidades puntuales\n",
    "\n",
    "$$P\\left( a_{n}\\right)  =\\left( 1-p\\right)^{2}  p^{n}\\wedge P\\left( b_{n}\\right)  =p^{2}\\left( 1-p\\right)^{n}$$\n",
    "<p style=\"text-align: right;\">$(5.54)$</p>\n",
    "\n",
    "Tal asignación es aceptable, porque tenemos, para $q=1-p$,\n",
    "\n",
    "$$\\sum^{+\\infty }_{n=0} P\\left( a_{n}\\right)  +\\sum^{+\\infty }_{n=0} P\\left( b_{n}\\right)  =q^{2}\\sum^{+\\infty }_{n=0} p^{n}+p^{2}\\sum^{+\\infty }_{n=0} q^{n}=\\frac{q^{2}}{1-p} +\\frac{p^{2}}{1-q} =\\frac{\\left( 1-q\\right)  q^{2}+\\left( 1-p\\right)  p^{2}}{\\left( 1-p\\right)  \\left( 1-q\\right)  } =q+p=1$$\n",
    "<p style=\"text-align: right;\">$(5.55)$</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
