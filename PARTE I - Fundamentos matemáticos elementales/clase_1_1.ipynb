{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de258054",
   "metadata": {},
   "source": [
    "# CLASE 1.1: Un repaso (consciente) de álgebra lineal.\n",
    "---\n",
    "\n",
    "## Introducción.\n",
    "Cuando formalizamos conceptos intuitivos, un enfoque muy utilizado es construir un conjunto de objetos (símbolos) y reglas para manipular tales objetos. Ambos constituyen un marco de referencia que suele ser denominado como un álgebra. En particular, el álgebra lineal es el estudio de elementos conocidos como vectores y de un conjunto de reglas que permiten manipular adecuadamente estos vectores. Los vectores solemos conocerlos por primera vez en la enseñanza media, cuando en los cursos de Física abordamos ciertos cálculos soportados por elementos geométricos que solemos denotar por símbolos tales como $\\overrightarrow{x}$ o $\\overrightarrow{y}$. En esta asignatura, discutiremos conceptos más generales de vectores y usaremos una letra en **negrita** para representarlos cuando éstos sean tuplas de $\\mathbb{R}^{n}$; por ejemplo, $\\mathbf{x}$ o $\\mathbf{y}$.\n",
    "\n",
    "En general, los vectores son objetos especiales que pueden sumados y multiplicados por escalares para producir otro objeto del mismo tipo. Desde un punto de vista matemático y abstracto, cualquier objeto que satisfaga estas dos propiedades puede ser considerada un vector. A continuación, revisaremos ejemplos de este tipo de objetos:\n",
    "\n",
    "1. **Vectores geométricos:** Este ejemplo resulta familiar para estudiantes de secundaria que hayan cursado las asignaturas de física y matemáticas. Los vectores geométricos, como se observa en la Fig. (1.1a), corresponden a segmentos con una dirección bien definida, los cuales pueden ser dibujados (al menos en dos o tres dimensiones). Dos vectores geométricos, digamos $\\overrightarrow{x}$ e $\\overrightarrow{y}$, pueden sumarse, de tal forma que $\\overrightarrow{x} + \\overrightarrow{y} = \\overrightarrow{z}$ es otro vector. Además, la multiplicación de cualquier vector por un escalar arbitrario $\\lambda \\in \\mathbb{R}$, $\\lambda \\overrightarrow{x}$, también da como resultado otro vector. De hecho, el resultado de la última operación no es más que el mismo vector amplificado por un **factor de escalamiento** $\\lambda$. Por lo tanto, los vectores geométricos son instancias del concepto de vector que discutimos en un principio. La interpretación de vectores como objetos geométricos nos permite utilizar nuestra intuición para entender conceptos tales como la dirección y la magnitud de un vector, así como la aritmética entre ellos.\n",
    "\n",
    "2. **Los polinomios también son vectores:** Cualquier expresión de la forma $y=\\displaystyle \\sum\\nolimits^{n}_{i=0} a_{i}x^{i}$, con $\\left\\{ a_{i}\\right\\}^{n}_{i=1}  \\in \\mathbb{C} $, se denomina polinomio de orden $n$ (para $n\\neq 0$), y el conjunto de todos ellos se denota como $\\mathbb{R}_{n}[x]$. Se observan algunos ejemplos en la Fig. (1.1b). Dos polinomios pueden sumarse entre ellos, dando lugar a un nuevo polinomio. Además, cualquier multiplicación de un polinomio por un escalar también dará lugar a un nuevo polinomio. Por lo tanto, los polinomios constituyen también una instancia del concepto de vector discutido previamente. Estos objetos son muy distintos de los vectores geométricos, ya que si bien pueden graficarse en el plano, son entidades con un nivel muy superior de abstracción.\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_1_1.png\" width=\"800\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (1.1): (a) Los vectores geométricos; (b) Un polinomio también es un vector</p>\n",
    "\n",
    "3. **Las señales de audio son vectores:** Dichas señales son representadas como una serie de números. Podemos, igualmente, sumar entre sí este tipo de señales, siendo su suma una nueva señal de audio. Si escalamos una señal de audio, también obtendremos una nueva señal. Por lo tanto, bajo nuestra primera conceptualización, las señales de audio son también vectores.\n",
    "\n",
    "4. **Los elementos de $\\mathbf{R}^{n}$ (tuplas de $n$ números reales) son también vectores:** Estos vectores serán el tipo de objeto que abordaremos con mayor detenimiento en estos apuntes. Por ejemplo, $\\mathbf{a}=(1, 2, 3)\\in \\mathbb{R}^{3}$ es una tripleta de números que conforman un vector en un espacio euclídeo de tres dimensiones. La adición de dos vectores $\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^{3}$, componente a componente, genera un nuevo vector (que podemos escribir como $\\mathbf{c} = \\mathbf{a} + \\mathbf{c}$). Además, la multiplicación de un vector arbitrario $\\mathbf{a} \\in \\mathbb{R}^{n}$ por un escalar $\\lambda \\in \\mathbb{R}$ resulta en otro vector (que podemos escribir como $\\mathbf{d} = \\lambda \\mathbf{a}$). La consideración de estas tuplas como vectores tiene el beneficio adicional de que es posible representar tales objetos como arreglos a nivel computacional (por ejemplo, en Python, podemos utilizar listas, tuplas o arreglos de **Numpy** para representar vectores).\n",
    "\n",
    "El álgebra lineal se enfoca, principalmente, en las similitudes existentes entre estos conceptos de vector. Podemos sumar vectores y multiplicarlos por escalares. Nos enfocaremos fundamentalmente en vectores en $\\mathbb{R}^{n}$, debido a que la mayoría de los algoritmos basados en álgebra lineal se formulan en dicho conjunto. Más adelante, veremos que con frecuencia consideraremos que la data del mundo real se representará mediante vectores en $\\mathbb{R}^{n}$. Además, nos limitaremos al estudio de otras estructuras generales como espacios vectoriales cuya dimensión será finita, de tal forma que siempre habrá una correspondencia 1 a 1 entre cualquier tipo de vector y el conjunto $\\mathbb{R}^{n}$. Cuando sea conveniente (y para ir migrando poco a poco al dominio de lo que es la implementación de estos conocimientos en la práctica), utilizaremos nuestra intuición relativa a vectores geométricos y consideraremos algoritmos basados en estructuras tales como arreglos.\n",
    "\n",
    "Una idea importante en matemáticas corresponde al concepto de clausura. La pregunta asociada a la formulación de dicho concepto es la siguiente: ¿Cuál es el conjunto de todos los objetos que pueden resultar de las operaciones que propongamos? O en el caso de los vectores: ¿Cuál es el conjunto de vectores que pueden resultar partiendo de un conjunto pequeño de vectores iniciales, sumándolos y escalándolos? Esto último resulta en un espacio vectorial (que veremos en detalle más adelante), el cual es un concepto que conforma la base de mucho de lo que comporta a lo relativo a Machine Learning (aprendizaje automatizado), una serie de pautas, metodologías y algoritmos que permiten modelar una serie de procesos, fenómenos y sistemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8296699",
   "metadata": {},
   "source": [
    "## Sistemas de ecuaciones lineales.\n",
    "Los sistemas de ecuaciones lineales juegan un papel fundamental en el álgebra lineal. Muchos problemas físicos (en todo tipo de contextos fenomenológicos e industriales) pueden ser resueltos mediante la formulación de los mismos en base a sistemas de ecuaciones lineales y, como cabría esperar, el álgebra lineal nos entrega las herramientas para resolverlos.\n",
    "\n",
    "**Ejemplo 1.1:** Una compañía produce diferentes productos $N_{1},...,N_{n}$ para los cuales se requieren varios recursos $R_{1},...,R_{m}$. Para producir una unidad del producto $N_{j}$, se necesitan $a_{ij}$ unidades del recurso $R_{i}$, donde $1\\leq i\\leq m$ y $1\\leq j\\leq n$.\n",
    "\n",
    "El objetivo es encontrar un plan de producción óptimo; es decir, un plan que estime cuántas unidades $x_{j}$ del producto $N_{j}$ deberían ser producidos si un total de $b_{i}$ unidades del recurso $R_{i}$ están disponibles y (idealmente) se utilizan todos los recursos disponibles (no quedan holguras de ninguno).\n",
    "\n",
    "Si producimos $x_{1},...,x_{n}$ unidades de los productos respectivos, necesitamos un total de\n",
    "\n",
    "$$a_{i1}x_{1}+\\cdots +a_{in}x_{n}$$\n",
    "<p style=\"text-align: right;\">$(1.1)$</p>\n",
    "\n",
    "unidades del recurso $R_{i}$. Un plan de producción óptimo $(x_{1},...,x_{n})\\in \\mathbb{R}^{n}$, por lo tanto, debe satisfacer el siguiente sistema de ecuaciones lineales:\n",
    "\n",
    "$$\\begin{array}{rlr}a_{11}x_{1}+a_{12}x_{2}+\\cdots +a_{1n}x_{n}&=&b_{1}\\\\ a_{21}x_{1}+a_{22}x_{2}+\\cdots +a_{2n}x_{n}&=&b_{2}\\\\ \\vdots &&\\\\ a_{m1}x_{1}+a_{m2}x_{2}+\\cdots +a_{mn}x_{n}&=&b_{m}\\end{array} $$\n",
    "<p style=\"text-align: right;\">$(1.2)$</p>\n",
    "\n",
    "Donde $a_{ij}$ y $b_{i}\\in \\mathbb{R}$. ◼︎\n",
    "\n",
    "La ecuación (1.2) ilustra el esquema general de un sistema de ecuaciones lineales, donde los valores $x_{1},...,x_{n}$ son las **incógnitas** del sistema. Cada tupla $\\mathbf{x}=(x_{1},...,x_{n})\\in \\mathbb{R}^{n}$ que satisface (1.2) es una **solución** del sistema.\n",
    "\n",
    "**Ejemplo 1.2:** El sistema de ecuaciones lineales\n",
    "\n",
    "$$\\begin{array}{rcll}x_{1}+x_{2}+x_{3}&=&3&\\left( 1\\right)  \\\\ x_{1}-x_{2}+2x_{3}&=&2&\\left( 2\\right)  \\\\ 2x_{1}+3x_{3}&=&1&\\left( 3\\right)  \\end{array}$$\n",
    "<p style=\"text-align: right;\">$(1.3)$</p>\n",
    "\n",
    "no tiene solución. Si sumamos las ecuaciones (1) y (2), obtenemos $2x_{1}+3x_{3}=5$, lo que contradice (3).\n",
    "\n",
    "Ahora observemos el siguiente sistema de ecuaciones:\n",
    "\n",
    "$$\\begin{array}{rcll}x_{1}+x_{2}+x_{3}&=&3&\\left( 1\\right)  \\\\ x_{1}-x_{2}+2x_{3}&=&2&\\left( 2\\right)  \\\\ x_{2}+x_{3}&=&1&\\left( 3\\right)  \\end{array}$$\n",
    "<p style=\"text-align: right;\">$(1.4)$</p>\n",
    "\n",
    "De (1) y (3), se tiene que $x_{1}=1$. De la operación (1) + (2), obtenemos $2x_{1}+3x_{3}=5$, lo que implica que $x_{3}=1$. De (3), obtenemos que $x_{2}=1$. Por lo tanto, el vector $\\mathbf{x}=(x_{1}, x_{2}, x_{3})=(1, 1, 1)$ es la **única** y posible solución del sistema (1.4).\n",
    "\n",
    "Consideremos, como tercer ejemplo, el siguiente sistema de ecuaciones:\n",
    "\n",
    "$$\\begin{array}{rcll}x_{1}+x_{2}+x_{3}&=&3&\\left( 1\\right)  \\\\ x_{1}-x_{2}+2x_{3}&=&2&\\left( 2\\right)  \\\\ 2x_{1}+3x_{3}&=&5&\\left( 3\\right)  \\end{array}$$\n",
    "<p style=\"text-align: right;\">$(1.5)$</p>\n",
    "\n",
    "Dado que (1) + (2) = (3), podemos omitir la tercera ecuación, ya que resulta ser **redundante**. De (1) y (2), obtenemos $2x_{1}=5-3x_{3}$ y $2x_{2}=1+x_{3}$. Definimos $x_{3}=a\\in \\mathbb{R}$ con una *variable libre*, de manera que cualquier tripleta del tipo $\\left( \\frac{1}{2} \\left( 5-3a\\right)  ,\\frac{1}{2} \\left( 1+a\\right)  ,a\\right)\\in \\mathbb{R}^{3}$ es una solución de (1.5). Por lo tanto, el conjunto definido previamente establece infinitas soluciones para el sistema. ◼︎\n",
    "\n",
    "En general, para un sistema de ecuaciones lineales con dominio en un subconjunto de $\\mathbb{R}$, pueden darse tres casos distintos: El sistema no tiene solución, tiene una solución única, o bien, tiene infinitas soluciones. El modelo de regresión lineal, por ejemplo (y como ya veremos más adelante), es un caso particular de solución analíticamente cerrada de un sistema de ecuaciones lineales cuando no podemos resolver dicho sistema por métodos más convencionales.\n",
    "\n",
    "En un sistema de ecuaciones con dos variables, digamos $x_{1}$ y $x_{2}$, cada ecuación lineal define una recta en el plano $(x_{1},x_{2})$. Dado que una solución para el sistema debe satisfacer simultáneamente todas sus ecuaciones, el conjunto solución del mismo corresponde a la intersección de ambas rectas. Esta intersección puede estar representada por otra recta (si las ecuaciones lineales respectivas describen a la misma recta), un punto, o un conjunto vacío (cuando ambas rectas son paralelas). En la Fig. (1.2) se observa un ejemplo geométrico de representación de la solución de un sistema lineal descrito por las ecuaciones\n",
    "\n",
    "$$\\begin{array}{lll}4x_{1}+4x_{2}&=&5\\\\ 2x_{1}-4x_{2}&=&1\\end{array}$$\n",
    "<p style=\"text-align: right;\">$(1.6)$</p>\n",
    "\n",
    "donde el espacio solución es el punto $(x_{1},x_{2})=\\left( 1,\\frac{1}{4} \\right)$.\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_1_2.png\" width=\"400\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (1.2): Representación de la solución de un sistema de dos ecuaciones lineales con solución única. La solución del sistema corresponde a la intersección de las rectas que resultan de cada ecuación del mismo</p>\n",
    "\n",
    "Similarmente, para un sistema de tres ecuaciones, cada ecuación describe un plano en el espacio $\\mathbb{R}^{3}$. Cuando intersectamos estos planos (satisfacer las tres ecuaciones de manera simultánea), podemos obtener un conjunto solución que puede ser un plano, una recta, un punto o un conjunto vacío (cuando los planos no tienen una intersección común).\n",
    "\n",
    "Para construir un enfoque sistemático a fin de resolver de manera general un sistema lineal de ecuaciones, introduciremos una notación compacta muy útil para estos efectos. Vamos a construir un arreglo vectorial con los coeficientes $a_{ij}$ y, a su vez, arreglaremos cada uno de estos vectores en una estructura más general, conocida como **matriz**. En otras palabras, escribiremos el sistema de ecuaciones (1.2) como\n",
    "\n",
    "$$\\left( \\begin{matrix}a_{11}\\\\ \\vdots \\\\ a_{m1}\\end{matrix} \\right)  x_{1}+\\left( \\begin{matrix}a_{12}\\\\ \\vdots \\\\ a_{m2}\\end{matrix} \\right)  x_{2}+\\cdots +\\left( \\begin{matrix}a_{1n}\\\\ \\vdots \\\\ a_{mn}\\end{matrix} \\right)  x_{n}=\\left( \\begin{matrix}b_{1}\\\\ \\vdots \\\\ b_{m}\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.7)$</p>\n",
    "\n",
    "El cual puede reordenarse conforme el uso de matrices como\n",
    "\n",
    "$$\\left( \\begin{matrix}a_{11}&\\cdots &a_{1n}\\\\ \\vdots &\\ddots &\\vdots \\\\ a_{m1}&\\cdots &a_{mn}\\end{matrix} \\right)  \\left( \\begin{matrix}x_{1}\\\\ \\vdots \\\\ x_{n}\\end{matrix} \\right)  =\\left( \\begin{matrix}b_{1}\\\\ \\vdots \\\\ b_{m}\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.8)$</p>\n",
    "\n",
    "En la siguiente subsección, nos detendremos a revisar el concepto de matriz y definiremos ciertas reglas para operar con ellas. Una vez hecho eso, volveremos al tema de los sistemas lineales de ecuaciones para mostrar como resolverlos usando estos maravillosos artilugios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2347d",
   "metadata": {},
   "source": [
    "## Matrices.\n",
    "Las matrices juegan un papel fundamental en el álgebra lineal. Pueden ser utilizadas para representar de manera compacta sistemas de ecuaciones lineales, además de otras entidades con un trasfondo mucho más profundo, como es el caso de las trasformaciones lineales (y que veremos más adelante). Antes de discutir estos tópicos (que resultan ser ciertamente muy interesantes), primero definiremos qué es una matriz y qué podemos hacer con ellas. Veremos más propiedades de las matrices cuando comencemos a abordar temas un tanto más complejos y que tienen aplicaciones muy importantes en el contexto de la ciencia de datos, como las descomposiciones matriciales.\n",
    "\n",
    "**<font color='blue'>Definición 1.1 – Matriz:</font>** Sean $m$ y $n$ dos números naturales. Una matriz con valores reales de dimensión $m\\times n$, que denotamos como $\\mathbf{A}$, es un arreglo rectangular con $m$ filas y $n$ columnas, donde cada valor en la posición $(i, j)$ es denotado como $a_{ij}$, siendo $1\\leq i\\leq m$ y $1\\leq j\\leq n$ y $a_{ij}\\in \\mathbb{R}$. La matriz $\\mathbf{A}$ puede ser escrita entonces como\n",
    "\n",
    "$$\\mathbf{A} =\\left( \\begin{matrix}a_{11}&a_{12}&\\cdots &a_{1n}\\\\ a_{21}&a_{22}&\\cdots &a_{2n}\\\\ \\vdots &\\vdots &\\ddots &\\vdots \\\\ a_{m1}&a_{m2}&\\cdots &a_{mn}\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.9)$</p>\n",
    "\n",
    "Por convención, las matrices de dimensión $1\\times n$ son llamadas **matrices fila**, mientras que aquellas de dimensión $m\\times 1$ son llamadas **matrices columna**. El conjunto de todas las matrices con elementos reales de dimensión $m\\times n$ suele escribirse como $\\mathbb{M}_{\\mathbb{R}}(m,n)$ o $\\mathbb{R}^{m\\times n}$. Esta última notación suele utilizarse para representar que las matrices simplemente son *arreglos rectangulares* que pueden ser *redimensionados* de la forma que queramos, mientras mantengamos su **dimensión** constante; esto es, la multiplicación del número de filas y columnas, $mn$. Dicha dimensión suele denotarse como $\\dim(\\mathbf{A})$.\n",
    "\n",
    "Una matriz así definida suele definirse rápidamente como $\\mathbf{A}=\\left\\{ a_{ij}\\right\\}\\in \\mathbb{R}^{m\\times n}$.\n",
    "\n",
    "Una interpretación geométrica del redimensionamiento se observa en la Fig. (1.3). Librerías de Python especializadas en el análisis de datos como **<font color='darkmagenta'>Numpy</font>** hacen un uso intensivo del redimensionamiento a fin de compatibilizar arreglos de números para la realización de un sinnúmero de operaciones.\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_1_3.png\" width=\"200\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (1.3): Representación geométrica del redimensionamiento de matrices</p>\n",
    "\n",
    "### Adición y multiplicación de matrices.\n",
    "Sean las matrices $\\mathbf{A}=\\left\\{ a_{ij}\\right\\}\\in \\mathbb{R}^{m\\times n}$ y $\\mathbf{B}=\\left\\{ b_{ij}\\right\\}\\in \\mathbb{R}^{m\\times n}$. La **suma** $\\mathbf{A}+\\mathbf{B}$ de ambas matrices da lugar a otra matriz, de las mismas dimensiones, definida como\n",
    "\n",
    "$$\\mathbf{A} +\\mathbf{B} :=\\left( \\begin{matrix}a_{11}+b_{11}&\\cdots &a_{1n}+b_{1n}\\\\ \\vdots &\\ddots &\\vdots \\\\ a_{m1}+b_{m1}&\\cdots &a_{mn}+b_{mn}\\end{matrix} \\right)  =\\left\\{ a_{ij}+b_{ij}\\right\\}  \\in \\mathbb{R}^{m\\times n} $$\n",
    "<p style=\"text-align: right;\">$(1.10)$</p>\n",
    "\n",
    "Por otro lado, sean las matrices $\\mathbf{A} =\\left\\{ a_{is}\\right\\}  \\in \\mathbb{R}^{n\\times k} ,\\mathbf{B} =\\left\\{ b_{sj}\\right\\}  \\in \\mathbb{R}^{k\\times n}$. Los elementos $\\left\\{ c_{ij}\\right\\}$ de la **matriz producto** $\\mathbf{C}=\\mathbf{A}\\mathbf{B}\\in \\mathbb{R}^{m\\times n}$ se definen como\n",
    "\n",
    "$$c_{ij}=\\sum^{k}_{s=1} a_{is}b_{sj}\\  ;\\  i=1,...,m\\wedge j=1,...,n$$\n",
    "<p style=\"text-align: right;\">$(1.11)$</p>\n",
    "\n",
    "Por lo tanto, para computar el elemento $\\left\\{ c_{ij}\\right\\}$ de la matriz $\\mathbf{C}$, multiplicamos los elementos de la $i$-ésima fila de $\\mathbf{A}$ con los elementos de la $j$-ésima columna de $\\mathbf{B}$, y luego sumamos todos los productos obtenidos. La multiplicación de matrices así definida pone de manifiesto que las matrices $\\mathbf{A}$ y $\\mathbf{B}$ deben ser **compatibles** para su realización. Por ejemplo, una matriz $\\mathbf{A}\\in \\mathbb{R}^{m\\times k}$ puede multiplicarse con otra matriz $\\mathbf{B}\\in \\mathbb{R}^{k\\times n}$, pero solamente de izquierda a derecha. Es decir,\n",
    "\n",
    "$$\\underbrace{\\mathbf{A} }_{m\\times k} \\  \\underbrace{\\mathbf{B} }_{k\\times n} =\\underbrace{\\mathbf{C} }_{m\\times n}$$\n",
    "<p style=\"text-align: right;\">$(1.12)$</p>\n",
    "\n",
    "El producto $\\mathbf{B}\\mathbf{A}$ no está definido si $m\\neq n$, ya que, de no ser así, las dimensiones respectivas no son compatibles.\n",
    "\n",
    "Cabe destacar que la multiplicación matricial, por lo tanto, no es una operación que se realiza componente a componente; es decir, $c_{ij}\\neq a_{ij}b_{ij}$ (incluso si el tamaño de las matrices $\\mathbf{A}$ y $\\mathbf{B}$ ha sido elegido apropiadamente). Este tipo de multiplicación aparece con frecuencia en lenguajes de programación cuando multiplicamos arreglos multidimensionales entre sí (por ejemplo, es característica de la multiplicación convencional de arreglos en **<font color='darkmagenta'>Numpy</font>**) y, formalmente, se conoce como producto de Hadamard. Dicho producto se denota como $\\mathbf{A} \\odot \\mathbf{B}$, y puede definirse como\n",
    "\n",
    "$$\\mathbf{A} \\odot \\mathbf{B} =\\left\\{ a_{ij}b_{ij}\\right\\}  =\\left( \\begin{matrix}a_{11}b_{11}&\\cdots &a_{1n}b_{1n}\\\\ \\vdots &\\ddots &\\vdots \\\\ a_{m1}b_{m1}&\\cdots &a_{mn}b_{mn}\\end{matrix} \\right)  \\in \\mathbb{R}^{m\\times n}$$\n",
    "<p style=\"text-align: right;\">$(1.13)$</p>\n",
    "\n",
    "**Ejemplo 1.3 – Una implementación del producto matricial en <font color='darkmagenta'>Numpy</font>:** Las matrices $\\mathbf{A}$ y $\\mathbf{B}$, definidas como\n",
    "\n",
    "$$\\mathbf{A} =\\left( \\begin{matrix}1&2&3\\\\ 3&2&1\\end{matrix} \\right)  \\  ;\\  \\mathbf{B} =\\left( \\begin{matrix}0&2\\\\ 1&-1\\\\ 0&1\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.14)$</p>\n",
    "\n",
    "son compatibles para la multiplicación en ambos sentidos. De esta manera, tenemos que:\n",
    "\n",
    "$$\\mathbf{A} \\mathbf{B} =\\left( \\begin{matrix}1&2&3\\\\ 3&2&1\\end{matrix} \\right)  \\left( \\begin{matrix}0&2\\\\ 1&-1\\\\ 0&1\\end{matrix} \\right)  =\\left( \\begin{matrix}2&3\\\\ 2&5\\end{matrix} \\right)  \\  ;\\  \\mathbf{B} \\mathbf{A} =\\left( \\begin{matrix}0&2\\\\ 1&-1\\\\ 0&1\\end{matrix} \\right)  \\left( \\begin{matrix}1&2&3\\\\ 3&2&1\\end{matrix} \\right)  =\\left( \\begin{matrix}6&4&2\\\\ -2&0&2\\\\ 3&2&1\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.15)$</p>\n",
    "\n",
    "Lo que nos permite verificar que la multiplicación matricial no es una operación conmutativa. Es decir, $\\mathbf{A} \\mathbf{B}\\neq \\mathbf{B} \\mathbf{A}$. Este hecho se ilustra en la Fig. (1.4).\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_1_4.png\" width=\"500\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (1.4): Representación geométrica de la multiplicación de matrices</p>\n",
    "\n",
    "En **<font color='darkmagenta'>Numpy</font>**, es posible multiplicar matrices fácilmente haciendo uso del operador `@`, o bien, mediante la función `numpy.matmul()`. Si definimos las matrices anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb46b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2e1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las matrices A y B.\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [3, 2, 1]\n",
    "])\n",
    "B = np.array([\n",
    "    [0, 2],\n",
    "    [1, -1],\n",
    "    [0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70393c24",
   "metadata": {},
   "source": [
    "Entonces tendremos que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d545911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [2, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación AB.\n",
    "A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcdb5bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  4,  2],\n",
       "       [-2,  0,  2],\n",
       "       [ 3,  2,  1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación BA.\n",
    "B @ A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e765bc2c",
   "metadata": {},
   "source": [
    "Estos resultados, naturalmente, son los mismos que obtuvimos previamente. ◼︎\n",
    "\n",
    "**<font color='blue'>Definición 1.2 – Matriz identidad:</font>** En el conjunto $\\mathbb{R}^{n\\times n}$, definimos la matriz identidad $\\mathbf{I}_{n}$ como la matriz de $n\\times n$ que contiene únicamente 1s en su diagonal principal y 0s en el resto de sus posiciones. De esta manera, podemos escribir\n",
    "\n",
    "$$\\mathbf{I}_{n} :=\\left\\{ a_{ij}\\right\\}  \\  ;\\  a_{ij}=\\begin{cases}1&;\\  \\mathrm{si} \\  i=j\\\\ 0&;\\  \\mathrm{si} \\  i\\neq j\\end{cases}$$\n",
    "<p style=\"text-align: right;\">$(1.16)$</p>\n",
    "\n",
    "Ahora que hemos definido la adición y multiplicación de matrices, y la matriz identidad, repasaremos algunas de las propiedades que se pueden definir a partir de la propia aritmética subyacente a estas operaciones:\n",
    "\n",
    "- **(P1) – Asociatividad:** $\\forall \\mathbf{A} \\in \\mathbb{R}^{m\\times n} ,\\mathbf{B} \\in \\mathbb{R}^{n\\times p} ,\\mathbf{C} \\in \\mathbb{R}^{p\\times q} :\\  \\left( \\mathbf{A} \\mathbf{B} \\right)  \\mathbf{C} =\\mathbf{A} \\left( \\mathbf{B} \\mathbf{C} \\right)$\n",
    "- **(P2) – Distributividad:** $\\forall \\mathbf{A} ,\\mathbf{B} \\in \\mathbb{R}^{m\\times n} \\wedge \\mathbf{C} ,\\mathbf{D} \\in \\mathbb{R}^{n\\times p} :\\  \\left( \\mathbf{A} +\\mathbf{B} \\right)  \\mathbf{C} =\\mathbf{A} \\mathbf{C} +\\mathbf{B} \\mathbf{C}$\n",
    "- **(P3) – Elemento neutro:** $\\forall \\mathbf{A} \\in \\mathbb{R}^{m\\times n} :\\  \\mathbf{I}_{m} \\mathbf{A} =\\mathbf{A} \\mathbf{I}_{n} =\\mathbf{A}$\n",
    "\n",
    "Notemos que, en (P3), $\\mathbf{I}_{m}\\neq \\mathbf{I}_{n}$ si $m\\neq n$.\n",
    "\n",
    "### Matriz inversa y transpuesta.\n",
    "Vamos a ampliar el conjunto de operaciones algebraicas disponibles para las matrices introduciendo dos conceptos nuevos aplicables a este tipo de objetos.\n",
    "\n",
    "**<font color='blue'>Definición 1.3 – Matriz inversa:</font>** Consideremos una **matriz cuadrada** (esto es, una matriz con el mismo número de filas que de columnas) denotada como $\\mathbf{A}\\in \\mathbb{R}^{n\\times n}$. Sea $\\mathbf{b}\\in \\mathbb{R}^{n\\times n}$ otra matriz cuadrada tal que $\\mathbf{A}\\mathbf{B}=\\mathbf{B}\\mathbf{A}=\\mathbf{I}_{n}$. La matriz $\\mathbf{B}$ es llamada **inversa** de $\\mathbf{A}$, y es denotada como $\\mathbf{A}^{-1}$.\n",
    "\n",
    "Desafortunadamente, no toda matriz $\\mathbf{A}$ posee una inversa $\\mathbf{A}^{-1}$. Si tal inversa existe, la matriz $\\mathbf{A}$ se denomina **invertible** o **no singular**. Además, en caso de que la inversa exista, ésta siempre es única. Cuando retomemos el estudio de la resolución de un sistema de ecuaciones lineales, veremos un método general para calcular la inversa de cualquier matriz no singular.\n",
    "\n",
    "Sin embargo, veamos el caso particular del cálculo de la inversa para una matriz cuadrada $\\mathbf{A}\\in \\mathbb{R}^{2\\times 2}$. En este caso, tenemos que\n",
    "\n",
    "$$\\mathbf{A} \\mathbf{A}^{-1} =\\left( \\begin{matrix}1&0\\\\ 0&1\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.17)$</p>\n",
    "\n",
    "Por lo tanto, podemos escribir\n",
    "\n",
    "$$\\mathbf{A} \\mathbf{A}^{-1} =\\left( \\begin{matrix}a_{11}a_{22}-a_{12}a_{21}&0\\\\ 0&a_{11}a_{22}-a_{12}a_{21}\\end{matrix} \\right)  =\\left( a_{11}a_{22}-a_{12}a_{21}\\right)  \\mathbf{I}_{2}$$\n",
    "<p style=\"text-align: right;\">$(1.18)$</p>\n",
    "\n",
    "Así que, al final, obtenemos\n",
    "\n",
    "$$\\mathbf{A} \\mathbf{A}^{-1} =\\frac{1}{a_{11}a_{22}-a_{12}a_{21}} \\left( \\begin{matrix}a_{22}&-a_{12}\\\\ -a_{21}&a_{11}\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.19)$</p>\n",
    "\n",
    "Lo que se cumple si y sólo si $a_{11}a_{22}-a_{12}a_{21}\\neq 0$. Más adelante, al abordar el concepto de descomposición matricial, veremos que la cantidad $a_{11}a_{22}-a_{12}a_{21}$ es llamada **determinante** de la matriz $\\mathbf{A}\\in \\mathbb{R}^{2\\times 2}$. Además, verificaremos que la existencia de dicho determinante, y que éste no sea nulo, son condiciones necesarias y suficientes para determinar la existencia de la inversa de una matriz cuadrada.\n",
    "\n",
    "**<font color='blue'>Definición 1.4 – Matriz transpuesta:</font>** Para la matriz $\\mathbf{A}\\in \\mathbb{R}^{m\\times n}$, se tendrá que la matriz $\\mathbf{B}\\in \\mathbb{R}^{n\\times m}$ cuyos elementos son tales que $b_{ji}=a_{ij}$, es llamada **matriz transpuesta** de $\\mathbf{A}$, y se denota como $\\mathbf{B}=\\mathbf{A}^{\\top }$. Es decir, la matriz transpuesta $\\mathbf{A}^{\\top }$ resulta simplemente de intercambiar las filas por las columnas de $\\mathbf{A}$.\n",
    "\n",
    "A continuación, se listan algunas importantes propiedades de las matrices inversas y transpuestas:\n",
    "\n",
    "- **(P1):** $\\mathbf{A} \\mathbf{A}^{-1} =\\mathbf{A}^{-1} \\mathbf{A} =\\mathbf{I}_{n} \\  ;\\  \\forall \\mathbf{A} \\in \\mathbb{R}^{n\\times n}$.\n",
    "- **(P2):** $\\left( \\mathbf{A} \\mathbf{B} \\right)^{-1}  =\\mathbf{B}^{-1} \\mathbf{A}^{-1} \\  ;\\  \\forall \\mathbf{A} ,\\mathbf{B} \\in \\mathbb{R}^{n\\times n}$.\n",
    "- **(P3):** $\\left( \\mathbf{A} +\\mathbf{B} \\right)^{-1}  \\neq \\mathbf{A}^{-1} +\\mathbf{B}^{-1} \\  ;\\  \\forall \\mathbf{A} ,\\mathbf{B} \\in \\mathbb{R}^{n\\times n}$.\n",
    "- **(P4):** $\\left( \\mathbf{A}^{\\top } \\right)^{\\top }  =\\mathbf{A} \\  ;\\  \\forall \\mathbf{A} \\in \\mathbb{R}^{n\\times n}$.\n",
    "- **(P5):** $\\left( \\mathbf{A} +\\mathbf{B} \\right)^{\\top }  =\\mathbf{A}^{\\top } +\\mathbf{B}^{\\top } \\  ;\\  \\forall \\mathbf{A} ,\\mathbf{B} \\in \\mathbb{R}^{n\\times n}$.\n",
    "- **(P6):** $\\left( \\mathbf{A} \\mathbf{B} \\right)^{\\top }  =\\mathbf{B}^{\\top } \\mathbf{A}^{\\top } \\  ;\\  \\forall \\mathbf{A} ,\\mathbf{B} \\in \\mathbb{R}^{n\\times n}$.\n",
    "\n",
    "**<font color='blue'>Definición 1.5 – Matriz simétrica:</font>** Sea la matriz cuadrada $\\mathbf{A} \\in \\mathbb{R}^{n\\times n}$. Diremos que $\\mathbf{A}$ es **simétrica** si $\\mathbf{A}=\\mathbf{A}^{\\top}$.\n",
    "\n",
    "Notemos que, naturalmente, sólo las matrices cuadradas pueden ser simétricas. Además, si una matriz cuadrada es invertible, es posible demostrar que su transpuesta también lo es.\n",
    "\n",
    "**Ejemplo 1.4 – Transposición e inversión de matrices en <font color='darkmagenta'>Numpy</font>:** En <font color='darkmagenta'>Numpy</font> es posible transponer e invertir matrices de manera sencilla, aprovechando la flexibilidad del objeto `numpy.ndarray` y su capacidad de representar matrices cuando éste es bidimensional. De esta manera, si consideramos, por ejemplo, la matriz $\\mathbf{A}$ definida como\n",
    "\n",
    "$$\\mathbf{A} =\\left( \\begin{matrix}-1&0&2&1\\\\ -4&9&-1&-8\\\\ 0&1&0&-4\\\\ 5&-6&0&3\\end{matrix} \\right)  \\in \\mathbb{R}^{4\\times 4}$$\n",
    "<p style=\"text-align: right;\">$(1.20)$</p>\n",
    "\n",
    "Ésta puede definirse en <font color='darkmagenta'>Numpy</font> como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "075fedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la matriz A.\n",
    "A = np.array([\n",
    "    [-1, 0, 2, 1],\n",
    "    [-4, 9, -1, -8],\n",
    "    [0, 1, 0, -4],\n",
    "    [5, -6, 0, 3],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be981b2",
   "metadata": {},
   "source": [
    "La transpuesta de `A` puede obtenerse por medio del atributo `T`. Mientras que su inversa puede calcularse rápidamente usando la función `numpy.invert()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81b01f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -4,  0,  5],\n",
       "       [ 0,  9,  1, -6],\n",
       "       [ 2, -1,  0,  0],\n",
       "       [ 1, -8, -4,  3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpuesta de A.\n",
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ce8044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  -1,  -3,  -2],\n",
       "       [  3, -10,   0,   7],\n",
       "       [ -1,  -2,  -1,   3],\n",
       "       [ -6,   5,  -1,  -4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inversa de A.\n",
    "np.invert(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ef01fce",
   "metadata": {},
   "source": [
    "◼︎\n",
    "\n",
    "### Multiplicación de una matriz por un escalar.\n",
    "Sea $\\mathbf{A}=\\left\\{ a_{ij}\\right\\}  \\in \\mathbb{R}^{m\\times n}$ y $\\lambda \\in \\mathbb{R}$. Entonces se tiene que $\\lambda \\mathbf{A}=\\mathbf{K}\\in \\mathbb{R}^{m\\times n}$, donde $k_{ij}=\\lambda a_{ij}$. Por lo tanto, la multiplicación de una matriz $\\mathbf{A}$ por un escalar $\\lambda$ resulta en otra matriz $\\mathbf{K}$, donde cada uno de sus elementos $k_{ij}$ no es más que el correspondiente elemento $a_{ij}$ de $\\mathbf{A}$ multiplicado por $\\lambda$.\n",
    "\n",
    "Para $\\lambda, \\psi \\in \\mathbb{R}$, se cumplen las siguientes propiedades:\n",
    "\n",
    "- **(P1) – Asociatividad:** $\\left( \\lambda \\psi \\right)  \\mathbf{C} =\\lambda \\left( \\psi \\mathbf{C} \\right)  ;\\  \\mathbf{C} \\in \\mathbb{R}^{m\\times n} \\wedge \\lambda \\left( \\mathbf{B} \\mathbf{C} \\right)  =\\left( \\lambda \\mathbf{B} \\right)  \\mathbf{C} =\\mathbf{B} \\left( \\lambda \\mathbf{C} \\right)  =\\left( \\mathbf{B} \\mathbf{C} \\right)  \\lambda ;\\  \\mathbf{B} \\in \\mathbb{R}^{m\\times n} ,\\mathbf{C} \\in \\mathbb{R}^{m\\times k}$.\n",
    "- **(P2):** $\\left( \\lambda \\mathbf{C} \\right)^{\\top }  =\\mathbf{C}^{\\top } \\lambda^{\\top } =\\mathbf{C}^{\\top } \\lambda =\\lambda \\mathbf{C}^{\\top } ;\\  \\mathbf{C} \\in \\mathbb{R}^{m\\times n}$, ya que $\\lambda^{\\top } =\\lambda ;\\  \\forall \\lambda \\in \\mathbb{R}$.\n",
    "- **(P3) – Distributividad:** $\\left( \\lambda +\\psi \\right)  \\mathbf{C} =\\lambda \\mathbf{C} +\\psi \\mathbf{C} ;\\  \\mathbf{C} \\in \\mathbb{R}^{m\\times n} \\wedge \\lambda \\left( \\mathbf{B} +\\mathbf{C} \\right)  =\\lambda \\mathbf{B} +\\lambda \\mathbf{C} ;\\  \\mathbf{B} ,\\mathbf{C} \\in \\mathbb{R}^{m\\times n}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db9119ca",
   "metadata": {},
   "source": [
    "## Solución de un sistema lineal de ecuaciones.\n",
    "\n",
    "### Representación matricial de un sistema lineal de ecuaciones.\n",
    "Si consideramos el siguiente sistema lineal de ecuaciones\n",
    "\n",
    "$$\\begin{array}{rcl}a_{11}x_{1}+a_{12}x_{2}+\\cdots +a_{1n}x_{n}&=&b_{1}\\\\ a_{21}x_{1}+a_{22}x_{2}+\\cdots +a_{2n}x_{n}&=&b_{2}\\\\ &\\vdots &\\\\ a_{m1}x_{1}+a_{m2}x_{2}+\\cdots +a_{mn}x_{n}&=&b_{m}\\end{array}$$\n",
    "<p style=\"text-align: right;\">$(1.21)$</p>\n",
    "\n",
    "Y usamos las reglas de la multiplicación matricial, podemos escribir dicho sistema de una forma más compacta como\n",
    "\n",
    "$$\\left( \\begin{matrix}a_{11}&a_{12}&\\cdots &a_{1n}\\\\ a_{21}&a_{22}&\\cdots &a_{2n}\\\\ \\vdots &\\vdots &\\ddots &\\vdots \\\\ a_{m1}&a_{m2}&\\cdots &a_{mn}\\end{matrix} \\right)  \\left( \\begin{matrix}x_{1}\\\\ x_{2}\\\\ \\vdots \\\\ x_{n}\\end{matrix} \\right)  =\\left( \\begin{matrix}b_{1}\\\\ b_{2}\\\\ \\vdots \\\\ b_{m}\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.22)$</p>\n",
    "\n",
    "En general, un sistema de $m$ ecuaciones lineales con $n$ incógnitas puede escribirse de manera compacta como $\\mathbf{A} \\mathbf{x} =\\mathbf{b}$, donde $\\mathbf{A} \\in \\mathbb{R}^{m\\times n}$, $\\mathbf{x} \\in \\mathbb{R}^{n\\times 1}$ y $\\mathbf{b} \\in \\mathbb{R}^{m\\times 1}$. Los números $a_{ij}, b_{i}\\in \\mathbb{R}$ son parámetros conocidos y el conjunto $\\left\\{ x_{j}\\right\\}^{n}_{j=1}$ contiene las **incógnitas** del sistema. A continuación, nos enfocaremos en la solución de sistemas como (1.21), describiendo un algoritmo general para ello que, además, nos permitirá determinar la inversa de una matriz no singular.\n",
    "\n",
    "**Ejemplo 1.5 - Solución general y particular de un sistema:** Antes de discutir cómo resolver un sistema lineal de ecuaciones, consideremos un ejemplo preliminar:\n",
    "\n",
    "$$\\left( \\begin{matrix}1&0&8&-4\\\\ 0&1&2&12\\end{matrix} \\right)  \\left( \\begin{matrix}x_{1}\\\\ x_{2}\\\\ x_{3}\\\\ x_{4}\\end{matrix} \\right)  =\\left( \\begin{matrix}42\\\\ 8\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.23)$</p>\n",
    "\n",
    "El sistema (1.23) tiene dos ecuaciones y cuatro incógnitas. Por lo tanto, en general, esperaríamos que éste tenga infinitas soluciones. Dicho sistema se ha presentado en una forma que resulta bastante sencilla, puesto que las primeras dos columnas consisten únicamente de 1s y 0s. Recordemos que queremos encontrar escalares $x_{1},...,x_{4}$ tales que $\\sum\\nolimits^{4}_{j=1} \\mathbf{c}_{j} x_{j}=\\mathbf{b}$, donde $\\mathbf{c}_{j}$ es la $j$-ésima columna de la matriz $\\mathbf{A}$, que a su vez se conoce como **matriz de coeficientes del sistema**, mientras que $\\mathbf{b}$ es la matriz columna que se encuentra a la derecha del sistema (1.23) tomando 42 veces la primera columna y 8 veces la segunda, de manera que\n",
    "\n",
    "$$\\mathbf{b} =\\left( \\begin{matrix}42\\\\ 8\\end{matrix} \\right)  =42\\left( \\begin{matrix}1\\\\ 0\\end{matrix} \\right)  +8\\left( \\begin{matrix}0\\\\ 1\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.24)$</p>\n",
    "\n",
    "De esta manera, el vector $\\mathbf{x}=(42,8,0,0)^{\\top}$ es una solución del sistema (1.23). Una solución de este tipo es llamada **solución particular** del sistema respectivo. Sin embargo, esta no es la única solución de (1.23). Para capturar el resto de las soluciones, necesitamos ser algo creativos, generando convenientemente un cero por medio de las columnas de la matriz de coeficientes del sistema. Para ello, expresamos la tercera columna por medio del uso de las primeras dos de la forma\n",
    "\n",
    "$$\\left( \\begin{matrix}8\\\\ 2\\end{matrix} \\right)  =8\\left( \\begin{matrix}1\\\\ 0\\end{matrix} \\right)  +2\\left( \\begin{matrix}0\\\\ 1\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.25)$</p>\n",
    "\n",
    "Por lo tanto, se tiene que $\\mathbf{0} =8\\mathbf{c}_{1} +2\\mathbf{c}_{2} -1\\mathbf{c}_{3} +0\\mathbf{c}_{4}$ y $\\left( x_{1},x_{2},x_{3},x_{4}\\right)  =\\left( 8,2,-1,0\\right)$. De hecho, cualquier escalamiento a esta solución por un factor $\\lambda \\in \\mathbb{R}$ produce el vector $\\mathbf{0}$, ya que\n",
    "\n",
    "$$\\left( \\begin{matrix}1&0&8&-4\\\\ 0&1&2&12\\end{matrix} \\right)  \\left( \\lambda_{1} \\left( \\begin{matrix}8\\\\ 2\\\\ -1\\\\ 0\\end{matrix} \\right)  \\right)  =\\lambda_{1} \\left( 8\\mathbf{c}_{1} +2\\mathbf{c}_{2} -\\mathbf{c}_{3} \\right)  =\\mathbf{0}$$\n",
    "<p style=\"text-align: right;\">$(1.26)$</p>\n",
    "\n",
    "Siguiendo el mismo razonamiento, expresamos la cuarta columna de la matriz de coeficientes del sistema usando sus primeras dos columnas como\n",
    "\n",
    "$$\\left( \\begin{matrix}1&0&8&-4\\\\ 0&1&2&12\\end{matrix} \\right)  \\left( \\lambda_{2} \\left( \\begin{matrix}-4\\\\ 12\\\\ 0\\\\ -1\\end{matrix} \\right)  \\right)  =\\lambda_{2} \\left( -4\\mathbf{c}_{1} +12\\mathbf{c}_{2} -\\mathbf{c}_{4} \\right)  =\\mathbf{0}$$\n",
    "<p style=\"text-align: right;\">$(1.27)$</p>\n",
    "\n",
    "Donde $\\lambda_{2}\\in \\mathbb{R}$. Uniendo las expresiones encontradas en (1.26) y (1.27), podemos construir el **conjunto solución** (con infinitos elementos) del sistema (1.23), denominado **solución general** $S$ del mismo, de manera tal que\n",
    "\n",
    "$$S=\\left\\{ \\mathbf{x} \\in \\mathbb{R}^{4} :\\mathbf{x} =\\left( \\begin{matrix}42\\\\ 8\\\\ 0\\\\ 0\\end{matrix} \\right)  +\\lambda_{1} \\left( \\begin{matrix}8\\\\ 2\\\\ -1\\\\ 0\\end{matrix} \\right)  +\\lambda_{2} \\left( \\begin{matrix}-4\\\\ 12\\\\ 0\\\\ -1\\end{matrix} \\right)  ;\\lambda_{1} ,\\lambda_{2} \\in \\mathbb{R} \\right\\}$$\n",
    "<p style=\"text-align: right;\">$(1.28)$</p>\n",
    "\n",
    "◼︎\n",
    "\n",
    "El procedimiento general que puede desprenderse del ejemplo anterior es el siguiente:\n",
    "\n",
    "- Encontrar una solución particular del sistema $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$.\n",
    "- Encontrar todas las soluciones del sistema $\\mathbf{A}\\mathbf{x}=\\mathbf{0}$.\n",
    "- Combinar las soluciones encontradas en los pasos anteriores para construir la solución general.\n",
    "\n",
    "Por extensión, ni la solución general ni la solución particular son únicas.\n",
    "\n",
    "El sistema de ecuaciones (1.23) fue fácil de resolver, porque la matriz $\\mathbf{A}$ de coeficientes del sistema tenía una forma particular en sus primeras dos columnas que permitía su solución por medio de simple inspección. Sin embargo, en general, los sistemas de ecuaciones lineales no tienen esta forma tan particular. Afortunadamente, existe un método que permite transformar cualquier sistema de ecuaciones lineales en uno del tipo visto en (1.23) (de hecho, tal estructura es conocida en álgebra como *matriz triangular superior*), conocido como **eliminación Gaussiana**. Su piedra fundamental está constituida por una serie de operaciones algebraicas conocidas como **transformaciones elementales de una matriz**, las que permiten, en general, transformar cualquier matriz arbitraria en una matriz triangular inferior.\n",
    "\n",
    "**<font color='blue'>Definición 1.6 – Diagonal principal:</font>** Sea $\\mathbf{A}=\\left\\{ a_{ij}\\right\\}  \\in \\mathbb{R}^{n\\times n}$ una matriz cuadrada de orden $n$. Se define la diagonal principal de $\\mathbf{A}$ como el conjunto $\\left\\{ a_{ij}|\\  i=j\\right\\}$. La suma de los elementos que constituyen dicha diagonal principal es conocida como traza de la matriz $\\mathbf{A}$, y se denota como $\\mathrm{tr}(\\mathbf{A})$.\n",
    "\n",
    "**<font color='blue'>Definición 1.7 – Matriz triangular:</font>** Una **matriz triangular** es un tipo especial de matriz cuadrada cuyos elementos por encima o por debajo de su diagonal principal son cero. Si los elementos nulos se ubican por debajo de la diagonal principal, la matriz es llamada **triangular superior**, y toma la forma\n",
    "\n",
    "$$\\mathbf{U} =\\left( \\begin{matrix}u_{11}&u_{12}&u_{13}&\\cdots &u_{1n}\\\\ 0&u_{22}&u_{23}&\\cdots &u_{2n}\\\\ 0&0&u_{33}&\\cdots &u_{3n}\\\\ \\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\ 0&0&0&\\cdots &u_{nn}\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.29)$</p>\n",
    "\n",
    "Por otro lado, si los elementos nulos se ubican en la parte superior de la diagonal principal, la matriz es llamada **triangular inferior**, y toma la forma\n",
    "\n",
    "$$\\mathbf{L} =\\left( \\begin{matrix}l_{11}&0&0&\\cdots &0\\\\ l_{21}&l_{22}&0&\\cdots &0\\\\ l_{31}&l_{32}&l_{33}&\\cdots &0\\\\ \\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\ l_{n1}&l_{n2}&l_{n3}&\\cdots &l_{nn}\\end{matrix} \\right)$$\n",
    "<p style=\"text-align: right;\">$(1.30)$</p>\n",
    "\n",
    "### Transformaciones elementales sobre una matriz.\n",
    "Las transformaciones elementales de una matriz corresponden a tres operaciones válidas sobre cualquier matriz cuyo objetivo es, como comentamos previamente, llegar a una matriz triangular superior. Dichas operaciones son las siguientes:\n",
    "\n",
    "- Multiplicar una fila cualquiera de una matriz por un escalar $c\\neq 0$. Esta transformación suele denotarse como $F_{i}(c)$, donde $F_{i}$ hace referencia a la fila $i$-ésima que se multiplica por el escalar $c$.\n",
    "- Sumar a una fila de una matriz un múltiplo de otra fila. Esta transformación suele denotarse como $F_{ij}(c)$, donde se referencia que la fila $i$ se multiplica por $c$ y el resultado se suma a la fila $j$.\n",
    "- Intercambiar dos filas cualquiera en una matriz. Esto suele denotarse como $F_{ij}$.\n",
    "\n",
    "Estas tres operaciones elementales son utilizadas para trabajar las matrices que contienen los coeficientes de un sistema lineal de ecuaciones, a fin de transformarlas en matrices triangulares superiores que permiten resolver muy fácilmente tales sistemas mediante sustituciones regresivas. Este trabajo de sustitución hacia atrás, para el caso de un sistema de $n$ ecuaciones con $n$ incógnitas, toma $n(n-1)/2$ multiplicaciones al reemplazar las incógnitas ya calculadas, y $n$ divisiones por los elementos de la diagonal principal respectiva resultantes después de las operaciones elementales, a fin de despejar la incógnita $x_{i}$.\n",
    "\n",
    "### Método de eliminación Gaussiana.\n",
    "La combinación del uso de las transformaciones elementales sobre una matriz y la construcción de una matriz triangular superior para la resolución de un sistema lineal de ecuaciones por simple sustitución regresiva se conoce como **método de eliminación Gaussiana**. Corresponde a un algoritmo que suele ser utilizado para la resolución analítica de sistemas lineales a nivel computacional por una gran cantidad de paquetes informáticos. Estos, por supuesto, incluyen a librerías de Python, como <font color='darkmagenta'>Numpy</font> y <font color='darkmagenta'>Scipy</font>.\n",
    "\n",
    "**<font color='blue'>Definición 1.8 – Matriz ampliada de un sistema:</font>** Consideremos un sistema lineal de ecuaciones del tipo $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$, donde $\\mathbf{A}$ es la matriz de coeficientes del sistema. La matriz resultante de añadir $\\mathbf{b}$ a la derecha de la última columna de $\\mathbf{A}$, y denotada como $[\\mathbf{A}|\\mathbf{b}]$, se conoce como la **matriz ampliada del sistema**.\n",
    "\n",
    "**<font color='blue'>Definición 1.9 – Pivote:</font>** El elemento $a_{qq}\\neq 0$ utilizado para eliminar los elementos $a_{rq}$ para $r=q+1,q+2,...,n$ en la matriz $\\mathbf{A}\\in \\mathbb{R}^{n\\times n}$ es llamado **elemento pivote** de la fila $q$, donde $1\\leq q\\leq n$.\n",
    "\n",
    "**<font color='blue'>Definición 1.10 – Multiplicadores:</font>** Los números $m_{rq}=a_{rq}/a_{qq}$ por el cual se multiplica la fila que contiene a un elemento pivote para luego aplicar la operación elemental relativa a sumar o restar a la fila $r$, con $r=q+1,q+2,...,n$, para así llegar a una matriz triangular (superior) se conocen como **multiplicadores**.\n",
    "\n",
    "Las operaciones elementales, junto con los elementos pivotes y los multiplicadores, nos permiten, cuando esto sea posible, transformar la matriz ampliada de un sistema de ecuaciones lineales, en una matriz triangular superior (o inferior, si se prefiere) y resolver el sistema equivalente, por sustitución regresiva (o progresiva, si se quiere)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
