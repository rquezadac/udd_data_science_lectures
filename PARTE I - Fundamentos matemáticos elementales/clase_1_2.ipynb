{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b3920e5",
   "metadata": {},
   "source": [
    "# CLASE 1.2: Espacios vectoriales con producto interno\n",
    "---\n",
    "\n",
    "## Introducción.\n",
    "En la sección anterior, estudiamos los conceptos de vectores, espacios vectoriales y transformaciones lineales en términos generales, pero además, completamente abstractos. En esta sección, añadiremos a estos conceptos abstractos algunas interpretaciones geométricas a fin de construir un cierto nivel de intuición respecto de estos conceptos. En particular, visualizaremos vectores desde una perspectiva geométrica y calcularemos sus longitudes y distancias o ángulos con respecto a otros vectores. Para poder hacer esto, vamos a equipar a los espacios vectoriales con una operación especial conocida como producto interno, cuya propiedad fundamental será la inducción de la geometría relativa al espacio vectorial respectivo.\n",
    "\n",
    "Los productos internos y sus normas correspondientes y métricas nos permiten capturar las nociones intuitivas de distancia y similitud, las que resultan fundamentales en la construcción de uno de los modelos de machine learning más importantes que existen: Las máquinas de soporte vectorial (support vector machines, SVM). Luego, utilizaremos los conceptos de longitud y ángulo entre vectores para discutir las proyecciones ortogonales, las que jugarán un papel fundamental cuando estudiemos dos de los modelos de aprendizaje más elementales en machine learning: El análisis de componentes principales (que es un modelo de aprendizaje no supervisado) y el modelo de regresión lineal (que es un modelo de aprendizaje supervisado)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc07fcfa",
   "metadata": {},
   "source": [
    "## Producto interno.\n",
    "Cuando pensamos en vectores desde una perspectiva puramente geométrica; es decir, líneas dirigidas que parten desde el origen y terminan en un punto determinado, siempre hemos asociado a estos vectores el concepto de longitud del mismo en términos de la distancia entre el origen y dicho punto. A continuación, formalizaremos esta noción intuitiva mediante el concepto de **norma**.\n",
    "\n",
    "**<font color='blue'>Definición 2.1 – Norma:</font>** Sea $V$ un espacio vectorial que supondremos (sin pérdida de generalidad) definido sobre el cuerpo $\\mathbb{R}$. Para todo $v\\in V$ definimos la función\n",
    "\n",
    "$$\\begin{array}{ll}\\| \\  \\cdot \\  \\| :&V\\longrightarrow \\mathbb{R} \\\\ &v\\longrightarrow \\left\\Vert v\\right\\Vert  \\end{array}$$\n",
    "<p style=\"text-align: right;\">$(2.1)$</p>\n",
    "\n",
    "y que será llamada **norma**. Esta función asigna a $v\\in V$ su **longitud** $\\left\\Vert v\\right\\Vert\\in \\mathbb{R}$, y es tal que, para todo $\\lambda \\in \\mathbb{R}$ y para cualquier otro vector $u\\in V$, cumple con las siguientes propiedades:\n",
    "\n",
    "- **(P1) – Homogeneidad absoluta:** $\\left\\Vert \\lambda v\\right\\Vert  =\\left| \\lambda \\right|  \\left\\Vert v\\right\\Vert$.\n",
    "- **(P2) – Desigualdad triangular:** $\\left\\Vert u+v\\right\\Vert  \\leq \\left\\Vert u\\right\\Vert  +\\left\\Vert v\\right\\Vert$.\n",
    "- **(P3) – Definida positiva:** $\\left\\Vert v\\right\\Vert  \\geq 0\\wedge \\left\\Vert v\\right\\Vert  =0\\Longleftrightarrow v=O_{V}$.\n",
    "\n",
    "En términos geométricos, por ejemplo, la desigualdad triangular puede interpretarse por medio de vectores en $\\mathbb{R}^{n}$ para $n\\leq 3$, estableciendo que, para un triángulo cualquiera, la suma de sus longitudes de dos de sus lados debe ser mayor o igual que la longitud del lado restante (lo que se ilustra en la Fig. (2.1)). \n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_2_1.png\" width=\"400\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (2.1): Una interpretación geométrica sencilla de la desigualdad triangular</p>\n",
    "\n",
    "La definición (2.1) es válida para cualquier espacio vectorial, pero, para efectos prácticos, bastará con que consideremos únicamente a aquellos con dimensión finita (y, puntualmente, nos limitaremos en muchos casos simplemente a $\\mathbb{R}^{n}$.\n",
    "\n",
    "**Ejemplo 2.1 – La norma $\\ell_{1}$:** La definición (2.1) establece las condiciones que debe cumplir una función (denotada como $\\left\\Vert \\cdot \\right\\Vert$) para ser considerada una norma sobre un determinado espacio vectorial (ya que opera con los elementos de dicho espacio). Por esa razón es que existen varios tipos de normas que son utilizadas en muchos campos de las matemáticas. Un ejemplo es la **norma $\\ell_{1}$**, llamada comúnmente **norma Manhattan**, que se define para cualquier vector $\\mathbf{x}\\in \\mathbb{R}^{n}$ (donde $\\mathbf{x}=(x_{1},...,x_{n})$) como\n",
    "\n",
    "$$\\left\\Vert \\mathbf{x} \\right\\Vert_{1}  :=\\sum^{n}_{i=1} \\left| x_{i}\\right|$$\n",
    "<p style=\"text-align: right;\">$(2.2)$</p>\n",
    "\n",
    "Donde $\\left| x_{i}\\right|$ es el valor absoluto de la *componente* $x_{i}$. En la Fig. (2.2a) se muestran todos los puntos en el plano $\\mathbb{R}^{2}$ tales que $\\left\\Vert \\mathbf{x} \\right\\Vert_{1}  =1$. ◼︎\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_2_2.png\" width=\"700\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (2.2): (a) Todos los puntos $\\mathbf{x}$ en el plano tales que $\\left\\Vert \\mathbf{x} \\right\\Vert_{1}  =1$ ; (b) Todos los puntos $\\mathbf{x}$ en el plano tales que $\\left\\Vert \\mathbf{x} \\right\\Vert_{2}  =1$</p>\n",
    "\n",
    "**Ejemplo 2.2 – La norma $\\ell_{2}$:** Otro tipo de norma muy común en las matemáticas (y en el análisis en $\\mathbb{R}^{n}$) corresponde a la **norma $\\ell_{2}$:**, conocida igualmente como **norma Euclidiana**, la que se define para cualquier vector $\\mathbf{x}\\in \\mathbb{R}^{n}$ (donde $\\mathbf{x}=(x_{1},...,x_{n})$) como\n",
    "\n",
    "$$\\left\\Vert \\mathbf{x} \\right\\Vert_{2}  :=\\left( \\sum^{n}_{i=1} x^{2}_{i}\\right)^{\\frac{1}{2} }  =\\sqrt{\\mathbf{x}^{\\top } \\mathbf{x} }$$\n",
    "<p style=\"text-align: right;\">$(2.3)$</p>\n",
    "\n",
    "Esta norma permite calcular la distancia Euclidiana del vector $\\mathbf{x}\\in \\mathbb{R}^{n}$ con respecto al origen del sistema de coordenadas rectangulares. En la Fig. (2.2b) se muestran todos los puntos en el plano $\\mathbb{R}^{2}$ tales que $\\left\\Vert \\mathbf{x} \\right\\Vert_{2}  =1$. La norma $\\ell_{2}$ es una norma que usaremos a menudo durante esta asignatura, y será frecuente que la denotamos como la opción por defecto de la función de norma (poniendo simplemente $\\left\\Vert \\mathbf{x} \\right\\Vert$ en vez de $\\left\\Vert \\mathbf{x} \\right\\Vert_{2}$), salvo que especifiquemos lo contrario. ◼︎\n",
    "\n",
    "La norma es un caso particular de una operación importante en álgebra conocida como **producto interno**, y que definiremos a continuación.\n",
    "\n",
    "**<font color='blue'>Definición 2.2 – Producto interno (general):</font>** Sea $V$ un $\\mathbb{K}$-espacio vectorial. Diremos que la función\n",
    "\n",
    "$$\\begin{array}{ll}\\left< \\  ,\\  \\right>  :&V\\times V\\longmapsto \\mathbb{K} \\\\ &\\left( u,v\\right)  \\longmapsto \\left< u,v\\right>  \\end{array}$$\n",
    "<p style=\"text-align: right;\">$(2.4)$</p>\n",
    "\n",
    "es llamada **producto interno** definido sobre $V$. Esta función cumple con las siguientes propiedades:\n",
    "\n",
    "- **(P1):** $\\left< v,v\\right>  \\geq O_{\\mathbb{K} };\\forall v\\in V\\wedge \\left< v,v\\right>  =O_{\\mathbb{K} }\\Longleftrightarrow v=O_{V}$.\n",
    "- **(P2):** $\\left< u+v,w\\right>  =\\left< u,w\\right>  +\\left< v,w\\right>  ;\\forall u,v,w\\in V$.\n",
    "- **(P3):** $\\left< u,v+w\\right>  =\\left< u,v\\right>  +\\left< v,w\\right>  ;\\forall u,v,w\\in V$.\n",
    "- **(P4):** $\\left< \\lambda u,v\\right>  =\\lambda \\left< u,v\\right>  ;\\forall u,v\\in V\\wedge \\lambda \\in \\mathbb{K}$.\n",
    "- **(P5):** $\\left< u,\\lambda v\\right>  =\\bar{\\lambda } \\left< u,v\\right>  ;\\forall u,v\\in V\\wedge \\lambda \\in \\mathbb{K}$.\n",
    "- **(P6):** $\\left< u,v\\right>  =\\overline{\\left< v,u\\right>  } ;\\forall u,v\\in V$.\n",
    "\n",
    "Cuando un $\\mathbb{K}$-espacio vectorial $V$ está *equipado* con un producto interno, se denomina **espacio vectorial normado o prehilbertiano**.\n",
    "\n",
    "**Ejemplo 2.3:** En $\\mathbb{K}^{n}$ (donde $\\mathbb{K}$ puede ser $\\mathbb{R}$ o $\\mathbb{C}$), definimos, para $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{K}^{n}$, con $\\mathbf{x}=(x_{1},...,x_{n})$ y $\\mathbf{y}=(y_{1},...,y_{n})$,\n",
    "\n",
    "$$\\left< \\mathbf{x} ,\\mathbf{y} \\right>  =\\sum^{n}_{k=1} x_{k}\\overline{y}_{k}$$\n",
    "<p style=\"text-align: right;\">$(2.5)$</p>\n",
    "\n",
    "y lo denominaremos **producto interno canónico en $\\mathbb{K}^{n}$**. Notemos que, cuando $\\mathbb{K}=\\mathbb{R}$, se tiene que $\\overline{y}_{k}=y_{k}$ para todo $k=1,...,n$. En un contexto más geométrico, donde estos vectores suelen describir cantidades físicas, tal producto interno suele denominarse como *producto punto*. ◼︎\n",
    "\n",
    "**Ejemplo 2.4:** En $\\mathbb{R}^{n\\times n}$ definimos, para $\\mathbf{A} =\\left\\{ a_{ij}\\right\\}  \\in \\mathbb{R}^{n\\times n} \\wedge \\mathbf{B} =\\left\\{ b_{ij}\\right\\}  \\in \\mathbb{R}^{n\\times n}$,\n",
    "\n",
    "$$\\left< \\mathbf{A} ,\\mathbf{B} \\right>  =\\mathrm{tr} \\left( \\mathbf{B}^{\\top } \\mathbf{A} \\right)$$\n",
    "<p style=\"text-align: right;\">$(2.6)$</p>\n",
    "\n",
    "y lo denominaremos **producto interno canónico de $\\mathbb{R}^{n\\times n}$**. ◼︎\n",
    "\n",
    "**Ejemplo 2.5:** Definimos el conjunto $C^{k}([a,b])$ como el conjunto de todas las funciones $k$ veces diferenciables sobre el intervalo cerrado $[a,b]$ (es decir, funciones de clase $C^{k}$ en el intervalo cerrado $[a,b]\\in \\mathbb{R}$). La operación definida como\n",
    "\n",
    "$$\\left< f,g\\right>  =\\left< f\\left( x\\right)  ,g\\left( x\\right)  \\right>  =\\int^{b}_{a} f\\left( x\\right)  g\\left( x\\right)  dx$$\n",
    "<p style=\"text-align: right;\">$(2.7)$</p>\n",
    "\n",
    "es llamada **producto interno de las funciones $f$ y $g$ para cada $x\\in [a,b]$**. ◼︎"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "448e187d",
   "metadata": {},
   "source": [
    "## Longitud y distancia.\n",
    "La norma, en general, corresponde a un caso particular de aplicación del producto interno, en el cual el argumento respectivo es siempre el mismo vector. Por esta razón, decimos que un producto interno sobre un espacio vectorial $V$ siempre induce una norma en $V$. En este caso, podemos re-definir la norma en relación a cualquier producto interno, ya que, para todo $v\\in V$, se tendrá que\n",
    "\n",
    "$$\\left\\Vert v\\right\\Vert  :=\\sqrt{\\left< v,v\\right>  }$$\n",
    "<p style=\"text-align: right;\">$(2.8)$</p>\n",
    "\n",
    "La norma corresponde a un concepto que, por tanto, se desprende de forma natural para cualquier espacio vectorial con producto interno. Sin embargo, no todas las normas son inducidas a partir de un producto interno; la norma $\\ell_{1}$ es un ejemplo de norma que no se corresponde con un producto interno y que resulta importante en procedimientos fundamentales propios de muchos algoritmos de machine learning tales como la regularización de hiperparámetros (donde, mediante un procedimiento iterativo, intentamos evitar que nuestros modelos sobreajusten o aprendan de memoria un patrón extremadamente variable dado un conjunto de datos que deseamos representar). Sin embargo, para definir conceptos geométricos claves, como longitudes, distancias y ángulos, nos limitaremos momentáneamente al uso de normas inducidas. Para ello, partiremos con un importante teorema, que generaliza la desigualdad triangular vista en la definición (2.1).\n",
    "\n",
    "**<font color='crimson'>Teorema 2.1 – Desigualdad de Cauchy-Schwarz:</font>** *Sea $V$ un espacio vectorial normado. Para todo par de vectores $u,v\\in V$ se tiene que*\n",
    "\n",
    "$$\\left| \\left< u,v\\right>  \\right|^{2}  \\leq \\left< u,u\\right>  \\left< v,v\\right>  \\Longleftrightarrow \\left| \\left< u,v\\right>  \\right|^{2}  \\leq \\left\\Vert u\\right\\Vert  \\left\\Vert v\\right\\Vert$$\n",
    "<p style=\"text-align: right;\">$(2.9)$</p>\n",
    "◆ \n",
    "\n",
    "**Ejemplo 2.6:** En el campo de la geometría analítica, con frecuencia, estamos interesados en la longitud de un vector. Podemos utilizar el producto interno para calcular tales longitudes por medio de la ecuación (2.8). Por ejemplo, consideremos el vector $\\mathbf{u}=(1, 1)^{\\top}\\in \\mathbb{R}^{2}$. En este caso, a partir de la definición de norma inducida y, en este caso, utilizando la norma $\\ell_{2}$ (que es, de hecho, el producto interno definido en el ejemplo (2.3)), obenemos\n",
    "\n",
    "$$\\left\\Vert \\mathbf{u} \\right\\Vert  =\\sqrt{\\left< \\mathbf{u} ,\\mathbf{u} \\right>  } =\\sqrt{1^{2}+1^{2}} =\\sqrt{2}$$\n",
    "<p style=\"text-align: right;\">$(2.10)$</p>\n",
    "\n",
    "y que corresponde a la longitud del vector $\\mathbf{u}$. Por otro lado, es posible demostrar que la expresión\n",
    "\n",
    "$$\\mathbf{u}^{\\top } \\mathbf{A} \\mathbf{v} ;\\forall \\mathbf{u} ,\\mathbf{v} \\in V\\wedge \\mathbf{A} \\in \\mathbb{R}^{n\\times n}$$\n",
    "<p style=\"text-align: right;\">$(2.11)$</p>\n",
    "\n",
    "donde $V$ es un espacio vectorial normado, es de hecho un producto interno siempre que la matriz $\\mathbf{A} =\\left\\{ a_{ij}\\right\\}$ sea definida positiva; es decir, si las submatrices $\\tilde{\\mathbf{A} } =\\left\\{ \\tilde{a}_{ij} \\right\\}$, con $i=1,...,n-r$ y $j=1,...,n-r$, para $r = 1,...,n-1$, son todas invertibles. Una matriz que cumple con este criterio es\n",
    "\n",
    "$$\\mathbf{A} =\\left( \\begin{array}{rr}1&-\\frac{1}{2} \\\\ -\\frac{1}{2} &1\\end{array} \\right)$$\n",
    "<p style=\"text-align: right;\">$(2.12)$</p>\n",
    "\n",
    "El producto interno (2.11) induce la norma $\\| \\mathbf{u} \\| =\\mathbf{u}^{\\top } \\mathbf{A} \\mathbf{u}$ para todo $\\mathbf{u}\\in V$. Con esta norma, obtenemos $\\| \\mathbf{u} \\|=\\sqrt{1}=1$. Por lo tanto, la longitud del vector $\\mathbf{u}$ será dependiente de la norma con la cual se defina. Esto abre la posibilidad de pensar en que la geometría no necesariamente tiene que ser Euclidiana, ya que los conceptos de distancia, como veremos un poco más adelante, dependerán de la métrica con la cual equipemos al espacio donde estamos trabajando. ◼︎\n",
    "\n",
    "**<font color='blue'>Definición 2.3 – Distancia y métrica:</font>** Sea $V$ un espacio vectorial normado y sean $u,v\\in V$. Definimos la **distancia** entre los vectores $u$ y $v$ como\n",
    "\n",
    "$$d\\left( u,v\\right)  :=\\left\\Vert u-v\\right\\Vert  =\\sqrt{\\left< u-v,u-v\\right>  }$$\n",
    "<p style=\"text-align: right;\">$(2.13)$</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
