{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e1669c0-8070-49f1-8c87-e57d2962124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acdc03ac-99a7-45da-b19e-1b3e34986ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9112f827-54d9-4f67-917f-63d7ee8ad00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMarginSVM:\n",
    "    def __init__(self, random_seed=42, C=1.0):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - random_seed: Seed for reproducibility.\n",
    "        - C: Regularization hyperparameter. Controls the trade-off between a smooth decision boundary and classifying training points correctly.\n",
    "        \"\"\"\n",
    "        self.random_seed = random_seed\n",
    "        self.C = C\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Soft Margin SVM model to the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input features (numpy array of shape [m, n]).\n",
    "        - y: Target values (-1 or +1) for each example in X (numpy array of shape [m,]).\n",
    "        \"\"\"\n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(self.random_seed)\n",
    "\n",
    "        m, n = X.shape\n",
    "\n",
    "        # Define the dual optimization problem\n",
    "        def objective(alpha):\n",
    "            return 0.5 * np.dot(alpha, alpha) - np.sum(alpha)\n",
    "\n",
    "        # Equality constraint: sum(alpha * y) = 0\n",
    "        def eq_constraint(alpha, y):\n",
    "            return np.dot(alpha, y)\n",
    "\n",
    "        # Inequality constraint: 0 <= alpha_i <= C\n",
    "        alpha_constraints = [{'type': 'ineq', 'fun': lambda alpha: alpha[i]} for i in range(m)]\n",
    "        C_constraint = {'type': 'ineq', 'fun': lambda alpha: self.C - alpha.sum()}\n",
    "\n",
    "        # Initial guess for alpha\n",
    "        alpha_init = np.random.rand(m)\n",
    "\n",
    "        # Solve the dual optimization problem using scipy's minimize function\n",
    "        res = minimize(objective, alpha_init, method='SLSQP', constraints=[{'type': 'eq', 'fun': eq_constraint, 'args': (y,)}, C_constraint] + alpha_constraints)\n",
    "\n",
    "        # Extract support vectors and compute weights and bias\n",
    "        support_vector_mask = res.x > 1e-5\n",
    "        self.alpha = res.x[support_vector_mask]\n",
    "        self.support_vectors = X[support_vector_mask]\n",
    "        self.support_vector_labels = y[support_vector_mask]\n",
    "\n",
    "        # Compute weights\n",
    "        self.w = np.dot(self.alpha * self.support_vector_labels, self.support_vectors)\n",
    "\n",
    "        # Compute bias\n",
    "        self.b = np.mean(self.support_vector_labels - np.dot(self.w, self.support_vectors.T))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels for new data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input features for prediction (numpy array of shape [k, n]).\n",
    "\n",
    "        Returns:\n",
    "        - Predicted class labels (-1 or +1) for each example in X (numpy array of shape [k,]).\n",
    "        \"\"\"\n",
    "        return np.sign(np.dot(self.w, X.T) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2cad71d-58cf-40f2-b5a2-b39593749dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "983ffdd4-5375-44b6-810f-16a8c153a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=2, center_box=(0, 15), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a2632eb-017d-4ba4-b5d5-a7f61bf57813",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4769178-4282-43ab-a4a2-47e9b1b37580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftMarginSVM(random_seed=42, C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06f22e-5ac4-4b71-b677-49c0cbf27710",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff41c01-ca7c-46e6-86e4-c0455caaf11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354ad91-ba4c-4446-b666-a5f87b4c9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a9e1d2-6496-4a51-aa8a-81e8d428ae12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
