{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0fe7226",
   "metadata": {},
   "source": [
    "# CLASE 2.1: Una introducción (sencilla) a los algoritmos de aprendizaje.\n",
    "---\n",
    "\n",
    "## Motivación.\n",
    "El concepto de *\"Machine Learning\"*, o su versión (aproximadamente) equivalente en español, *algoritmos de aprendizaje*, ha sido repetido varias veces a lo largo de estos apuntes, pero siempre evitando dar definiciones rigurosas en relación al mismo, con la promesa (que a estas alturas, probablemente, sea difícil de creer) de que *pronto* o *más adelante* nos apegaremos al manual y definiremos este concpeto. Sin embargo, en esta sección, ha llegado la hora de cumplir. Haremos todo el esfuerzo posible para definir esta frase, tan de moda por estos días en prácticamente todos los ámbitos de la ingeniería, con lujo de detalles.\n",
    "\n",
    "Partiremos diciendo pues que *Machine Learning* no es exactamente lo mismo que *algoritmos de aprendizaje*, sino que resulta en un concepto más general. Con *Machine Learning* nos referimos a un sub-campo de la *inteligencia artificial* que se divide fundamentalmente en tres áreas: **Aprendizaje supervisado**, **aprendizaje no supervisado** y **aprendizaje por reforzamiento**. Existe una rama especial, llamada **deep learning**, que permite revisitar las áreas previamente comentadas –y busca extenderlas a fin de cubrir otro tipo de soluciones en inteligencia artificial–, tales como **representación del conocimiento**, **razonamiento**, **planificación** y **procesamiento del lenguaje natural**, por medio de una unidad de cálculo de gran potencia conocida como **red neuronal artificial**. Se tienen pues dos sabores distintos para este concepto: El **aprendizaje automatizado clásico** (*classic machine learning*) y el **aprendizaje profundo** (*deep learning*, por medio de redes neuronales artificiales). En estos apuntes nos enfocaremos fundamentalmente en el aprendizaje automatizado clásico, enfocado en problemas de aprendizaje tanto supervisado como no supervisado. Y antes de entrar de lleno en formulaciones y código, vamos a tomarnos algo de tiempo para hablar acerca de algunos elementos fundamentales relativos a los algoritmos de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce663f6c",
   "metadata": {},
   "source": [
    "## Algoritmos de aprendizaje.\n",
    "Un algoritmo de aprendizaje (al cual, con frecuencia, nos referiremos igualmente como *algoritmo de machine learning*) corresponde a un **algoritmo que puede aprender a partir de los datos**. No obstante, la definicón del verbo *aprender* suele ser difusa en este contexto. Tom Mitchell, en su libro de 1997 titulado simplemente *Machine Learning*, nos provee con la siguiente definición.\n",
    "\n",
    "**<font color='blue'>Definición 1.1 – Algoritmo de aprendizaje (o algoritmo de machine learning):</font>** Se dice que un programa de computadora *aprende* desde la experiencia $E$, con respecto a algún conjunto de tareas o problemas $T$ y una determinada métrica de rendimiento $P$, si su desempeño en las tareas de $T$, medido por $P$, mejora con la experiencia $E$.\n",
    "\n",
    "Podemos imaginar una gran cantidad de experiencias $E$, tareas $T$ y métricas de rendimiento $P$. No haremos el esfuerzo de definir formalmente estos conceptos. En su lugar, intentaremos construir una noción más bien intuitiva de estas entidades, apoyándonos por medio de ejemplos sencillos de diferentes tipos de tareas, métricas de rendimiento y experiencias que pueden ser utilizados para la construcción de algoritmos de aprendizaje.\n",
    "\n",
    "### La tarea o problema, $T$.\n",
    "Los algoritmos de aprendizaje nos permiten tratar problemas que pueden resultar extremadamente difíciles de resolver mediante programas con instrucciones fijas, comúnmente diseñados por seres humanos. Desde un punto de vista tanto científico como filosófico, el aprendizaje automatizado resulta interesante porque el desarrollo de nuestro entendimiento de este tipo de algoritmos nos permite igualmente entender los principios subyacentes a un concepto mucho más general, que corresponde al de *inteligencia*.\n",
    "\n",
    "En un nivel de abstracción menos nebuloso, el proceso de *aprender* no es un sinónimo de la **tarea** propiamente tal. El aprendizaje es el proceso que nos permite adoptar la habilidad de realizar una tarea. Por ejemplo, si queremos que un robot sea capaz de caminar, entonces *caminar* es la *tarea*. Podríamos programar al robot para que *aprenda* a caminar, o bien, podríamos intentar escribir directamente un programa que describa paso a paso como un robot *puede* caminar.\n",
    "\n",
    "Los problemas de machine learning suelen describirse en términos de cómo un sistema de aprendizaje automatizado debiera procesar un **ejemplo** o **instancia**. Un ejemplo es una colección de **atributos** que han sido cuantitativamente medidos a partir de algún evento u objeto que queremos que sl sistema de aprendizaje procese. Con frecuencia, solemos representar un ejemplo por medio de un vector $\\mathbf{x}\\in \\mathbb{R}^{n}$, donde cada elemento $x_{i}$ (para $1\\leq i\\leq n$) del vector es una medición relativa a un atributo. Por ejemplo, los atributos de una imagen son, usualmente, los pixeles de la misma; en un conjunto de datos con **formato rectangular** o **matricial**, los atributos se corresponden con las columnas de la matriz, siendo las filas los ejemplos o instancias.\n",
    "\n",
    "Es posible resolver varios tipos de problemas mediante el uso de algoritmos de aprendizaje. Algunos ejemplos de estos problemas son los siguientes:\n",
    "\n",
    "1. **Clasificación:** En este tipo de problema, queremos que un programa de computadora especifique a cuál de un conjunto finito de $k$ categorías pertenece un determinado vector $\\mathbf{x}\\in \\mathbb{R}^{n}$. Para resolver este problema, se suele pedir a un algoritmo de aprendizaje que produzca una función, digamos $f:\\mathbb{R}^{n} \\longrightarrow \\left\\{ 1,...,k\\right\\}$, que llamamos **modelo**. Cuando $y=f(\\mathbf{x})$, el modelo asigna una entrada descrita por el vector $\\mathbf{x}\\in \\mathbb{R}^{n}$ a una categoría que identificamos por medio de un código numérico que llamamos $y$. Existen otras variantes de un problema de clasificación, donde $f$ permite describir la probabilidad de que $\\mathbf{x}$ pertenezca a una determinada clase. Un ejemplo de problema de clasificación corresponde a la determinación de la probabilidad de falla de un talud en una operación minera a cielo abierto, dados ciertos atributos que describen sus parámetros geomecánicos, geométricos y operacionales. Si un vector $\\mathbf{x}\\in \\mathbb{R}^{n}$ describe un total de $n$ atributos de interés, y el talud es categorizado en un total de $k$ condiciones diferentes –por ejemplo, $k=\\left\\{ \\mathrm{buena} \\  \\mathrm{calidad} ,\\mathrm{calidad} \\  \\mathrm{regular} ,\\mathrm{mala} \\  \\mathrm{calidad} \\right\\}$, las que codificamos mediante los valores $k=\\left\\{ 0,1,2\\right\\}$–, entonces queremos que nuestro algoritmo de aprendizaje estime una función de probabilidad $P(y=k)$, que describa qué tan probable es que el talud se corresponda con una determinada categoría.\n",
    "\n",
    "2. **Regresión:** En este tipo de problema, queremos que un programa de computadora estima (o *prediga*) un valor numérico continuo a partir de un conjunto de datos de entrada.Para resolver este problema, se suele pedir a un algoritmo de aprendizaje que produzca una función $f:\\mathbb{R}^n\\longrightarrow \\mathbb{R}$, que llamamos **modelo**. Se trata de un problema cuya naturaleza es similar al de un problema de clasificación, con el detalle de que el *formato* de la **variable de respuesta** es diferente. Un ejemplo de problema de regresión corresponde a la predicción del tamaño de mineral (comúnmente el $P_{80}$ con respecto a una referencia de malla Tyler) que se obtiene en una planta de molienda, a partir de datos operacionales y contextuales. En este caso, la variable de respuesta, que llamamos $y$, es continua (o, al menos, seccionalmente continua) en un intervalo (a veces desconocido) en $\\mathbb{R}$.\n",
    "\n",
    "3. **Detección de anomalías:** En este tipo de problema, queremos que un programa de computadora examine cuidadosamente un conjunto de eventos u objetos (representados, naturalmente, por datos), y califique algunos de ellos como *atípicos* o *inusuales*. Un ejemplo de problema de este tipo corresponde a la detección de eventos sísmicos de gran magnitud de momento en una operación minera subterránea sometida a campos tensionales de enorme magnitud. Tales eventos sísmicos son completamente inusuales, y suelen ser inducidos por anomalías operacionales en la forma en la cual hacemos minería. En términos probabilísticos, solemos decir que tales eventos se muestrean a partir de una distribución de probabilidad distinta a la que gobierna los eventos sísmicos más comunes (y que pueden ocurrir de a cientos de miles cada año).\n",
    "\n",
    "4. **Estimación de funciones de densidad:** En este tipo de problema, queremos que un programa de computadora *aprenda* una función $f_{\\mathrm{modelo}}:\\mathbb{R}^{n}\\longrightarrow \\mathbb{R}$, donde $f_{\\mathrm{modelo}}(\\mathbf{x})$ puede interpretarse como una función de densidad conjunta de probabilidad (si $\\mathbf{x}$ es una variable continua) o una función de masa conjunta de probabilidad (si $\\mathbf{x}$ es una variable discreta), en ambos casos definida sobre un espacio muestral desde donde se han extraído las instancias del problema. Para lograr resolver este problema con éxito (y especificaremos qué significa el *éxito* al hablar acerca de la métrica de desempeño $P$), el correspondiente algoritmo de aprendizaje requiere *aprender* la estructura de la data que ha *visto*. Debe reconocer donde las instancias se agrupan de forma más apretada (formando lo que, en estadística, se denomina *cluster*), y donde aquello es menos probable que ocurra. La mayoría de estos sub-problemas requieren que el algoritmo de aprendizaje capture (al menos de forma implícita) la estructura de la correspondiente distribución de probabilidad.\n",
    "\n",
    "Por supuesto, pueden definirse más problemas o tareas. Las que hemos listado simplemente tienen el objetivo de proveer de ejemplos un tanto más tangibles para así construir una noción intuitiva de lo que significa un problema o tarea en el contexto de los algoritmos de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdae7d0-fde7-43ff-a0d8-9bb43ad13f7a",
   "metadata": {},
   "source": [
    "### La métrica de desempeño, $P$.\n",
    "A fin de evaluar las habilidades de un algoritmo de aprendizaje, debemos diseñar una métrica cuantitativa de su desempeño. Usualmente, dicha métrica $P$ es específica con respecto al problema o tarea $T$ que se desea resolver.\n",
    "\n",
    "Consideremos un problema de clasificación. En una tarea como ésta, con frecuencia, solemos medir la **exactitud** del modelo resultante. La exactitud se define como la proporción de instancias para las cuales nuestro modelo produce un resultado correcto (el mismo que el real). También podemos obtener información equivalente por medio de la medición de la **tasa de error**, que es la proporción de instancias para las cuales nuestro modelo produce un resultado incorrecto. Para problemas tales como la regresión, la medición de cantidades tales como la exactitud o la tasa de error no tiene sentido, porque las variables de salida son continuas y, por definición, matemáticamente la probabilidad de que un modelo (sin ningún tipo de fuga de datos –o *data leakage*–) le *atine* exactamente al valor real es igual a cero, de la misma forma que la probabilidad de que un dardo caiga exactamente en las coordenadas $(x,y)$ de un blanco es también cero, porque existen infinitos de estos puntos. En un contexto como éste, estamos interesados en diseñar métricas de desempeño basadas en la **distancia** existente entre un valor estimado por el modelo (digamos $\\tilde{y}_{\\mathrm{pred}}$) y el correspondiente valor real ($y_{\\mathrm{real}}$). Por ejemplo, el error cuadrático medio es una métrica apta de desempeño para los modelos de regresión, ya que permite obtener el promedio de las diferencias (distancias) al cuadrado entre $\\tilde{y}_{\\mathrm{pred}}$ e $y_{\\mathrm{real}}$. Es decir,\n",
    "\n",
    "$$P=\\frac{1}{m} \\sum^{m}_{i=1} \\left( \\tilde{y}_{\\mathrm{pred} } -y_{\\mathrm{real} }\\right)^{2}$$\n",
    "<p style=\"text-align: right;\">$(1.1)$</p>\n",
    "\n",
    "Usualmente, estamos interesados en qué tan bien se desempeña un algoritmo de machine learning sobre un conjunto de datos que no ha *visto* previamente, dado que aquello nos dará una idea (aproximada) en relación a cómo dicho algoritmo va a trabajar cuando se *despliegue* en el mundo real. Por lo tanto, las métricas de desempeño suelen evaluarse sobre un **conjunto de datos de prueba**, que se separa en primera instancia del conjunto de datos que se utiliza para que nuestro algoritmo *aprenda* a partir de ellos, y que suele llamarse **conjunto de entrenamiento**.\n",
    "\n",
    "La elección de la métrica de desempeño $P$ puede parecer directa y objetiva, pero con frecuencia resulta resulta difícil escoger una métrica que se corresponda exactamente con el comportamiento que queremos que el sistema de interés –basado en el algoritmo de aprendizaje– tenga en el futuro. En algunos casos, esto se debe a que a veces es complicado decidir qué deberíamos medir. Por ejemplo, cuando resolvemos un problema de regresión, una pregunta que cae de cajón es la siguiente: ¿Deberíamos penalizar más el sistema si éste frecuentemente comete errores cuya magnitud no sea muy significativa, o si rara vez comete errores de magnitud muy singifcativa? Estas decisiones, naturalmente, dependen de la aplicación del sistema que queremos diseñar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941c2ad-51c3-41e4-971d-70c646ee0154",
   "metadata": {},
   "source": [
    "### La experiencia, $E$.\n",
    "Los algoritmos de machine learning pueden ser categorizados, en términos legos, pueden ser categorizados en algoritmos de aprendizaje **supervisado** y **no supervisado**, en términos del tipo de **experiencia** que permitimos que éstos tengan durante su correspondiente proceso de aprendizaje.\n",
    "\n",
    "La mayoría de los algoritmos de aprendizaje que trataremos en estos apuntes serán tales que permitiremos que éstos aprendan a partir de un **conjunto de datos** o **dataset**. Un dataset es una colección de muchas instancias, que suelen denominarse como **datos puntuales** (del inglés, *data points*). Un ejemplo de dataset muy utilizado por profesores y alumnos desde hace mucho tiempo (y subrayamos *muy utilizado*, porque es muy común verlo en infinidad de cursos online de ciencia de datos o machine learning, e incluso en la documentación de varias librerías o frameworks dedicadas a la implementación de estas materias a nivel computacional) corresponde al dataset <font color='green'>IRIS</font>, desarrollado por el matemático inglés Ronald Fisher y presentado en 1936, que contiene 50 muestras de cada una de tres especies de flores del género Iris (*Iris setosa, Iris virginica* e *Iris versicolor*). Para cada flor se especifican cuatro rasgos: El largo y ancho del sépalo y pétalo, en centímetros. De esta manera, cada muestra de flor en este dataset representa una instancia que comunica las mediciones relativas a los rasgos previamente señalados.\n",
    "\n",
    "Como <font color='green'>IRIS</font>, existen muchos datasets famosos que han sido masivamente utilizados para explicar (y *aprender*) todo tipo de algoritmos y modelos. Cuando comencemos a estudiar las implementaciones de algoritmos de aprendizaje en Python provistas por la librería <font color='mediumorchid'>Scikit-Learn</font>, dedicaremos un tiempo a revisar el módulo `sklearn.datasets`, que nos proveerá de muchos datasets con los que podremos probar nuestras implementaciones de machine learning. Estos datasets tienen, en general, la característica general de ser *bien comportados*. Es decir, tienen una estructura particularmente fácil de aprender por ciertos tipos de algoritmos, no tienen filas (instancias) con registros vacíos (`nan`, como aprendimos al estudiar el detalle algunas implementaciones de la librería <font color='mediumorchid'>Pandas</font>) u otras anomalías típicas que encontraríamos en datasets propios del *mundo real*. Por esa razón, muchos profesionales y académicos suelen referirse a estos datasets como *toysets* (a veces, cariñosamente, a veces, quizás despectivamente). Son perfectos para dar los primeros pasos a la hora de aprender a diseñar sistemas basados en algoritmos de aprendizaje, y como benchmark a la hora de diseñar nuevos algoritmos. Pero no son, en absoluto, buenos representantes de los datasets que nos encontraremos en el mundo real, donde seguramente nos gastaremos la mayor parte de nuestro tiempo en trabajarlos a fin de llegar al **formato estructurado** que la mayoría de los algoritmos de aprendizaje requerirán en un principio (y en el que ya nos adentraremos más adelante).\n",
    "\n",
    "Pasado el paréntesis anterior relativos a los datasets, es bueno que profundicemos un poco más diferenciar los algoritmos de aprendizaje supervisado de los no supervisados. En efecto,\n",
    "\n",
    "a) Los algoritmos de **aprendizaje no supervisado** *experimentan* un dataset que contiene muchos **atributos**. De esta manera, pueden *aprender* algunas propiedades de interés relativas a la estructura de dicho dataset. Por ejemplo, la distribución de probabilidad que ha generado el dataset completo, o bien, ciertas similitudes entre subconjuntos propios del dataset que guardan relación con su propia estructura, lo que se denomina en la práctica como agriupamiento o **clustering**.\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_1_2.png\" width=\"850\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (1.1): Un esquema ilustrativo que ejemplifica el caso de un algoritmo de aprendizaje no supervisado. El sistema de interés se basa en un modelo de agrupamiento o clustering que se entrena sobre un dataset que contiene imágenes de muchos animales, sin ningún indicador que permita al algoritmo tener información de a qué animal corresponde cada imagen. El objetivo del algoritmo es, por tanto, agrupar estas imágenes en estructuras similares (por ejemplo, grupos de gatos –o animales similares–, grupos de perros –o animales similares–, y así sucesivamente)</p>\n",
    "\n",
    "b) Los algoritmos de **aprendizaje supervisado** *experimentan* un dataset que también contiene atributos, pero cada instancia tiene asociada una **etiqueta** o **valor objetivo**. Por ejemplo, en el caso del dataset <font color='green'>IRIS</font>, tal valor objetivo corresponde a la subespecie de flor Iris que está asociada a cada instancia (caracterizada por el largo y ancho de pétalos y sépalos de cada flor). De esta manera, un algoritmo de aprendizaje supervisado puede **clasificar** cada flor en una subespecie de Iris determinada, basado en los atributos relativos a cada una.\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"figures/fig_1_1.png\" width=\"850\"></p>\n",
    "<p style=\"text-align: center;\">Fig. (1.2): Un esquema ilustrativo que ejemplifica el caso de un algoritmo de aprendizaje supervisado. El sistema de interés se basa en un modelo de clasificación que permite discriminar imágenes de gatos con respecto a imágenes que muestran a otros animales. En este caso, el dataset consiste de instancias $\\mathbf{x}\\in \\mathbb{R}^{n}$ que están etiquetadas con valores $y$ tales que $y=\\mathrm{Gato}$ e $y=\\mathrm{No} \\  \\mathrm{gato}$</p>\n",
    "\n",
    "En términos simples, el aprendizaje no supervisado involucra la *observación* de varias instancias de un vector aleatorio $\\mathbf{x}$, a fin de aprender (ya sea implícita o explícitamente) la distribución de probabilidad inherente a $\\mathbf{x}$, o bien, algunas propiedades de interés para dicha distribución. Por otro lado, el aprendizaje supervisado involucra la observación de varias instancias de un vector aleatorio $\\mathbf{x}$, junto con un valor asociado (o vector) $\\mathbf{y}$, a fin de predecir el valor de $\\mathbf{y}$ en términos de $\\mathbf{x}$, usualmente por medio de la estimación de la probabilidad condicional $P(\\mathbf{y}|\\mathbf{x})$. El término *\"aprendizaje supervisado\"* se origina a partir de la consideración de $\\mathbf{y}$ como una suerte de *instructor* o *profesor*, el cual le *muestra* a un hipotético sistema basado en algoritmos de machine learning qué *tiene* que aprender. En el caso del aprendizaje no supervisado, no existe un *instructor* y, por tanto, el algoritmo de aprendizaje debe *aprender* por sí mismo *alguna* característica del dataset sin esta guía.\n",
    "\n",
    "Algunos algoritmos de machine learning no *experimentan* un dataset fijo. Por ejemplo, los algoritmos de **aprendizaje por reforzamiento** interactúan con un **entorno**, de tal forma que existe un bucle de retroalimentación entre el sistema y sus experiencias. Tales algoritmos están fuera del alcance de estos apuntes, pero existen alternativas muy buenas para su aprendizaje, como el maravilloso libro [*Reinforcement Learning, an Introduction*](https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf) (Barto, A. & Sulton, R., 2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e11f6-154f-4581-b9bb-021fe721b629",
   "metadata": {},
   "source": [
    "## Datos, modelos y aprendizaje.\n",
    "A partir de este momento, vamos a asumir siempre que cualquier conjunto de datos puede ser leído por medio de un computador, y representado adecuadamente en un formato numérico con un formato estructurado de tipo tabular. Tomemos el ejemplo del dataset `mill_circuit_data.csv`, en la carpeta `datasets` de este repositorio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
